{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d719021c",
   "metadata": {},
   "source": [
    "# 8-1. 프로젝트 : 네이버 영화리뷰 감성분석 도전하기\n",
    "활용할 데이터셋은 네이버 영화의 댓글을 모아 구성된 [Naver sentiment movie corpus](https://github.com/e9t/nsmc)입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80ad4026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.3\n",
      "0.5.2\n",
      "4.1.2\n",
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import konlpy\n",
    "import gensim\n",
    "import tensorflow as tf\n",
    "\n",
    "print(pandas.__version__)\n",
    "print(konlpy.__version__)\n",
    "print(gensim.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc88024a",
   "metadata": {},
   "source": [
    "## 1) 데이터 준비와 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9e882fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6d76d4",
   "metadata": {},
   "source": [
    "## 2) 데이터로더 구성\n",
    "실습 때 다루었던 IMDB 데이터셋은 텍스트를 가공하여 imdb.data_loader() 메서드를 호출하면 숫자 인덱스로 변환된 텍스트와 word_to_index 딕셔너리까지 친절하게 제공합니다. 그러나 이번에 다루게 될 nsmc 데이터셋은 전혀 가공되지 않은 텍스트 파일로 이루어져 있습니다. 이것을 읽어서 imdb.data_loader()와 동일하게 동작하는 자신만의 data_loader를 만들어 보는 것으로 시작합니다. data_loader 안에서는 다음을 수행해야 합니다.\n",
    "\n",
    "- 데이터의 중복 제거\n",
    "- NaN 결측치 제거\n",
    "- 한국어 토크나이저로 토큰화\n",
    "- 불용어(Stopwords) 제거\n",
    "- 사전 `word_to_index` 구성\n",
    "- 텍스트 스트링을 사전 인덱스 스트링으로 변환\n",
    "- `X_train`, `y_train`, `X_test`, `y_test`, `word_to_index` 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb95fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    \n",
    "    # 결측치 제거\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "    \n",
    "    # train data\n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 한국어 토크나이저로 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    # test data\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "    \n",
    "    # 학습 데이터에서 가장 많이 등장하는 단어를 선택하여 단어 집합(vocabulary) 구성\n",
    "    words = np.concatenate(X_train).tolist() # words에는 학습 데이터에 등장한 모든 단어가 포함된 리스트가 저장\n",
    "    counter = Counter(words) # Counter 클래스를 사용하여 words 리스트 내의 각 단어의 빈도수를 계산\n",
    "    counter = counter.most_common(10000-4) # 빈도수가 가장 높은 단어부터 내림차순으로 정렬된 리스트를 생성, -4를 하는 이유는 이전에 4개의 예약어를 추가했기 때문\n",
    "    vocab = ['', '', '', ''] + [key for key, _ in counter] # 처음 4개의 요소가 빈 문자열('')로 초기화 그리고 이어서 상위 단어들이 추가\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)} # 딕셔너리\n",
    "    \n",
    "    # 처음 몇 개 인덱스는 사전에 정의되어 있습니다.\n",
    "    word_to_index[\"<PAD>\"] = 0\n",
    "    word_to_index[\"<BOS>\"] = 1\n",
    "    word_to_index[\"<UNK>\"] = 2 # unknown\n",
    "    word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "    # 주어진 단어 리스트(wordlist)를 단어 인덱스 리스트로 변환하는 역할\n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index[''] for word in wordlist]\n",
    "        \n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "    \n",
    "    # 리턴\n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "    \n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faf9708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab600d0",
   "metadata": {},
   "source": [
    "## 3) 모델 구성을 위한 데이터 분석 및 가공\n",
    "- 데이터셋 내 문장 길이 분포\n",
    "- 적절한 최대 문장 길이 지정\n",
    "- keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1ff2fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  15.96940191154864\n",
      "문장길이 최대 :  116\n",
      "문장길이 표준편차 :  12.843571191092\n",
      "pad_sequences maxlen :  41\n",
      "전체 문장의 0.9342988343341575%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(X_train) + list(X_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print(f'전체 문장의 {np.sum(num_tokens < max_tokens) / len(num_tokens)}%가 maxlen 설정값 이내에 포함됩니다. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b53b35ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre padding\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre',\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre', \n",
    "                                                        maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600b514a",
   "metadata": {},
   "source": [
    "## 4) 모델 구성 및 validation set 구성\n",
    "모델은 3가지 이상 다양하게 구성하여 실험해 보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9c288f",
   "metadata": {},
   "source": [
    "### 첫 번째 모델 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c1ab7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(embedding_matrix, maxlen, vocab_size=10000, word_vector_dim=100):\n",
    "    '''\n",
    "    embedding_matrix: 사전 학습된 임베딩 레이어 (없으면 0)\n",
    "    maxlen: 문장의 최대 길이\n",
    "    vocab_size: 어휘 사전의 크기입니다(단어 개수)\n",
    "    word_vector_dim: 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "    '''\n",
    "\n",
    "    # model 설계\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    if type(embedding_matrix) != int:\n",
    "        model.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                     word_vector_dim, \n",
    "                                     embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                     input_length=maxlen, \n",
    "                                     trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "    else:\n",
    "        model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "    model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "    model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "    model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1 dim 입니다.\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bc09207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          11216     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,013,169\n",
      "Trainable params: 1,013,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_cnn = cnn_model(0,maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4858e4",
   "metadata": {},
   "source": [
    "### 두 번째 모델 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2ad6063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_model(embedding_matrix, maxlen,vocab_size=10000, word_vector_dim=100):\n",
    "    '''\n",
    "    embedding_matrix: 사전 학습된 임베딩 레이어 (없으면 0)\n",
    "    maxlen: 문장의 최대 길이\n",
    "    vocab_size: 어휘 사전의 크기입니다(단어 개수)\n",
    "    word_vector_dim: 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "    '''\n",
    "\n",
    "    # model 설계\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    if embedding_matrix == True:\n",
    "        model.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                     word_vector_dim, \n",
    "                                     embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                     input_length=maxlen, \n",
    "                                     trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "    else:\n",
    "        model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "\n",
    "    model.add(tf.keras.layers.SimpleRNN(32))  # RNN 레이어\n",
    "    model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid')) # 최종 출력은 긍정/부정을 나타내는 1 dim 입니다.\n",
    "        \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cf3ab9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 32)                4256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,004,529\n",
      "Trainable params: 1,004,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_rnn = rnn_model(0, maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9375ed6",
   "metadata": {},
   "source": [
    "### 세 번째 모델 GlobalMaxPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "129b0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def globalmax_model(embedding_matrix, maxlen, vocab_size=10000, word_vector_dim=100):\n",
    "    '''\n",
    "    embedding_matrix: 사전 학습된 임베딩 레이어 (없으면 0)\n",
    "    maxlen: 문장의 최대 길이\n",
    "    vocab_size: 어휘 사전의 크기입니다(단어 개수)\n",
    "    word_vector_dim: 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "    '''\n",
    "\n",
    "    # model 설계\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    if embedding_matrix == True:\n",
    "        model.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                     word_vector_dim, \n",
    "                                     embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                     input_length=maxlen, \n",
    "                                     trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "    else:\n",
    "        model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "\n",
    "    model.add(tf.keras.layers.GlobalMaxPooling1D())  # GlobalMaxPooling 레이어\n",
    "    model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid')) # 최종 출력은 긍정/부정을 나타내는 1 dim 입니다.\n",
    "        \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7e9b2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 808       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,000,817\n",
      "Trainable params: 1,000,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_gm = globalmax_model(0,maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661d7b53",
   "metadata": {},
   "source": [
    "## 5) 모델 훈련 개시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "514e3be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partial_x_train size:  (116946, 41)\n",
      "partial_y_train size:  (116946,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 20%로 분리\n",
    "split_ratio = 0.2\n",
    "split_index = int(len(X_train) * split_ratio)\n",
    "\n",
    "x_val = X_train[:split_index]   \n",
    "y_val = y_train[:split_index]\n",
    "\n",
    "# validation set을 제외한 나머지 80%\n",
    "partial_x_train = X_train[split_index:]  \n",
    "partial_y_train = y_train[split_index:]\n",
    "\n",
    "print(\"partial_x_train size: \", partial_x_train.shape)\n",
    "print(\"partial_y_train size: \", partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e48150f",
   "metadata": {},
   "source": [
    "### CNN 훈련 및 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89efdf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "229/229 [==============================] - 5s 7ms/step - loss: 0.4570 - accuracy: 0.7788 - val_loss: 0.3427 - val_accuracy: 0.8506\n",
      "Epoch 2/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.3093 - accuracy: 0.8702 - val_loss: 0.3286 - val_accuracy: 0.8588\n",
      "Epoch 3/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2590 - accuracy: 0.8952 - val_loss: 0.3301 - val_accuracy: 0.8611\n",
      "Epoch 4/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2019 - accuracy: 0.9238 - val_loss: 0.3571 - val_accuracy: 0.8545\n",
      "Epoch 5/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.1411 - accuracy: 0.9503 - val_loss: 0.4158 - val_accuracy: 0.8486\n",
      "Epoch 6/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.0934 - accuracy: 0.9689 - val_loss: 0.4868 - val_accuracy: 0.8457\n",
      "Epoch 7/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.0627 - accuracy: 0.9808 - val_loss: 0.5695 - val_accuracy: 0.8424\n",
      "Epoch 8/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.0451 - accuracy: 0.9871 - val_loss: 0.6575 - val_accuracy: 0.8419\n",
      "Epoch 9/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.0355 - accuracy: 0.9898 - val_loss: 0.6980 - val_accuracy: 0.8388\n",
      "Epoch 10/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.0292 - accuracy: 0.9917 - val_loss: 0.7482 - val_accuracy: 0.8373\n",
      "Epoch 11/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.0247 - accuracy: 0.9931 - val_loss: 0.7965 - val_accuracy: 0.8391\n",
      "Epoch 12/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.0220 - accuracy: 0.9937 - val_loss: 0.8409 - val_accuracy: 0.8367\n",
      "Epoch 13/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.0210 - accuracy: 0.9938 - val_loss: 0.9182 - val_accuracy: 0.8375\n",
      "Epoch 14/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.0214 - accuracy: 0.9934 - val_loss: 0.9083 - val_accuracy: 0.8330\n",
      "Epoch 15/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.0245 - accuracy: 0.9922 - val_loss: 0.9787 - val_accuracy: 0.8312\n",
      "Epoch 16/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.0284 - accuracy: 0.9905 - val_loss: 0.9608 - val_accuracy: 0.8334\n",
      "Epoch 17/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.0240 - accuracy: 0.9922 - val_loss: 1.0802 - val_accuracy: 0.8314\n",
      "Epoch 18/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.0195 - accuracy: 0.9934 - val_loss: 1.0389 - val_accuracy: 0.8299\n",
      "Epoch 19/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 1.1043 - val_accuracy: 0.8315\n",
      "Epoch 20/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 1.1165 - val_accuracy: 0.8328\n"
     ]
    }
   ],
   "source": [
    "model_cnn.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history_cnn = model_cnn.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "274dd15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 1.1517 - accuracy: 0.8277\n",
      "[1.1517093181610107, 0.827715277671814]\n"
     ]
    }
   ],
   "source": [
    "results_cnn = model_cnn.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27174845",
   "metadata": {},
   "source": [
    "### RNN 훈련 및 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fda3cdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "229/229 [==============================] - 11s 42ms/step - loss: 0.4287 - accuracy: 0.8050 - val_loss: 0.3530 - val_accuracy: 0.8467\n",
      "Epoch 2/20\n",
      "229/229 [==============================] - 9s 40ms/step - loss: 0.3237 - accuracy: 0.8643 - val_loss: 0.3491 - val_accuracy: 0.8509\n",
      "Epoch 3/20\n",
      "229/229 [==============================] - 9s 41ms/step - loss: 0.2809 - accuracy: 0.8866 - val_loss: 0.3683 - val_accuracy: 0.8413\n",
      "Epoch 4/20\n",
      "229/229 [==============================] - 9s 41ms/step - loss: 0.2281 - accuracy: 0.9131 - val_loss: 0.4067 - val_accuracy: 0.8346\n",
      "Epoch 5/20\n",
      "229/229 [==============================] - 9s 41ms/step - loss: 0.1772 - accuracy: 0.9354 - val_loss: 0.4507 - val_accuracy: 0.8268\n",
      "Epoch 6/20\n",
      "229/229 [==============================] - 9s 41ms/step - loss: 0.1405 - accuracy: 0.9505 - val_loss: 0.5019 - val_accuracy: 0.8230\n",
      "Epoch 7/20\n",
      "229/229 [==============================] - 9s 41ms/step - loss: 0.1135 - accuracy: 0.9604 - val_loss: 0.5819 - val_accuracy: 0.8185\n",
      "Epoch 8/20\n",
      "229/229 [==============================] - 9s 41ms/step - loss: 0.0945 - accuracy: 0.9677 - val_loss: 0.6270 - val_accuracy: 0.8179\n",
      "Epoch 9/20\n",
      "229/229 [==============================] - 9s 41ms/step - loss: 0.0802 - accuracy: 0.9727 - val_loss: 0.6843 - val_accuracy: 0.8144\n",
      "Epoch 10/20\n",
      "229/229 [==============================] - 9s 41ms/step - loss: 0.0716 - accuracy: 0.9755 - val_loss: 0.7211 - val_accuracy: 0.8133\n",
      "Epoch 11/20\n",
      "229/229 [==============================] - 9s 41ms/step - loss: 0.0635 - accuracy: 0.9780 - val_loss: 0.7869 - val_accuracy: 0.8144\n",
      "Epoch 12/20\n",
      "229/229 [==============================] - 9s 41ms/step - loss: 0.0573 - accuracy: 0.9806 - val_loss: 0.8302 - val_accuracy: 0.8067\n",
      "Epoch 13/20\n",
      "229/229 [==============================] - 9s 41ms/step - loss: 0.0536 - accuracy: 0.9815 - val_loss: 0.8697 - val_accuracy: 0.8099\n",
      "Epoch 14/20\n",
      "229/229 [==============================] - 9s 41ms/step - loss: 0.0510 - accuracy: 0.9826 - val_loss: 0.8835 - val_accuracy: 0.8099\n",
      "Epoch 15/20\n",
      "229/229 [==============================] - 9s 41ms/step - loss: 0.0459 - accuracy: 0.9840 - val_loss: 0.9302 - val_accuracy: 0.8062\n",
      "Epoch 16/20\n",
      "229/229 [==============================] - 9s 41ms/step - loss: 0.0430 - accuracy: 0.9850 - val_loss: 0.9430 - val_accuracy: 0.8107\n",
      "Epoch 17/20\n",
      "229/229 [==============================] - 9s 41ms/step - loss: 0.0434 - accuracy: 0.9844 - val_loss: 0.9954 - val_accuracy: 0.8070\n",
      "Epoch 18/20\n",
      "229/229 [==============================] - 9s 41ms/step - loss: 0.0381 - accuracy: 0.9865 - val_loss: 1.0305 - val_accuracy: 0.8022\n",
      "Epoch 19/20\n",
      "229/229 [==============================] - 9s 40ms/step - loss: 0.0354 - accuracy: 0.9875 - val_loss: 1.0703 - val_accuracy: 0.7985\n",
      "Epoch 20/20\n",
      "229/229 [==============================] - 9s 41ms/step - loss: 0.0380 - accuracy: 0.9863 - val_loss: 1.0751 - val_accuracy: 0.8052\n"
     ]
    }
   ],
   "source": [
    "model_rnn.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history_rnn = model_rnn.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec337c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 7s - loss: 1.0890 - accuracy: 0.8029\n",
      "[1.088998556137085, 0.8028764724731445]\n"
     ]
    }
   ],
   "source": [
    "results_rnn = model_rnn.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d670875",
   "metadata": {},
   "source": [
    "### GlobalMaxPooling 훈련 및 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7169d51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "229/229 [==============================] - 2s 6ms/step - loss: 0.4964 - accuracy: 0.7977 - val_loss: 0.3576 - val_accuracy: 0.8420\n",
      "Epoch 2/20\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.3257 - accuracy: 0.8619 - val_loss: 0.3371 - val_accuracy: 0.8528\n",
      "Epoch 3/20\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.2798 - accuracy: 0.8840 - val_loss: 0.3387 - val_accuracy: 0.8555\n",
      "Epoch 4/20\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.2441 - accuracy: 0.9024 - val_loss: 0.3475 - val_accuracy: 0.8553\n",
      "Epoch 5/20\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.2107 - accuracy: 0.9189 - val_loss: 0.3641 - val_accuracy: 0.8535\n",
      "Epoch 6/20\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.1774 - accuracy: 0.9349 - val_loss: 0.3859 - val_accuracy: 0.8501\n",
      "Epoch 7/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.1459 - accuracy: 0.9497 - val_loss: 0.4137 - val_accuracy: 0.8486\n",
      "Epoch 8/20\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.1168 - accuracy: 0.9622 - val_loss: 0.4474 - val_accuracy: 0.8453\n",
      "Epoch 9/20\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0918 - accuracy: 0.9721 - val_loss: 0.4854 - val_accuracy: 0.8431\n",
      "Epoch 10/20\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0711 - accuracy: 0.9803 - val_loss: 0.5246 - val_accuracy: 0.8403\n",
      "Epoch 11/20\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0554 - accuracy: 0.9852 - val_loss: 0.5593 - val_accuracy: 0.8398\n",
      "Epoch 12/20\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0430 - accuracy: 0.9894 - val_loss: 0.5977 - val_accuracy: 0.8385\n",
      "Epoch 13/20\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0340 - accuracy: 0.9915 - val_loss: 0.6357 - val_accuracy: 0.8358\n",
      "Epoch 14/20\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0271 - accuracy: 0.9933 - val_loss: 0.6711 - val_accuracy: 0.8379\n",
      "Epoch 15/20\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0222 - accuracy: 0.9945 - val_loss: 0.7030 - val_accuracy: 0.8354\n",
      "Epoch 16/20\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0187 - accuracy: 0.9951 - val_loss: 0.7318 - val_accuracy: 0.8347\n",
      "Epoch 17/20\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0159 - accuracy: 0.9956 - val_loss: 0.7623 - val_accuracy: 0.8348\n",
      "Epoch 18/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 0.7903 - val_accuracy: 0.8344\n",
      "Epoch 19/20\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.8160 - val_accuracy: 0.8350\n",
      "Epoch 20/20\n",
      "229/229 [==============================] - 1s 4ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.8393 - val_accuracy: 0.8330\n"
     ]
    }
   ],
   "source": [
    "model_gm.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history_gm = model_gm.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60300de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 2s - loss: 0.8565 - accuracy: 0.8265\n",
      "[0.8565140962600708, 0.8264540433883667]\n"
     ]
    }
   ],
   "source": [
    "results_gm = model_gm.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results_gm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ade3552",
   "metadata": {},
   "source": [
    "## 6) Loss, Accuracy 그래프 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ccefb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history_cnn.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79856c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "854e5f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_plot(eval_name, train_eval, val_eval, epochs):\n",
    "    '''\n",
    "    eval_name: 'accuracy', 'loss'\n",
    "    '''\n",
    "    # name\n",
    "    train_label = 'Training ' + eval_name\n",
    "    val_label = 'Training ' + eval_name\n",
    "    plot_title = 'Training and validation ' + eval_name\n",
    "    \n",
    "    # draw\n",
    "    plt.plot(epochs, train_eval, 'bo', label=train_label) # \"bo\"는 \"파란색 점\"입니다\n",
    "    plt.plot(epochs, val_eval, 'b', label=val_label) # b는 \"파란 실선\"입니다\n",
    "    plt.title(plot_title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(eval_name)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d7881a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_plot('Loss', loss, val_loss, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5a1051e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_plot('Accuracy', acc, val_acc, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d965bb75",
   "metadata": {},
   "source": [
    "## 7) 학습된 Embedding 레이어 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c01560f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 100)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58015566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "vocab_size = weights.shape[0]\n",
    "word_vector_dim = weights.shape[1]\n",
    "\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/workplace/exploration/ex04/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7f6d37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04407321, -0.00319362, -0.01487116, -0.03827733, -0.04826949,\n",
       "       -0.01155907, -0.03736287, -0.00327495,  0.01635257, -0.00869817,\n",
       "        0.01792267,  0.01461221,  0.03230265, -0.03731353,  0.00613331,\n",
       "        0.00729008,  0.01190798, -0.01070349,  0.02402124, -0.01754151,\n",
       "       -0.01943004,  0.03494206, -0.01110737,  0.01978768, -0.01296445,\n",
       "       -0.03251396, -0.00934353,  0.01701826, -0.03513157, -0.00935203,\n",
       "        0.0285528 , -0.03786641,  0.00513808,  0.02759087,  0.01476062,\n",
       "        0.02616345,  0.01161699,  0.01302848, -0.00469214, -0.03158619,\n",
       "        0.04872098, -0.03613473,  0.00461067,  0.04520884,  0.03750436,\n",
       "       -0.01241492, -0.03041358, -0.00982108,  0.02787762, -0.03322228,\n",
       "       -0.01774908, -0.03788294, -0.02623783,  0.01654999, -0.00916364,\n",
       "       -0.0169176 , -0.00765149, -0.02664504,  0.03672692,  0.04365844,\n",
       "        0.00363175,  0.01682774,  0.03252282,  0.00603796, -0.01853387,\n",
       "        0.03066956, -0.03738133, -0.04094013, -0.00096538,  0.01738227,\n",
       "       -0.01208596,  0.01630393, -0.03061817,  0.01586869, -0.03241998,\n",
       "       -0.0242264 , -0.04358658, -0.03179564, -0.01728214, -0.03003427,\n",
       "        0.04948506, -0.03809533, -0.02281795, -0.01564306,  0.02124027,\n",
       "       -0.03092049,  0.02137263, -0.02204883, -0.01257366,  0.02429048,\n",
       "       -0.02266438,  0.03239064,  0.03883385,  0.03534019,  0.04493887,\n",
       "        0.01960293, -0.03888273,  0.04252609,  0.02385093, -0.02593527],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['컴퓨터']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee1f4d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('동일', 0.32821688055992126),\n",
       " ('번지르르', 0.3277997076511383),\n",
       " ('지수', 0.3262002170085907),\n",
       " ('한단', 0.3242741525173187),\n",
       " ('텅', 0.3176712989807129),\n",
       " ('PD', 0.31380462646484375),\n",
       " ('-_', 0.31281813979148865),\n",
       " ('대회', 0.312574565410614),\n",
       " ('파이터', 0.30854105949401855),\n",
       " ('SM', 0.304198682308197)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"사랑\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e05bb8",
   "metadata": {},
   "source": [
    "## 8) 한국어 Word2Vec 임베딩 활용하여 성능 개선\n",
    "- 한국어 Word2Vec은 /data 폴더 안에 있는 word2vec_ko.model을 활용하세요.\n",
    "- 한국어 Word2Vec을 활용할 때는 load_word2vec_format() 형태가 아닌 load() 형태로 모델을 불러와주세요. 또한 모델을 활용할 때에는 아래 예시와 같이 .wv를 붙여서 활용합니다. 좀더 자세한 활용법에 대해선 다음 링크들을 참조해주세요. [참고 링크1](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html#storing-and-loading-models), [참고 링크2](https://radimrehurek.com/gensim/models/keyedvectors.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0719f53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "word2vec_path = '/aiffel/data/word2vec_ko.model'\n",
    "word_vectors = Word2VecKeyedVectors.load(word2vec_path)\n",
    "vector = word_vectors.wv['끝']\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bcfdc276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('이별', 0.7626414895057678),\n",
       " ('행복', 0.7550068497657776),\n",
       " ('슬픔', 0.7381505966186523),\n",
       " ('유혹', 0.7238055467605591),\n",
       " ('그리움', 0.7167419195175171),\n",
       " ('추억', 0.7143999338150024),\n",
       " ('꿈', 0.7089294195175171),\n",
       " ('애정', 0.7066588997840881),\n",
       " ('포옹', 0.7034594416618347),\n",
       " ('마음', 0.6972615718841553)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# '사랑'과 유사한 단어\n",
    "word_vectors.wv.similar_by_word(\"사랑\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f4f25fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 100  # 워드 벡터의 차원수\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word_vectors.wv:\n",
    "        embedding_matrix[i] = word_vectors.wv[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5645aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 41, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 35, 16)            11216     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 16)             1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,013,169\n",
      "Trainable params: 1,013,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "model = cnn_model(embedding_matrix,maxlen,vocab_size,word_vector_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f985a67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "229/229 [==============================] - 2s 7ms/step - loss: 0.6039 - accuracy: 0.6543 - val_loss: 0.5095 - val_accuracy: 0.7524\n",
      "Epoch 2/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.4546 - accuracy: 0.7879 - val_loss: 0.4250 - val_accuracy: 0.8066\n",
      "Epoch 3/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.3921 - accuracy: 0.8245 - val_loss: 0.4021 - val_accuracy: 0.8190\n",
      "Epoch 4/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.3548 - accuracy: 0.8451 - val_loss: 0.3724 - val_accuracy: 0.8361\n",
      "Epoch 5/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.3255 - accuracy: 0.8601 - val_loss: 0.3633 - val_accuracy: 0.8404\n",
      "Epoch 6/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.3053 - accuracy: 0.8703 - val_loss: 0.3657 - val_accuracy: 0.8382\n",
      "Epoch 7/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2881 - accuracy: 0.8784 - val_loss: 0.3644 - val_accuracy: 0.8450\n",
      "Epoch 8/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2731 - accuracy: 0.8876 - val_loss: 0.3660 - val_accuracy: 0.8407\n",
      "Epoch 9/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2599 - accuracy: 0.8933 - val_loss: 0.3676 - val_accuracy: 0.8434\n",
      "Epoch 10/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2477 - accuracy: 0.8990 - val_loss: 0.3722 - val_accuracy: 0.8473\n",
      "Epoch 11/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2347 - accuracy: 0.9057 - val_loss: 0.3751 - val_accuracy: 0.8448\n",
      "Epoch 12/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2235 - accuracy: 0.9110 - val_loss: 0.3874 - val_accuracy: 0.8458\n",
      "Epoch 13/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2126 - accuracy: 0.9159 - val_loss: 0.4025 - val_accuracy: 0.8437\n",
      "Epoch 14/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2037 - accuracy: 0.9206 - val_loss: 0.4040 - val_accuracy: 0.8439\n",
      "Epoch 15/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.1932 - accuracy: 0.9252 - val_loss: 0.4206 - val_accuracy: 0.8430\n",
      "Epoch 16/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.1821 - accuracy: 0.9311 - val_loss: 0.4427 - val_accuracy: 0.8405\n",
      "Epoch 17/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.1711 - accuracy: 0.9358 - val_loss: 0.4515 - val_accuracy: 0.8405\n",
      "Epoch 18/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.1609 - accuracy: 0.9403 - val_loss: 0.4924 - val_accuracy: 0.8395\n",
      "Epoch 19/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.1555 - accuracy: 0.9421 - val_loss: 0.4667 - val_accuracy: 0.8405\n",
      "Epoch 20/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.1447 - accuracy: 0.9469 - val_loss: 0.4943 - val_accuracy: 0.8364\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b89e4504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 0.5100 - accuracy: 0.8330\n",
      "[0.5100432634353638, 0.832963764667511]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eacc94",
   "metadata": {},
   "source": [
    "# 회고\n",
    "텍스트 분석에서 임베딩 레이어의 중요성을 배웠다. pre trained model의 사용방법과 성능향상을 경험했다. 여전히 성능을 높이기 위한 방법이 고민이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
