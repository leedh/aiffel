{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3024363a",
   "metadata": {},
   "source": [
    "# 프로젝트: 없다면 어떻게 될까? (ResNet Ablation Study) \n",
    "|평가문항|상세기준|\n",
    "|:---|:---|\n",
    "|1. ResNet-34, ResNet-50 모델 구현이 정상적으로 진행되었는가?|블록함수 구현이 제대로 진행되었으며 구현한 모델의 summary가 예상된 형태로 출력되었다.|\n",
    "|2. 구현한 ResNet 모델을 활용하여 Image Classification 모델 훈련이 가능한가?|tensorflow-datasets에서 제공하는 cats_vs_dogs 데이터셋으로 학습 진행 시 loss가 감소하는 것이 확인되었다.|\n",
    "|3. Ablation Study 결과가 바른 포맷으로 제출되었는가?|ResNet-34, ResNet-50 각각 plain모델과 residual모델을 동일한 epoch만큼 학습시켰을 때의 validation accuracy 기준으로 Ablation Study 결과표가 작성되었다.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcf7aab",
   "metadata": {},
   "source": [
    "##  0. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83477b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade tensorflow_datasets # 4.9.3 최신버전으로 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b3cceaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.21.4\n",
      "4.9.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds # tensorflow 데이터셋\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "print(tfds.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38d3a2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensorflow가 활용할 GPU가 장착되어 있는지 확인\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a64a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "#tfds.disable_progress_bar()   # 이 주석을 풀면 데이터셋 다운로드과정의 프로그레스바가 나타나지 않습니다.\n",
    "\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split=['train[:80%]', 'train[80%:]'],\n",
    "    as_supervised=True,\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865c3bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow 데이터셋을 로드 후 feature 정보 확인\n",
    "print(ds_info.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf44d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 개수도 확인\n",
    "print(tf.data.experimental.cardinality(ds_train))\n",
    "print(tf.data.experimental.cardinality(ds_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3addcb2f",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002f3d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지의 표현이 0과 1 사이로 들어오는 정규화 코드\n",
    "def normalize_and_resize_img(image, label):\n",
    "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "    image = tf.image.resize(image, (224,224))\n",
    "    return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "def apply_normalize_on_dataset(ds, is_test=False, batch_size=16):\n",
    "    ds = ds.map(\n",
    "        normalize_and_resize_img, \n",
    "        num_parallel_calls=1\n",
    "    )\n",
    "    ds = ds.batch(batch_size)\n",
    "    if not is_test:\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.shuffle(200)\n",
    "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962d434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = ds_info.features[\"label\"].num_classes\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8541e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_info.features[\"label\"].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1d4f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 일부 시각화\n",
    "fig = tfds.show_examples(ds_train, ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb903cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 일부 시각화\n",
    "fig = tfds.show_examples(ds_test, ds_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8df62e",
   "metadata": {},
   "source": [
    "## 2. Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c29555",
   "metadata": {},
   "source": [
    "### building block 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d24bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for building VGG Block\n",
    "\n",
    "def build_resnet_block(input_layer,\n",
    "                    num_cnn=3, \n",
    "                    channel=64,\n",
    "                    block_num=1,\n",
    "                    is_50=False\n",
    "                   ):\n",
    "    # 입력 레이어\n",
    "    x = input_layer\n",
    "    \n",
    "    # conv 레이어\n",
    "    if is_50 == False: # ResNet34\n",
    "        # shortcut\n",
    "        shortcut = keras.layers.Conv2D(\n",
    "            filters=channel,\n",
    "            kernel_size=(1,1)\n",
    "        )(input_layer)\n",
    "        \n",
    "        # 디폴트 3개 CNN 레이어\n",
    "        for cnn_num in range(num_cnn): \n",
    "            x = keras.layers.Conv2D(\n",
    "                    filters=channel,\n",
    "                    kernel_size=(3,3),\n",
    "                    padding='same',\n",
    "                    kernel_initializer='he_normal',\n",
    "                    name=f'block{block_num}_conv{cnn_num}_1'\n",
    "                )(x)\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "            x = keras.layers.Activation('relu')(x)\n",
    "            x = keras.layers.Conv2D(\n",
    "                    filters=channel,\n",
    "                    kernel_size=(3,3),\n",
    "                    padding='same',\n",
    "                    kernel_initializer='he_normal',\n",
    "                    name=f'block{block_num}_conv{cnn_num}_2'\n",
    "                )(x)\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "            # f(x) + x\n",
    "            x = keras.layers.Add(name=f'block{block_num}_add_{cnn_num}')([shortcut, x])\n",
    "            x = keras.layers.Activation(\"relu\", name=f'block{block_num}_out_{cnn_num}')(x)\n",
    "    \n",
    "    \n",
    "    else: #ResNet50\n",
    "        #shortcut\n",
    "        shortcut = keras.layers.Conv2D(\n",
    "                filters=channel*4,\n",
    "                kernel_size=(1,1)\n",
    "            )(input_layer)\n",
    "    \n",
    "        # 디폴트 3개 CNN 레이어\n",
    "        for cnn_num in range(num_cnn): \n",
    "\n",
    "            # 1x1 CNN 레이어\n",
    "            x = keras.layers.Conv2D(\n",
    "                        filters=channel,\n",
    "                        kernel_size=(1,1),\n",
    "                        kernel_initializer='he_normal',\n",
    "                        padding='same',\n",
    "                        name=f'block{block_num}_conv{cnn_num}_1x1'\n",
    "                    )(x)\n",
    "            \n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "            x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "            # 3x3 CNN 레이어\n",
    "            x = keras.layers.Conv2D(\n",
    "                        filters=channel,\n",
    "                        kernel_size=(3,3),\n",
    "                        kernel_initializer='he_normal',\n",
    "                        padding='same',\n",
    "                        name=f'block{block_num}_conv{cnn_num}_3x3'\n",
    "                    )(x)\n",
    "    \n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "            x = keras.layers.Activation('relu')(x)\n",
    "            \n",
    "            \n",
    "            # 1x1 CNN 레이어\n",
    "            x = keras.layers.Conv2D(\n",
    "                filters=channel*4,\n",
    "                kernel_size=(1,1),\n",
    "                activation='relu',\n",
    "                kernel_initializer='he_normal',\n",
    "                padding='same',\n",
    "                name=f'block{block_num}_conv{cnn_num}_1x1_2'\n",
    "            )(x)\n",
    "            \n",
    "            # 마지막 batch normalization\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "            \n",
    "            # f(x) + x\n",
    "            x = keras.layers.Add(name=f'block{block_num}_add_{cnn_num}')([shortcut, x])\n",
    "            x = keras.layers.Activation(\"relu\", name=f'block{block_num}_out_{cnn_num}')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fe8669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# block 생성 테스트\n",
    "resnet_input_layer = keras.layers.Input(shape=(32,32,3))   # 입력 레이어 생성\n",
    "resnet_block_output = build_resnet_block(resnet_input_layer)    # ResNet 블록 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaee72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 블록 1개짜리 model 생성\n",
    "model = keras.Model(inputs=resnet_input_layer, outputs=resnet_block_output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbb8278",
   "metadata": {},
   "source": [
    "### ResNet 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a996bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NesNet 모델 자체를 생성하는 함수\n",
    "def build_resnet(input_shape=(32,32,3),\n",
    "              num_cnn_list=[3,4,6,3],\n",
    "              channel_list=[64,128,256,512],\n",
    "              num_classes=num_classes,\n",
    "              is_50=False):\n",
    "    \n",
    "    assert len(num_cnn_list) == len(channel_list) #모델을 만들기 전에 config list들이 같은 길이인지 확인합니다.\n",
    "    \n",
    "    input_layer = keras.layers.Input(shape=input_shape)  # input layer를 만들어둡니다.\n",
    "#     output = input_layer\n",
    "    \n",
    "    # 첫 번째 Conv 레이어\n",
    "    x = keras.layers.Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(7,7),\n",
    "        strides=2\n",
    "    )(input_layer)\n",
    "    \n",
    "    # Max Pooling 레이어\n",
    "    output = keras.layers.MaxPooling2D(\n",
    "        pool_size=(3, 3),\n",
    "        strides=2\n",
    "    )(x)\n",
    "    \n",
    "    # config list들의 길이만큼 반복해서 두 번째 - 다섯 번째 Conv 블록을 생성\n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        output = build_resnet_block(\n",
    "            output,\n",
    "            num_cnn=num_cnn, \n",
    "            channel=channel,\n",
    "            block_num=i,\n",
    "            is_50=is_50\n",
    "        )\n",
    "    \n",
    "    output = keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(output)\n",
    "    output = keras.layers.Flatten(name='flatten')(output)\n",
    "    output = keras.layers.Dense(1000, activation='relu', name='fc2')(output)\n",
    "    output = keras.layers.Dense(1, activation='sigmoid', name='predictions')(output)\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = keras.Model(\n",
    "        inputs=input_layer, \n",
    "        outputs=output\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efbef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_34 = build_resnet(input_shape=(224, 224, 3), is_50=False)\n",
    "resnet_34.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9703c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_50 = build_resnet(input_shape=(224, 224, 3), is_50=True)\n",
    "resnet_50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72c5f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164bf7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = apply_normalize_on_dataset(ds_train, batch_size=BATCH_SIZE)\n",
    "ds_test = apply_normalize_on_dataset(ds_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfee09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79caf5a",
   "metadata": {},
   "source": [
    "## 3. Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53d4b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_34.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, clipnorm=1.),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_34 = resnet_34.fit(\n",
    "    ds_train,\n",
    "    steps_per_epoch=int(ds_info.splits['train[:80%]'].num_examples/BATCH_SIZE),\n",
    "    validation_steps=int(ds_info.splits['train[80%:]'].num_examples/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa3a6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_50.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, clipnorm=1.),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_50 = resnet_50.fit(\n",
    "    ds_train,\n",
    "    steps_per_epoch=int(ds_info.splits['train[:80%]'].num_examples/BATCH_SIZE),\n",
    "    validation_steps=int(ds_info.splits['train[80%:]'].num_examples/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e44b7d",
   "metadata": {},
   "source": [
    "## 4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dd4678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history_16.history['loss'], 'r')\n",
    "plt.plot(history_19.history['loss'], 'b')\n",
    "plt.title('Model training loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['vgg_16', 'vgg_19'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130ab8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_16.history['val_accuracy'], 'r')\n",
    "plt.plot(history_19.history['val_accuracy'], 'b')\n",
    "plt.title('Model validation accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['vgg_16', 'vgg_19'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
