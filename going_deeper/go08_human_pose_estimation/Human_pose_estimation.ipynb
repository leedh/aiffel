{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16f32ba4",
   "metadata": {},
   "source": [
    "# 프로젝트: 행동 스티커 만들기\n",
    "|평가문항|상세기준|\n",
    "|:---|:---|\n",
    "|1. tfrecord를 활용한 데이터셋 구성과 전처리를 통해 프로젝트 베이스라인 구성을 확인하였다.|MPII 데이터셋을 기반으로 1epoch에 30분 이내에 학습가능한 베이스라인을 구축하였다.\n",
    "|2. simplebaseline 모델을 정상적으로 구현하였다.|simplebaseline 모델을 구현하여 실습코드의 모델을 대체하여 정상적으로 학습이 진행되었다.\n",
    "|3. Hourglass 모델과 simplebaseline 모델을 비교분석한 결과를 체계적으로 정리하였다.|두 모델의 pose estimation 테스트결과 이미지 및 학습진행상황 등을 체계적으로 비교분석하였다.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ebf4e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec  6 09:27:49 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.199.02   Driver Version: 470.199.02   CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   35C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26751367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주의! ray를 tensorflow보다 먼저 import하면 오류가 발생할 수 있습니다\n",
    "import io, json, os, math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Add, Concatenate, Lambda\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, MaxPool2D\n",
    "from tensorflow.keras.layers import UpSampling2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import ray\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PROJECT_PATH = os.getenv('HOME') + '/aiffel/mpii'\n",
    "IMAGE_PATH = os.path.join(PROJECT_PATH, 'images')\n",
    "MODEL_PATH = os.path.join(PROJECT_PATH, 'models')\n",
    "TFRECORD_PATH = os.path.join(PROJECT_PATH, 'tfrecords_mpii')\n",
    "TRAIN_JSON = os.path.join(PROJECT_PATH, 'mpii_human_pose_v1_u12_2', 'train.json')\n",
    "VALID_JSON = os.path.join(PROJECT_PATH, 'mpii_human_pose_v1_u12_2', 'validation.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5bc2b4",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79f9fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(TRAIN_JSON) as train_json:\n",
    "#     train_annos = json.load(train_json)\n",
    "#     json_formatted_str = json.dumps(train_annos[0], indent=2)\n",
    "#     print(json_formatted_str)\n",
    "\n",
    "# def parse_one_annotation(anno, image_dir):\n",
    "#     filename = anno['image']\n",
    "#     joints = anno['joints']\n",
    "#     joints_visibility = anno['joints_vis']\n",
    "#     annotation = {\n",
    "#         'filename': filename,\n",
    "#         'filepath': os.path.join(image_dir, filename),\n",
    "#         'joints_visibility': joints_visibility,\n",
    "#         'joints': joints,\n",
    "#         'center': anno['center'],\n",
    "#         'scale' : anno['scale']\n",
    "#     }\n",
    "#     return annotation\n",
    "\n",
    "# with open(TRAIN_JSON) as train_json:\n",
    "#     train_annos = json.load(train_json)\n",
    "#     test = parse_one_annotation(train_annos[0], IMAGE_PATH)\n",
    "#     print(test)\n",
    "    \n",
    "# # TFRecord 는 tf.train.Example들의 합으로 이루어지므로 하나의 annotation을 하나의 tf.train.Example로 만들어 주는 함수\n",
    "# def generate_tfexample(anno):\n",
    "\n",
    "#     # byte 인코딩을 위한 함수\n",
    "#     def _bytes_feature(value):\n",
    "#         if isinstance(value, type(tf.constant(0))):\n",
    "#             value = value.numpy()\n",
    "#         return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "#     filename = anno['filename']\n",
    "#     filepath = anno['filepath']\n",
    "#     with open(filepath, 'rb') as image_file:\n",
    "#         content = image_file.read()\n",
    "\n",
    "#     image = Image.open(filepath)\n",
    "#     if image.format != 'JPEG' or image.mode != 'RGB':\n",
    "#         image_rgb = image.convert('RGB')\n",
    "#         with io.BytesIO() as output:\n",
    "#             image_rgb.save(output, format=\"JPEG\", quality=95)\n",
    "#             content = output.getvalue()\n",
    "\n",
    "#     width, height = image.size\n",
    "#     depth = 3\n",
    "\n",
    "#     c_x = int(anno['center'][0])\n",
    "#     c_y = int(anno['center'][1])\n",
    "#     scale = anno['scale']\n",
    "\n",
    "#     x = [\n",
    "#         int(joint[0]) if joint[0] >= 0 else int(joint[0]) \n",
    "#         for joint in anno['joints']\n",
    "#     ]\n",
    "#     y = [\n",
    "#         int(joint[1]) if joint[1] >= 0 else int(joint[0]) \n",
    "#         for joint in anno['joints']\n",
    "#     ]\n",
    "\n",
    "#     v = [0 if joint_v == 0 else 2 for joint_v in anno['joints_visibility']]\n",
    "\n",
    "#     feature = {\n",
    "#         'image/height':\n",
    "#         tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
    "#         'image/width':\n",
    "#         tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
    "#         'image/depth':\n",
    "#         tf.train.Feature(int64_list=tf.train.Int64List(value=[depth])),\n",
    "#         'image/object/parts/x':\n",
    "#         tf.train.Feature(int64_list=tf.train.Int64List(value=x)),\n",
    "#         'image/object/parts/y':\n",
    "#         tf.train.Feature(int64_list=tf.train.Int64List(value=y)),\n",
    "#         'image/object/center/x': \n",
    "#         tf.train.Feature(int64_list=tf.train.Int64List(value=[c_x])),\n",
    "#         'image/object/center/y': \n",
    "#         tf.train.Feature(int64_list=tf.train.Int64List(value=[c_y])),\n",
    "#         'image/object/scale':\n",
    "#         tf.train.Feature(float_list=tf.train.FloatList(value=[scale])),\n",
    "#         'image/object/parts/v':\n",
    "#         tf.train.Feature(int64_list=tf.train.Int64List(value=v)),\n",
    "#         'image/encoded':\n",
    "#         _bytes_feature(content),\n",
    "#         'image/filename':\n",
    "#         _bytes_feature(filename.encode())\n",
    "#     }\n",
    "\n",
    "#     return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "\n",
    "# # 우선 얼마나 많은 TFRecord를 만들지 결정할 함수\n",
    "# def chunkify(l, n):\n",
    "#     size = len(l) // n\n",
    "#     start = 0\n",
    "#     results = []\n",
    "#     for i in range(n):\n",
    "#         results.append(l[start:start + size])\n",
    "#         start += size\n",
    "#     return results\n",
    "\n",
    "\n",
    "# # chunkify함수를 테스트\n",
    "# test_chunks = chunkify([0] * 1000, 64)\n",
    "# print(test_chunks)\n",
    "# print(len(test_chunks))\n",
    "# print(len(test_chunks[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338bca26",
   "metadata": {},
   "source": [
    "[Ray](https://www.ray.io/)는 병렬 처리를 위한 라이브러리인데요. 파이썬에서 기본적으로 제공하는 multiprocessing 패키지보다 편하게 다양한 환경에서 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc87e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 하나의 chunk를 TFRecord로 만들어 줄 함수\n",
    "# @ray.remote\n",
    "# def build_single_tfrecord(chunk, path):\n",
    "#     print('start to build tf records for ' + path)\n",
    "\n",
    "#     with tf.io.TFRecordWriter(path) as writer:\n",
    "#         for anno in chunk:\n",
    "#             tf_example = generate_tfexample(anno)\n",
    "#             writer.write(tf_example.SerializeToString())\n",
    "\n",
    "#     print('finished building tf records for ' + path)\n",
    "    \n",
    "# # 전체 데이터를 적당한 수의 TFRecord 파일로 만들어주는 함수\n",
    "# def build_tf_records(annotations, total_shards, split):\n",
    "#     chunks = chunkify(annotations, total_shards)\n",
    "#     futures = [\n",
    "#         build_single_tfrecord.remote(\n",
    "#             chunk, '{}/{}_{}_of_{}.tfrecords'.format(\n",
    "#                 TFRECORD_PATH,\n",
    "#                 split,\n",
    "#                 str(i + 1).zfill(4),\n",
    "#                 str(total_shards).zfill(4),\n",
    "#             )) for i, chunk in enumerate(chunks)\n",
    "#     ]\n",
    "#     ray.get(futures)\n",
    "    \n",
    "# # 데이터를 TFRecord로 만들어 줍니다. train 데이터는 64개로, val 데이터는 8개의 파일로 만듭니다. \n",
    "# num_train_shards = 64\n",
    "# num_val_shards = 8\n",
    "\n",
    "# ray.init()\n",
    "\n",
    "# print('Start to parse annotations.')\n",
    "# if not os.path.exists(TFRECORD_PATH):\n",
    "#     os.makedirs(TFRECORD_PATH)\n",
    "\n",
    "# with open(TRAIN_JSON) as train_json:\n",
    "#     train_annos = json.load(train_json)\n",
    "#     train_annotations = [\n",
    "#         parse_one_annotation(anno, IMAGE_PATH)\n",
    "#         for anno in train_annos\n",
    "#     ]\n",
    "#     print('First train annotation: ', train_annotations[0])\n",
    "\n",
    "# with open(VALID_JSON) as val_json:\n",
    "#     val_annos = json.load(val_json)\n",
    "#     val_annotations = [\n",
    "#         parse_one_annotation(anno, IMAGE_PATH) \n",
    "#         for anno in val_annos\n",
    "#     ]\n",
    "#     print('First val annotation: ', val_annotations[0])\n",
    "    \n",
    "# print('Start to build TF Records.')\n",
    "# build_tf_records(train_annotations, num_train_shards, 'train')\n",
    "# build_tf_records(val_annotations, num_val_shards, 'val')\n",
    "\n",
    "# print('Successfully wrote {} annotations to TF Records.'.format(\n",
    "#     len(train_annotations) + len(val_annotations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfe8cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TFRecord로 저장된 데이터를 모델 학습에 필요한 데이터로 바꿔줄 함수\n",
    "# # 주의할 점은 TFRecord가 직렬화된 데이터이기 때문에 만들 때 데이터 순서와 읽어올 때 데이터 순서가 같아야 한다는 점이에요. 데이터의 형식도 동일하게 맞춰 줘야 합니다.\n",
    "# def parse_tfexample(example):\n",
    "#     image_feature_description = {\n",
    "#         'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "#         'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
    "#         'image/depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "#         'image/object/parts/x': tf.io.VarLenFeature(tf.int64),\n",
    "#         'image/object/parts/y': tf.io.VarLenFeature(tf.int64),\n",
    "#         'image/object/parts/v': tf.io.VarLenFeature(tf.int64),\n",
    "#         'image/object/center/x': tf.io.FixedLenFeature([], tf.int64),\n",
    "#         'image/object/center/y': tf.io.FixedLenFeature([], tf.int64),\n",
    "#         'image/object/scale': tf.io.FixedLenFeature([], tf.float32),\n",
    "#         'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "#         'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
    "#     }\n",
    "#     return tf.io.parse_single_example(example, image_feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902ecc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 얻은 image 와 label 을 이용해서 적절한 학습 형태로 변환합니다. 이미지를 그대로 사용하지 않고 적당히 정사각형으로 crop하여 사용합니다.\n",
    "# def crop_roi(image, features, margin=0.2):\n",
    "#     img_shape = tf.shape(image)\n",
    "#     img_height = img_shape[0]\n",
    "#     img_width = img_shape[1]\n",
    "#     img_depth = img_shape[2]\n",
    "\n",
    "#     keypoint_x = tf.cast(tf.sparse.to_dense(features['image/object/parts/x']), dtype=tf.int32)\n",
    "#     keypoint_y = tf.cast(tf.sparse.to_dense(features['image/object/parts/y']), dtype=tf.int32)\n",
    "#     center_x = features['image/object/center/x']\n",
    "#     center_y = features['image/object/center/y']\n",
    "#     body_height = features['image/object/scale'] * 200.0\n",
    "\n",
    "#     # keypoint 중 유효한값(visible = 1) 만 사용합니다.\n",
    "#     masked_keypoint_x = tf.boolean_mask(keypoint_x, keypoint_x > 0)\n",
    "#     masked_keypoint_y = tf.boolean_mask(keypoint_y, keypoint_y > 0)\n",
    "\n",
    "#     # min, max 값을 찾습니다.\n",
    "#     keypoint_xmin = tf.reduce_min(masked_keypoint_x)\n",
    "#     keypoint_xmax = tf.reduce_max(masked_keypoint_x)\n",
    "#     keypoint_ymin = tf.reduce_min(masked_keypoint_y)\n",
    "#     keypoint_ymax = tf.reduce_max(masked_keypoint_y)\n",
    "\n",
    "#     # 높이 값을 이용해서 x, y 위치를 재조정 합니다. 박스를 정사각형으로 사용하기 위해 아래와 같이 사용합니다.\n",
    "#     xmin = keypoint_xmin - tf.cast(body_height * margin, dtype=tf.int32)\n",
    "#     xmax = keypoint_xmax + tf.cast(body_height * margin, dtype=tf.int32)\n",
    "#     ymin = keypoint_ymin - tf.cast(body_height * margin, dtype=tf.int32)\n",
    "#     ymax = keypoint_ymax + tf.cast(body_height * margin, dtype=tf.int32)\n",
    "\n",
    "#     # 이미지 크기를 벗어나는 점을 재조정 해줍니다.\n",
    "#     effective_xmin = xmin if xmin > 0 else 0\n",
    "#     effective_ymin = ymin if ymin > 0 else 0\n",
    "#     effective_xmax = xmax if xmax < img_width else img_width\n",
    "#     effective_ymax = ymax if ymax < img_height else img_height\n",
    "#     effective_height = effective_ymax - effective_ymin\n",
    "#     effective_width = effective_xmax - effective_xmin\n",
    "\n",
    "#     image = image[effective_ymin:effective_ymax, effective_xmin:effective_xmax, :]\n",
    "#     new_shape = tf.shape(image)\n",
    "#     new_height = new_shape[0]\n",
    "#     new_width = new_shape[1]\n",
    "\n",
    "#     effective_keypoint_x = (keypoint_x - effective_xmin) / new_width\n",
    "#     effective_keypoint_y = (keypoint_y - effective_ymin) / new_height\n",
    "\n",
    "#     return image, effective_keypoint_x, effective_keypoint_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3892c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_2d_guassian(height, width, y0, x0, visibility=2, sigma=1, scale=12):\n",
    "    heatmap = tf.zeros((height, width))\n",
    "\n",
    "    xmin = x0 - 3 * sigma\n",
    "    ymin = y0 - 3 * sigma\n",
    "    xmax = x0 + 3 * sigma\n",
    "    ymax = y0 + 3 * sigma\n",
    "    \n",
    "    if xmin >= width or ymin >= height or xmax < 0 or ymax < 0 or visibility == 0:\n",
    "        return heatmap\n",
    "\n",
    "    size = 6 * sigma + 1\n",
    "    x, y = tf.meshgrid(tf.range(0, 6 * sigma + 1, 1), tf.range(0, 6 * sigma + 1, 1), indexing='xy')\n",
    "\n",
    "    center_x = size // 2\n",
    "    center_y = size // 2\n",
    "\n",
    "    gaussian_patch = tf.cast(tf.math.exp(\n",
    "        -(tf.math.square(x - center_x) + tf.math.square(y - center_y)) / (tf.math.square(sigma) * 2)) * scale,\n",
    "                             dtype=tf.float32)\n",
    "\n",
    "    patch_xmin = tf.math.maximum(0, -xmin)\n",
    "    patch_ymin = tf.math.maximum(0, -ymin)\n",
    "    patch_xmax = tf.math.minimum(xmax, width) - xmin\n",
    "    patch_ymax = tf.math.minimum(ymax, height) - ymin\n",
    "\n",
    "    heatmap_xmin = tf.math.maximum(0, xmin)\n",
    "    heatmap_ymin = tf.math.maximum(0, ymin)\n",
    "    heatmap_xmax = tf.math.minimum(xmax, width)\n",
    "    heatmap_ymax = tf.math.minimum(ymax, height)\n",
    "\n",
    "    indices = tf.TensorArray(tf.int32, 1, dynamic_size=True)\n",
    "    updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for j in tf.range(patch_ymin, patch_ymax):\n",
    "        for i in tf.range(patch_xmin, patch_xmax):\n",
    "            indices = indices.write(count, [heatmap_ymin + j, heatmap_xmin + i])\n",
    "            updates = updates.write(count, gaussian_patch[j][i])\n",
    "            count += 1\n",
    "\n",
    "    heatmap = tf.tensor_scatter_nd_update(heatmap, indices.stack(), updates.stack())\n",
    "\n",
    "    return heatmap\n",
    "\n",
    "def make_heatmaps(features, keypoint_x, keypoint_y, heatmap_shape):\n",
    "    v = tf.cast(tf.sparse.to_dense(features['image/object/parts/v']), dtype=tf.float32)\n",
    "    x = tf.cast(tf.math.round(keypoint_x * heatmap_shape[0]), dtype=tf.int32)\n",
    "    y = tf.cast(tf.math.round(keypoint_y * heatmap_shape[1]), dtype=tf.int32)\n",
    "\n",
    "    num_heatmap = heatmap_shape[2]\n",
    "    heatmap_array = tf.TensorArray(tf.float32, 16)\n",
    "\n",
    "    for i in range(num_heatmap):\n",
    "        gaussian = self.generate_2d_guassian(heatmap_shape[1], heatmap_shape[0], y[i], x[i], v[i])\n",
    "        heatmap_array = heatmap_array.write(i, gaussian)\n",
    "\n",
    "    heatmaps = heatmap_array.stack()\n",
    "    heatmaps = tf.transpose(heatmaps, perm=[1, 2, 0])  # change to (64, 64, 16)\n",
    "\n",
    "    return heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3aa99f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor(object):\n",
    "    def __init__(self,\n",
    "                 image_shape=(256, 256, 3),\n",
    "                 heatmap_shape=(64, 64, 16),\n",
    "                 is_train=False):\n",
    "        self.is_train = is_train\n",
    "        self.image_shape = image_shape\n",
    "        self.heatmap_shape = heatmap_shape\n",
    "\n",
    "    def __call__(self, example):\n",
    "        features = self.parse_tfexample(example)\n",
    "        image = tf.io.decode_jpeg(features['image/encoded'])\n",
    "\n",
    "        if self.is_train:\n",
    "            random_margin = tf.random.uniform([1], 0.1, 0.3)[0]\n",
    "            image, keypoint_x, keypoint_y = self.crop_roi(image, features, margin=random_margin)\n",
    "            image = tf.image.resize(image, self.image_shape[0:2])\n",
    "        else:\n",
    "            image, keypoint_x, keypoint_y = self.crop_roi(image, features)\n",
    "            image = tf.image.resize(image, self.image_shape[0:2])\n",
    "\n",
    "        image = tf.cast(image, tf.float32) / 127.5 - 1\n",
    "        heatmaps = self.make_heatmaps(features, keypoint_x, keypoint_y, self.heatmap_shape)\n",
    "\n",
    "        return image, heatmaps\n",
    "\n",
    "        \n",
    "    def crop_roi(self, image, features, margin=0.2):\n",
    "        img_shape = tf.shape(image)\n",
    "        img_height = img_shape[0]\n",
    "        img_width = img_shape[1]\n",
    "        img_depth = img_shape[2]\n",
    "\n",
    "        keypoint_x = tf.cast(tf.sparse.to_dense(features['image/object/parts/x']), dtype=tf.int32)\n",
    "        keypoint_y = tf.cast(tf.sparse.to_dense(features['image/object/parts/y']), dtype=tf.int32)\n",
    "        center_x = features['image/object/center/x']\n",
    "        center_y = features['image/object/center/y']\n",
    "        body_height = features['image/object/scale'] * 200.0\n",
    "        \n",
    "        masked_keypoint_x = tf.boolean_mask(keypoint_x, keypoint_x > 0)\n",
    "        masked_keypoint_y = tf.boolean_mask(keypoint_y, keypoint_y > 0)\n",
    "        \n",
    "        keypoint_xmin = tf.reduce_min(masked_keypoint_x)\n",
    "        keypoint_xmax = tf.reduce_max(masked_keypoint_x)\n",
    "        keypoint_ymin = tf.reduce_min(masked_keypoint_y)\n",
    "        keypoint_ymax = tf.reduce_max(masked_keypoint_y)\n",
    "        \n",
    "        xmin = keypoint_xmin - tf.cast(body_height * margin, dtype=tf.int32)\n",
    "        xmax = keypoint_xmax + tf.cast(body_height * margin, dtype=tf.int32)\n",
    "        ymin = keypoint_ymin - tf.cast(body_height * margin, dtype=tf.int32)\n",
    "        ymax = keypoint_ymax + tf.cast(body_height * margin, dtype=tf.int32)\n",
    "        \n",
    "        effective_xmin = xmin if xmin > 0 else 0\n",
    "        effective_ymin = ymin if ymin > 0 else 0\n",
    "        effective_xmax = xmax if xmax < img_width else img_width\n",
    "        effective_ymax = ymax if ymax < img_height else img_height\n",
    "        effective_height = effective_ymax - effective_ymin\n",
    "        effective_width = effective_xmax - effective_xmin\n",
    "\n",
    "        image = image[effective_ymin:effective_ymax, effective_xmin:effective_xmax, :]\n",
    "        new_shape = tf.shape(image)\n",
    "        new_height = new_shape[0]\n",
    "        new_width = new_shape[1]\n",
    "        \n",
    "        effective_keypoint_x = (keypoint_x - effective_xmin) / new_width\n",
    "        effective_keypoint_y = (keypoint_y - effective_ymin) / new_height\n",
    "        \n",
    "        return image, effective_keypoint_x, effective_keypoint_y\n",
    "        \n",
    "    \n",
    "    def generate_2d_guassian(self, height, width, y0, x0, visibility=2, sigma=1, scale=12):\n",
    "        \n",
    "        heatmap = tf.zeros((height, width))\n",
    "\n",
    "        xmin = x0 - 3 * sigma\n",
    "        ymin = y0 - 3 * sigma\n",
    "        xmax = x0 + 3 * sigma\n",
    "        ymax = y0 + 3 * sigma\n",
    "\n",
    "        if xmin >= width or ymin >= height or xmax < 0 or ymax <0 or visibility == 0:\n",
    "            return heatmap\n",
    "\n",
    "        size = 6 * sigma + 1\n",
    "        x, y = tf.meshgrid(tf.range(0, 6*sigma+1, 1), tf.range(0, 6*sigma+1, 1), indexing='xy')\n",
    "\n",
    "        center_x = size // 2\n",
    "        center_y = size // 2\n",
    "\n",
    "        gaussian_patch = tf.cast(tf.math.exp(-(tf.square(x - center_x) + tf.math.square(y - center_y)) / (tf.math.square(sigma) * 2)) * scale, dtype=tf.float32)\n",
    "\n",
    "        patch_xmin = tf.math.maximum(0, -xmin)\n",
    "        patch_ymin = tf.math.maximum(0, -ymin)\n",
    "        patch_xmax = tf.math.minimum(xmax, width) - xmin\n",
    "        patch_ymax = tf.math.minimum(ymax, height) - ymin\n",
    "\n",
    "        heatmap_xmin = tf.math.maximum(0, xmin)\n",
    "        heatmap_ymin = tf.math.maximum(0, ymin)\n",
    "        heatmap_xmax = tf.math.minimum(xmax, width)\n",
    "        heatmap_ymax = tf.math.minimum(ymax, height)\n",
    "\n",
    "        indices = tf.TensorArray(tf.int32, 1, dynamic_size=True)\n",
    "        updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for j in tf.range(patch_ymin, patch_ymax):\n",
    "            for i in tf.range(patch_xmin, patch_xmax):\n",
    "                indices = indices.write(count, [heatmap_ymin+j, heatmap_xmin+i])\n",
    "                updates = updates.write(count, gaussian_patch[j][i])\n",
    "                count += 1\n",
    "                \n",
    "        heatmap = tf.tensor_scatter_nd_update(heatmap, indices.stack(), updates.stack())\n",
    "\n",
    "        return heatmap\n",
    "\n",
    "\n",
    "    def make_heatmaps(self, features, keypoint_x, keypoint_y, heatmap_shape):\n",
    "        v = tf.cast(tf.sparse.to_dense(features['image/object/parts/v']), dtype=tf.float32)\n",
    "        x = tf.cast(tf.math.round(keypoint_x * heatmap_shape[0]), dtype=tf.int32)\n",
    "        y = tf.cast(tf.math.round(keypoint_y * heatmap_shape[1]), dtype=tf.int32)\n",
    "        \n",
    "        num_heatmap = heatmap_shape[2]\n",
    "        heatmap_array = tf.TensorArray(tf.float32, 16)\n",
    "\n",
    "        for i in range(num_heatmap):\n",
    "            gaussian = self.generate_2d_guassian(heatmap_shape[1], heatmap_shape[0], y[i], x[i], v[i])\n",
    "            heatmap_array = heatmap_array.write(i, gaussian)\n",
    "        \n",
    "        heatmaps = heatmap_array.stack()\n",
    "        heatmaps = tf.transpose(heatmaps, perm=[1, 2, 0]) # change to (64, 64, 16)\n",
    "        \n",
    "        return heatmaps\n",
    "\n",
    "    def parse_tfexample(self, example):\n",
    "        image_feature_description = {\n",
    "            'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/object/parts/x': tf.io.VarLenFeature(tf.int64),\n",
    "            'image/object/parts/y': tf.io.VarLenFeature(tf.int64),\n",
    "            'image/object/parts/v': tf.io.VarLenFeature(tf.int64),\n",
    "            'image/object/center/x': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/object/center/y': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/object/scale': tf.io.FixedLenFeature([], tf.float32),\n",
    "            'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "            'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
    "        }\n",
    "        return tf.io.parse_single_example(example,\n",
    "                                          image_feature_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4abc3e",
   "metadata": {},
   "source": [
    "## 모델 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd55297",
   "metadata": {},
   "source": [
    "### (1) StackedHourglass Network\n",
    "![hourglass](https://d3s0tskafalll9.cloudfront.net/media/images/GC-10-P-4.max-800x600.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6f30344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BottleneckBlock(inputs, filters, strides=1, downsample=False, name=None):\n",
    "    identity = inputs\n",
    "    if downsample:\n",
    "        identity = Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=1,\n",
    "            strides=strides,\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal')(inputs)\n",
    "\n",
    "    x = BatchNormalization(momentum=0.9)(inputs)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(\n",
    "        filters=filters // 2,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(x)\n",
    "\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(\n",
    "        filters=filters // 2,\n",
    "        kernel_size=3,\n",
    "        strides=strides,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(x)\n",
    "\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(x)\n",
    "\n",
    "    x = Add()([identity, x])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03a0a789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재귀함수를 이용해서 모델 구조 간단히 하기\n",
    "def HourglassModule(inputs, order, filters, num_residual):\n",
    "    \n",
    "    up1 = BottleneckBlock(inputs, filters, downsample=False)\n",
    "    for i in range(num_residual):\n",
    "        up1 = BottleneckBlock(up1, filters, downsample=False)\n",
    "\n",
    "    low1 = MaxPool2D(pool_size=2, strides=2)(inputs)\n",
    "    for i in range(num_residual):\n",
    "        low1 = BottleneckBlock(low1, filters, downsample=False)\n",
    "\n",
    "    low2 = low1\n",
    "    if order > 1:\n",
    "        low2 = HourglassModule(low1, order - 1, filters, num_residual)\n",
    "    else:\n",
    "        for i in range(num_residual):\n",
    "            low2 = BottleneckBlock(low2, filters, downsample=False)\n",
    "\n",
    "    low3 = low2\n",
    "    for i in range(num_residual):\n",
    "        low3 = BottleneckBlock(low3, filters, downsample=False)\n",
    "\n",
    "    up2 = UpSampling2D(size=2)(low3)\n",
    "\n",
    "    return up2 + up1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8f46df",
   "metadata": {},
   "source": [
    "hourglass 모듈을 여러 층으로 쌓은 것이 stacked hourglass network 인데요, 모델이 깊어지는 만큼 학습이 어려워 **intermediate loss (auxilary loss)** 를 추가해야 하는 것을 논문에서 언급했습니다.\n",
    "![auxilary loss](https://d3s0tskafalll9.cloudfront.net/media/original_images/GC-10-P-5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ed9dd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearLayer(inputs, filters):\n",
    "    x = Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(inputs)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c8664c",
   "metadata": {},
   "source": [
    "만든 hourglass 를 여러 층으로 쌓으면 stacked hourglass 가 됩니다. stacked 되는 hourglass 층 사이사이에 LinearLayer 를 삽입하고 중간 loss 를 계산해 줍니다.\n",
    "![stacked hourglass](https://d3s0tskafalll9.cloudfront.net/media/images/GC-10-P-6.max-800x600.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f612c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def StackedHourglassNetwork(\n",
    "        input_shape=(256, 256, 3), \n",
    "        num_stack=4, \n",
    "        num_residual=1,\n",
    "        num_heatmap=16):\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=7,\n",
    "        strides=2,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(inputs)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BottleneckBlock(x, 128, downsample=True)\n",
    "    x = MaxPool2D(pool_size=2, strides=2)(x)\n",
    "    x = BottleneckBlock(x, 128, downsample=False)\n",
    "    x = BottleneckBlock(x, 256, downsample=True)\n",
    "\n",
    "    ys = []\n",
    "    for i in range(num_stack):\n",
    "        x = HourglassModule(x, order=4, filters=256, num_residual=num_residual)\n",
    "        for i in range(num_residual):\n",
    "            x = BottleneckBlock(x, 256, downsample=False)\n",
    "\n",
    "        x = LinearLayer(x, 256)\n",
    "\n",
    "        y = Conv2D(\n",
    "            filters=num_heatmap,\n",
    "            kernel_size=1,\n",
    "            strides=1,\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal')(x)\n",
    "        ys.append(y)\n",
    "\n",
    "        if i < num_stack - 1:\n",
    "            y_intermediate_1 = Conv2D(filters=256, kernel_size=1, strides=1)(x)\n",
    "            y_intermediate_2 = Conv2D(filters=256, kernel_size=1, strides=1)(y)\n",
    "            x = Add()([y_intermediate_1, y_intermediate_2])\n",
    "\n",
    "    return tf.keras.Model(inputs, ys, name='stacked_hourglass')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8843ba0",
   "metadata": {},
   "source": [
    "### (2) Simplebaseline 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "908ffd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = tf.keras.applications.resnet.ResNet50(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53a7f3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_deconv_layer(num_deconv_layers):\n",
    "    seq_model = tf.keras.models.Sequential()\n",
    "    for i in range(num_deconv_layers):\n",
    "        seq_model.add(tf.keras.layers.Conv2DTranspose(256, kernel_size=(4,4), strides=(2,2), padding='same'))\n",
    "        seq_model.add(tf.keras.layers.BatchNormalization())\n",
    "        seq_model.add(tf.keras.layers.ReLU())\n",
    "    return seq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3de3ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "upconv = _make_deconv_layer(3)\n",
    "\n",
    "final_layer = tf.keras.layers.Conv2D(17, kernel_size=(1,1), padding='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e5fd0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Simplebaseline(input_shape=(256, 256, 3)):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    x = resnet(inputs)\n",
    "    x = upconv(x)\n",
    "    out = final_layer(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, out, name='simple_baseline')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385000fd",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a053a006",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 modelname,\n",
    "                 epochs,\n",
    "                 global_batch_size,\n",
    "                 strategy,\n",
    "                 initial_learning_rate):\n",
    "        self.model = model\n",
    "        self.modelname = modelname\n",
    "        self.epochs = epochs\n",
    "        self.strategy = strategy\n",
    "        self.global_batch_size = global_batch_size\n",
    "        self.loss_object = tf.keras.losses.MeanSquaredError(\n",
    "            reduction=tf.keras.losses.Reduction.NONE)\n",
    "        self.optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=initial_learning_rate)\n",
    "\n",
    "        self.current_learning_rate = initial_learning_rate\n",
    "        self.last_val_loss = math.inf\n",
    "        self.lowest_val_loss = math.inf\n",
    "        self.patience_count = 0\n",
    "        self.max_patience = 10\n",
    "        self.best_model = None\n",
    "\n",
    "    def lr_decay(self):\n",
    "        if self.patience_count >= self.max_patience:\n",
    "            self.current_learning_rate /= 10.0\n",
    "            self.patience_count = 0\n",
    "        elif self.last_val_loss == self.lowest_val_loss:\n",
    "            self.patience_count = 0\n",
    "        self.patience_count += 1\n",
    "\n",
    "        self.optimizer.learning_rate = self.current_learning_rate\n",
    "\n",
    "    def lr_decay_step(self, epoch):\n",
    "        if epoch == 25 or epoch == 50 or epoch == 75:\n",
    "            self.current_learning_rate /= 10.0\n",
    "        self.optimizer.learning_rate = self.current_learning_rate\n",
    "\n",
    "    def compute_loss(self, labels, outputs):\n",
    "        loss = 0\n",
    "        for output in outputs:\n",
    "            weights = tf.cast(labels > 0, dtype=tf.float32) * 81 + 1\n",
    "            loss += tf.math.reduce_mean(\n",
    "                tf.math.square(labels - output) * weights) * (\n",
    "                    1. / self.global_batch_size)\n",
    "        return loss\n",
    "    \n",
    "    def compute_loss_2(self, labels, outputs):\n",
    "        loss = 0\n",
    "        weights = tf.cast(labels > 0, dtype=tf.float32) * 81 + 1\n",
    "        loss += tf.math.reduce_mean(\n",
    "            tf.math.square(labels - outputs) * weights) * (\n",
    "                1. / self.global_batch_size)\n",
    "        return loss\n",
    "\n",
    "    def train_step(self, inputs):\n",
    "        images, labels = inputs\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = self.model(images, training=True)\n",
    "            \n",
    "            if self.modelname == 'stacked_hourglass':\n",
    "                loss = self.compute_loss(labels, outputs)\n",
    "            elif self.modelname == 'simple_baseline':\n",
    "                loss = self.compute_loss_2(labels, outputs)\n",
    "\n",
    "        grads = tape.gradient(\n",
    "            target=loss, sources=self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads, self.model.trainable_variables))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def val_step(self, inputs):\n",
    "        images, labels = inputs\n",
    "        outputs = self.model(images, training=False)\n",
    "        \n",
    "        if self.modelname == 'stacked_hourglass':\n",
    "            loss = self.compute_loss(labels, outputs)\n",
    "        elif self.modelname == 'simple_baseline':\n",
    "            loss = self.compute_loss_2(labels, outputs)\n",
    "            \n",
    "        return loss\n",
    "\n",
    "    def run(self, train_dist_dataset, val_dist_dataset):\n",
    "        @tf.function\n",
    "        def distributed_train_epoch(dataset):\n",
    "            tf.print('Start distributed traininng...')\n",
    "            total_loss = 0.0\n",
    "            num_train_batches = 0.0\n",
    "            for one_batch in dataset:\n",
    "                per_replica_loss = self.strategy.run(\n",
    "                    self.train_step, args=(one_batch, ))\n",
    "                batch_loss = self.strategy.reduce(\n",
    "                    tf.distribute.ReduceOp.SUM, per_replica_loss, axis=None)\n",
    "                total_loss += batch_loss\n",
    "                num_train_batches += 1\n",
    "                tf.print('Trained batch', num_train_batches, 'batch loss',\n",
    "                         batch_loss, 'epoch total loss', total_loss / num_train_batches)\n",
    "            return total_loss, num_train_batches\n",
    "\n",
    "        @tf.function\n",
    "        def distributed_val_epoch(dataset):\n",
    "            total_loss = 0.0\n",
    "            num_val_batches = 0.0\n",
    "            for one_batch in dataset:\n",
    "                per_replica_loss = self.strategy.run(\n",
    "                    self.val_step, args=(one_batch, ))\n",
    "                num_val_batches += 1\n",
    "                batch_loss = self.strategy.reduce(\n",
    "                    tf.distribute.ReduceOp.SUM, per_replica_loss, axis=None)\n",
    "                tf.print('Validated batch', num_val_batches, 'batch loss',\n",
    "                         batch_loss)\n",
    "                if not tf.math.is_nan(batch_loss):\n",
    "                    # TODO: Find out why the last validation batch loss become NaN\n",
    "                    total_loss += batch_loss\n",
    "                else:\n",
    "                    num_val_batches -= 1\n",
    "\n",
    "            return total_loss, num_val_batches\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            self.lr_decay()\n",
    "            print('Start epoch {} with learning rate {}'.format(\n",
    "                epoch, self.current_learning_rate))\n",
    "\n",
    "            train_total_loss, num_train_batches = distributed_train_epoch(\n",
    "                train_dist_dataset)\n",
    "            train_loss = train_total_loss / num_train_batches\n",
    "            print('Epoch {} train loss {}'.format(epoch, train_loss))\n",
    "\n",
    "            val_total_loss, num_val_batches = distributed_val_epoch(\n",
    "                val_dist_dataset)\n",
    "            val_loss = val_total_loss / num_val_batches\n",
    "            print('Epoch {} val loss {}'.format(epoch, val_loss))\n",
    "\n",
    "            # save model when reach a new lowest validation loss\n",
    "            if val_loss < self.lowest_val_loss:\n",
    "                self.save_model(epoch, val_loss)\n",
    "                self.lowest_val_loss = val_loss\n",
    "            self.last_val_loss = val_loss\n",
    "\n",
    "        return self.best_model\n",
    "\n",
    "    def save_model(self, epoch, loss):\n",
    "        model_name = MODEL_PATH + '/model-epoch-{}-loss-{:.4f}.h5'.format(epoch, loss)\n",
    "        self.model.save_weights(model_name)\n",
    "        self.best_model = model_name\n",
    "        print(\"Model {} saved.\".format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "625c6f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 만드는 함수\n",
    "# TFRecord 파일이 여러개이므로 tf.data.Dataset.list_files를 통해 불러옵니다.\n",
    "IMAGE_SHAPE = (256, 256, 3)\n",
    "HEATMAP_SIZE = (64, 64)\n",
    "\n",
    "def create_dataset(tfrecords, batch_size, num_heatmap, is_train):\n",
    "    preprocess = Preprocessor(\n",
    "        IMAGE_SHAPE, (HEATMAP_SIZE[0], HEATMAP_SIZE[1], num_heatmap), is_train)\n",
    "\n",
    "    dataset = tf.data.Dataset.list_files(tfrecords)\n",
    "    dataset = tf.data.TFRecordDataset(dataset)\n",
    "    dataset = dataset.map(\n",
    "        preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    if is_train:\n",
    "        dataset = dataset.shuffle(batch_size)\n",
    "\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c65e3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋과 모델, 훈련용 객체를 조립만하면 되겠군요. 하나의 함수로 만들어 준다\n",
    "\n",
    "def train(model, epochs, learning_rate, num_heatmap, batch_size, train_tfrecords, val_tfrecords):\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    global_batch_size = strategy.num_replicas_in_sync * batch_size\n",
    "    train_dataset = create_dataset(\n",
    "        train_tfrecords, global_batch_size, num_heatmap, is_train=True)\n",
    "    val_dataset = create_dataset(\n",
    "        val_tfrecords, global_batch_size, num_heatmap, is_train=False)\n",
    "\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        os.makedirs(MODEL_PATH)\n",
    "\n",
    "    with strategy.scope():\n",
    "        train_dist_dataset = strategy.experimental_distribute_dataset(\n",
    "            train_dataset)\n",
    "        val_dist_dataset = strategy.experimental_distribute_dataset(\n",
    "            val_dataset)\n",
    "\n",
    "        # model = StackedHourglassNetwork(IMAGE_SHAPE, 4, 1, num_heatmap)\n",
    "        modelname = model.name\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model,\n",
    "            modelname,\n",
    "            epochs,\n",
    "            global_batch_size,\n",
    "            strategy,\n",
    "            initial_learning_rate=learning_rate)\n",
    "\n",
    "        print('Start training...')\n",
    "        return trainer.run(train_dist_dataset, val_dist_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4b0ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습\n",
    "train_tfrecords = os.path.join(TFRECORD_PATH, 'train*')\n",
    "val_tfrecords = os.path.join(TFRECORD_PATH, 'val*')\n",
    "epochs = 4 # 최소 3 이상 5 이상 권장\n",
    "batch_size = 16\n",
    "num_heatmap = 16\n",
    "learning_rate = 0.0007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d3659fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"stacked_hourglass\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 64) 9472        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 128, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 128, 128, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 64) 256         re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 128, 128, 64) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 64) 4160        re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 128, 64) 256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 128, 128, 64) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 64) 36928       re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 128, 128, 64) 256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 128, 128, 64) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 128 8320        re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 128 8320        re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 128, 128, 128 0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 64, 64, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 128)  512         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 64, 64, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 64)   8256        re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 64, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 64, 64, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 64)   36928       re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 64, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 64, 64, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 128)  8320        re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 128)  0           max_pooling2d[0][0]              \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 128)  512         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 64, 64, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 128)  16512       re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 128)  512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 64, 64, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 128)  147584      re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 128)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 64, 64, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 256)  33024       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 256)  33024       re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 256)  0           conv2d_9[0][0]                   \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 32, 256)  1024        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_19 (ReLU)                 (None, 32, 32, 256)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 128)  32896       re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_20 (ReLU)                 (None, 32, 32, 128)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 128)  147584      re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 128)  512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_21 (ReLU)                 (None, 32, 32, 128)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 256)  33024       re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 32, 256)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 256)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 256)  1024        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_28 (ReLU)                 (None, 16, 16, 256)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 128)  32896       re_lu_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 16, 16, 128)  512         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_29 (ReLU)                 (None, 16, 16, 128)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 128)  147584      re_lu_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 16, 16, 128)  512         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_30 (ReLU)                 (None, 16, 16, 128)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 256)  33024       re_lu_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 16, 256)  0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 256)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 8, 8, 256)    1024        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_37 (ReLU)                 (None, 8, 8, 256)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 8, 8, 128)    32896       re_lu_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 8, 8, 128)    512         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_38 (ReLU)                 (None, 8, 8, 128)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 8, 8, 128)    147584      re_lu_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 8, 8, 128)    512         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_39 (ReLU)                 (None, 8, 8, 128)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 8, 8, 256)    33024       re_lu_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 256)    0           max_pooling2d_3[0][0]            \n",
      "                                                                 conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 256)    0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 4, 4, 256)    1024        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_46 (ReLU)                 (None, 4, 4, 256)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 4, 4, 128)    32896       re_lu_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 4, 4, 128)    512         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_47 (ReLU)                 (None, 4, 4, 128)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 4, 4, 128)    147584      re_lu_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 4, 4, 128)    512         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_48 (ReLU)                 (None, 4, 4, 128)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 4, 4, 256)    33024       re_lu_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 4, 4, 256)    0           max_pooling2d_4[0][0]            \n",
      "                                                                 conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 4, 4, 256)    1024        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_49 (ReLU)                 (None, 4, 4, 256)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 8, 8, 256)    1024        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 4, 4, 128)    32896       re_lu_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_40 (ReLU)                 (None, 8, 8, 256)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 4, 4, 128)    512         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 8, 8, 128)    32896       re_lu_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_50 (ReLU)                 (None, 4, 4, 128)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 8, 8, 128)    512         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 4, 4, 128)    147584      re_lu_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_41 (ReLU)                 (None, 8, 8, 128)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 4, 4, 128)    512         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 8, 8, 128)    147584      re_lu_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_51 (ReLU)                 (None, 4, 4, 128)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 8, 8, 128)    512         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 4, 4, 256)    33024       re_lu_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_42 (ReLU)                 (None, 8, 8, 128)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 4, 4, 256)    0           add_14[0][0]                     \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 8, 8, 256)    33024       re_lu_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 4, 4, 256)    1024        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 8, 8, 256)    0           add_11[0][0]                     \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_52 (ReLU)                 (None, 4, 4, 256)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 8, 8, 256)    1024        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 4, 4, 128)    32896       re_lu_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_43 (ReLU)                 (None, 8, 8, 256)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 4, 4, 128)    512         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 8, 8, 128)    32896       re_lu_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 16, 16, 256)  1024        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_53 (ReLU)                 (None, 4, 4, 128)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 8, 8, 128)    512         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_31 (ReLU)                 (None, 16, 16, 256)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 4, 4, 128)    147584      re_lu_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_44 (ReLU)                 (None, 8, 8, 128)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 128)  32896       re_lu_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 4, 4, 128)    512         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 8, 8, 128)    147584      re_lu_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 16, 16, 128)  512         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_54 (ReLU)                 (None, 4, 4, 128)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 8, 8, 128)    512         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_32 (ReLU)                 (None, 16, 16, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 4, 4, 256)    33024       re_lu_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_45 (ReLU)                 (None, 8, 8, 128)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 128)  147584      re_lu_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 4, 4, 256)    0           add_15[0][0]                     \n",
      "                                                                 conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 8, 8, 256)    33024       re_lu_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 16, 16, 128)  512         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 8, 8, 256)    0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 8, 8, 256)    0           add_12[0][0]                     \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_33 (ReLU)                 (None, 16, 16, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 8, 8, 256)    0           up_sampling2d[0][0]              \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 256)  33024       re_lu_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 8, 256)    1024        tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 256)  0           add_8[0][0]                      \n",
      "                                                                 conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_55 (ReLU)                 (None, 8, 8, 256)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 256)  1024        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 8, 128)    32896       re_lu_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_34 (ReLU)                 (None, 16, 16, 256)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 8, 8, 128)    512         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 128)  32896       re_lu_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 256)  1024        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_56 (ReLU)                 (None, 8, 8, 128)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 128)  512         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_22 (ReLU)                 (None, 32, 32, 256)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 128)    147584      re_lu_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_35 (ReLU)                 (None, 16, 16, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 128)  32896       re_lu_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 8, 8, 128)    512         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 128)  147584      re_lu_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 32, 128)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_57 (ReLU)                 (None, 8, 8, 128)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 128)  512         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_23 (ReLU)                 (None, 32, 32, 128)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 256)    33024       re_lu_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_36 (ReLU)                 (None, 16, 16, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 128)  147584      re_lu_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 8, 8, 256)    0           tf.__operators__.add[0][0]       \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 256)  33024       re_lu_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 32, 128)  512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 256)  0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 256)  0           add_9[0][0]                      \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_24 (ReLU)                 (None, 32, 32, 128)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 16, 16, 256)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 256)  33024       re_lu_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 16, 16, 256)  1024        tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 32, 256)  0           add_5[0][0]                      \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_58 (ReLU)                 (None, 16, 16, 256)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 32, 32, 256)  1024        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 16, 16, 128)  32896       re_lu_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_25 (ReLU)                 (None, 32, 32, 256)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 16, 16, 128)  512         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 128)  32896       re_lu_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 256)  1024        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_59 (ReLU)                 (None, 16, 16, 128)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 32, 128)  512         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 64, 64, 256)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 16, 16, 128)  147584      re_lu_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_26 (ReLU)                 (None, 32, 32, 128)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 128)  32896       re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 16, 16, 128)  512         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 128)  147584      re_lu_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64, 64, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_60 (ReLU)                 (None, 16, 16, 128)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 32, 128)  512         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, 64, 64, 128)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 16, 16, 256)  33024       re_lu_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_27 (ReLU)                 (None, 32, 32, 128)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 128)  147584      re_lu_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 16, 16, 256)  0           tf.__operators__.add_1[0][0]     \n",
      "                                                                 conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 256)  33024       re_lu_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 64, 128)  512         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 32, 256)  0           add_6[0][0]                      \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 64, 64, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam (None, 32, 32, 256)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 256)  33024       re_lu_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 32, 32, 256)  1024        tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 64, 256)  0           add_2[0][0]                      \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_61 (ReLU)                 (None, 32, 32, 256)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 64, 64, 256)  1024        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 32, 32, 128)  32896       re_lu_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, 64, 64, 256)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 32, 32, 128)  512         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 128)  32896       re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_62 (ReLU)                 (None, 32, 32, 128)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 64, 64, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 32, 32, 128)  147584      re_lu_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 64, 64, 128)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 32, 32, 128)  512         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 128)  147584      re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_63 (ReLU)                 (None, 32, 32, 128)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 64, 64, 128)  512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 32, 32, 256)  33024       re_lu_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_18 (ReLU)                 (None, 64, 64, 128)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 32, 32, 256)  0           tf.__operators__.add_2[0][0]     \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 256)  33024       re_lu_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 256)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 64, 64, 256)  0           add_3[0][0]                      \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_3 (TFOpLam (None, 64, 64, 256)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 64, 64, 256)  1024        tf.__operators__.add_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_64 (ReLU)                 (None, 64, 64, 256)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 64, 64, 128)  32896       re_lu_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 64, 64, 128)  512         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_65 (ReLU)                 (None, 64, 64, 128)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 64, 64, 128)  147584      re_lu_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 64, 64, 128)  512         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_66 (ReLU)                 (None, 64, 64, 128)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 64, 64, 256)  33024       re_lu_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 64, 64, 256)  0           tf.__operators__.add_3[0][0]     \n",
      "                                                                 conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 64, 64, 256)  65792       add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 64, 64, 256)  1024        conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_67 (ReLU)                 (None, 64, 64, 256)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 64, 64, 16)   4112        re_lu_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 64, 64, 256)  65792       re_lu_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 64, 64, 256)  4352        conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 64, 64, 256)  0           conv2d_69[0][0]                  \n",
      "                                                                 conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 256)  0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 32, 32, 256)  1024        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_74 (ReLU)                 (None, 32, 32, 256)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 32, 32, 128)  32896       re_lu_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 32, 32, 128)  512         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_75 (ReLU)                 (None, 32, 32, 128)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 32, 32, 128)  147584      re_lu_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 32, 32, 128)  512         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_76 (ReLU)                 (None, 32, 32, 128)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 32, 32, 256)  33024       re_lu_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 32, 32, 256)  0           max_pooling2d_5[0][0]            \n",
      "                                                                 conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 256)  0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 16, 16, 256)  1024        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_83 (ReLU)                 (None, 16, 16, 256)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 16, 16, 128)  32896       re_lu_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 16, 16, 128)  512         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_84 (ReLU)                 (None, 16, 16, 128)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 16, 16, 128)  147584      re_lu_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 16, 16, 128)  512         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_85 (ReLU)                 (None, 16, 16, 128)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 16, 16, 256)  33024       re_lu_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 16, 16, 256)  0           max_pooling2d_6[0][0]            \n",
      "                                                                 conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 256)    0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 256)    1024        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_92 (ReLU)                 (None, 8, 8, 256)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 8, 8, 128)    32896       re_lu_92[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 128)    512         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_93 (ReLU)                 (None, 8, 8, 128)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 8, 8, 128)    147584      re_lu_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 8, 8, 128)    512         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_94 (ReLU)                 (None, 8, 8, 128)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 8, 8, 256)    33024       re_lu_94[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 8, 8, 256)    0           max_pooling2d_7[0][0]            \n",
      "                                                                 conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 4, 4, 256)    0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 4, 4, 256)    1024        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_101 (ReLU)                (None, 4, 4, 256)    0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 4, 4, 128)    32896       re_lu_101[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 4, 4, 128)    512         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_102 (ReLU)                (None, 4, 4, 128)    0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 4, 4, 128)    147584      re_lu_102[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 4, 4, 128)    512         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_103 (ReLU)                (None, 4, 4, 128)    0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 4, 4, 256)    33024       re_lu_103[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 4, 4, 256)    0           max_pooling2d_8[0][0]            \n",
      "                                                                 conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 4, 4, 256)    1024        add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_104 (ReLU)                (None, 4, 4, 256)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 8, 8, 256)    1024        add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 4, 4, 128)    32896       re_lu_104[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_95 (ReLU)                 (None, 8, 8, 256)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 4, 4, 128)    512         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 8, 8, 128)    32896       re_lu_95[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_105 (ReLU)                (None, 4, 4, 128)    0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 8, 8, 128)    512         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 4, 4, 128)    147584      re_lu_105[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_96 (ReLU)                 (None, 8, 8, 128)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 4, 4, 128)    512         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 8, 8, 128)    147584      re_lu_96[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_106 (ReLU)                (None, 4, 4, 128)    0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 8, 8, 128)    512         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 4, 4, 256)    33024       re_lu_106[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_97 (ReLU)                 (None, 8, 8, 128)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 4, 4, 256)    0           add_33[0][0]                     \n",
      "                                                                 conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 4, 4, 256)    1024        add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 8, 8, 256)    0           add_30[0][0]                     \n",
      "                                                                 conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_107 (ReLU)                (None, 4, 4, 256)    0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 8, 8, 256)    1024        add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 4, 4, 128)    32896       re_lu_107[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_98 (ReLU)                 (None, 8, 8, 256)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 4, 4, 128)    512         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 16, 16, 256)  1024        add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_108 (ReLU)                (None, 4, 4, 128)    0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 8, 8, 128)    512         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_86 (ReLU)                 (None, 16, 16, 256)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 4, 4, 128)    147584      re_lu_108[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_99 (ReLU)                 (None, 8, 8, 128)    0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 16, 16, 128)  32896       re_lu_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 4, 4, 128)    512         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_99[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 16, 16, 128)  512         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_109 (ReLU)                (None, 4, 4, 128)    0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 8, 8, 128)    512         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_87 (ReLU)                 (None, 16, 16, 128)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 4, 4, 256)    33024       re_lu_109[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_100 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 16, 16, 128)  147584      re_lu_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 4, 4, 256)    0           add_34[0][0]                     \n",
      "                                                                 conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_100[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 16, 16, 128)  512         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 8, 8, 256)    0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 8, 8, 256)    0           add_31[0][0]                     \n",
      "                                                                 conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_88 (ReLU)                 (None, 16, 16, 128)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_4 (TFOpLam (None, 8, 8, 256)    0           up_sampling2d_4[0][0]            \n",
      "                                                                 add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 16, 16, 256)  33024       re_lu_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 8, 8, 256)    1024        tf.__operators__.add_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 16, 16, 256)  0           add_27[0][0]                     \n",
      "                                                                 conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_110 (ReLU)                (None, 8, 8, 256)    0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 16, 16, 256)  1024        add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_110[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_89 (ReLU)                 (None, 16, 16, 256)  0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 8, 8, 128)    512         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 16, 16, 128)  32896       re_lu_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 32, 32, 256)  1024        add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_111 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 16, 16, 128)  512         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_77 (ReLU)                 (None, 32, 32, 256)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_111[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_90 (ReLU)                 (None, 16, 16, 128)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 32, 32, 128)  32896       re_lu_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 8, 8, 128)    512         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 16, 16, 128)  147584      re_lu_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 32, 32, 128)  512         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_112 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 16, 16, 128)  512         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_78 (ReLU)                 (None, 32, 32, 128)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_112[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_91 (ReLU)                 (None, 16, 16, 128)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 32, 32, 128)  147584      re_lu_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 8, 8, 256)    0           tf.__operators__.add_4[0][0]     \n",
      "                                                                 conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 16, 16, 256)  33024       re_lu_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 32, 32, 128)  512         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 16, 16, 256)  0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 16, 16, 256)  0           add_28[0][0]                     \n",
      "                                                                 conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_79 (ReLU)                 (None, 32, 32, 128)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_5 (TFOpLam (None, 16, 16, 256)  0           up_sampling2d_5[0][0]            \n",
      "                                                                 add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 32, 32, 256)  33024       re_lu_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 16, 16, 256)  1024        tf.__operators__.add_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 32, 32, 256)  0           add_24[0][0]                     \n",
      "                                                                 conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_113 (ReLU)                (None, 16, 16, 256)  0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 32, 32, 256)  1024        add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 16, 16, 128)  32896       re_lu_113[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_80 (ReLU)                 (None, 32, 32, 256)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 16, 16, 128)  512         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 32, 32, 128)  32896       re_lu_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 64, 64, 256)  1024        add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_114 (ReLU)                (None, 16, 16, 128)  0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 32, 32, 128)  512         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_68 (ReLU)                 (None, 64, 64, 256)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 16, 16, 128)  147584      re_lu_114[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_81 (ReLU)                 (None, 32, 32, 128)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 64, 64, 128)  32896       re_lu_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 16, 16, 128)  512         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 32, 32, 128)  147584      re_lu_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 64, 64, 128)  512         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_115 (ReLU)                (None, 16, 16, 128)  0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 32, 32, 128)  512         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_69 (ReLU)                 (None, 64, 64, 128)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 16, 16, 256)  33024       re_lu_115[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_82 (ReLU)                 (None, 32, 32, 128)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 64, 64, 128)  147584      re_lu_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 16, 16, 256)  0           tf.__operators__.add_5[0][0]     \n",
      "                                                                 conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 32, 32, 256)  33024       re_lu_82[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 64, 64, 128)  512         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 32, 32, 256)  0           add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 32, 32, 256)  0           add_25[0][0]                     \n",
      "                                                                 conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_70 (ReLU)                 (None, 64, 64, 128)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_6 (TFOpLam (None, 32, 32, 256)  0           up_sampling2d_6[0][0]            \n",
      "                                                                 add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 64, 64, 256)  33024       re_lu_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 32, 32, 256)  1024        tf.__operators__.add_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 64, 64, 256)  0           add_21[0][0]                     \n",
      "                                                                 conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_116 (ReLU)                (None, 32, 32, 256)  0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 64, 64, 256)  1024        add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 32, 32, 128)  32896       re_lu_116[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_71 (ReLU)                 (None, 64, 64, 256)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 32, 32, 128)  512         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 64, 64, 128)  32896       re_lu_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_117 (ReLU)                (None, 32, 32, 128)  0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 64, 64, 128)  512         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 32, 32, 128)  147584      re_lu_117[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_72 (ReLU)                 (None, 64, 64, 128)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 32, 32, 128)  512         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 64, 64, 128)  147584      re_lu_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_118 (ReLU)                (None, 32, 32, 128)  0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 64, 64, 128)  512         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 32, 32, 256)  33024       re_lu_118[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_73 (ReLU)                 (None, 64, 64, 128)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 32, 32, 256)  0           tf.__operators__.add_6[0][0]     \n",
      "                                                                 conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 64, 64, 256)  33024       re_lu_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 64, 64, 256)  0           add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 64, 64, 256)  0           add_22[0][0]                     \n",
      "                                                                 conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_7 (TFOpLam (None, 64, 64, 256)  0           up_sampling2d_7[0][0]            \n",
      "                                                                 add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 64, 64, 256)  1024        tf.__operators__.add_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_119 (ReLU)                (None, 64, 64, 256)  0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 64, 64, 128)  32896       re_lu_119[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 64, 64, 128)  512         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_120 (ReLU)                (None, 64, 64, 128)  0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 64, 64, 128)  147584      re_lu_120[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 64, 64, 128)  512         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_121 (ReLU)                (None, 64, 64, 128)  0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 64, 64, 256)  33024       re_lu_121[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 64, 64, 256)  0           tf.__operators__.add_7[0][0]     \n",
      "                                                                 conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 64, 64, 256)  65792       add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 64, 64, 256)  1024        conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_122 (ReLU)                (None, 64, 64, 256)  0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 64, 64, 16)   4112        re_lu_122[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 64, 64, 256)  65792       re_lu_122[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 64, 64, 256)  4352        conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 64, 64, 256)  0           conv2d_127[0][0]                 \n",
      "                                                                 conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 32, 32, 256)  0           add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 32, 32, 256)  1024        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_129 (ReLU)                (None, 32, 32, 256)  0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 32, 32, 128)  32896       re_lu_129[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 32, 32, 128)  512         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_130 (ReLU)                (None, 32, 32, 128)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 32, 32, 128)  147584      re_lu_130[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 32, 32, 128)  512         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_131 (ReLU)                (None, 32, 32, 128)  0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 32, 32, 256)  33024       re_lu_131[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 32, 32, 256)  0           max_pooling2d_9[0][0]            \n",
      "                                                                 conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 16, 16, 256)  0           add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 16, 16, 256)  1024        max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_138 (ReLU)                (None, 16, 16, 256)  0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 16, 16, 128)  32896       re_lu_138[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 16, 16, 128)  512         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_139 (ReLU)                (None, 16, 16, 128)  0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 16, 16, 128)  147584      re_lu_139[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 16, 16, 128)  512         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_140 (ReLU)                (None, 16, 16, 128)  0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 16, 16, 256)  33024       re_lu_140[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 16, 16, 256)  0           max_pooling2d_10[0][0]           \n",
      "                                                                 conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 8, 8, 256)    0           add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 8, 8, 256)    1024        max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_147 (ReLU)                (None, 8, 8, 256)    0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_147[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 8, 8, 128)    512         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_148 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_148[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 8, 8, 128)    512         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_149 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_149[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_49 (Add)                    (None, 8, 8, 256)    0           max_pooling2d_11[0][0]           \n",
      "                                                                 conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 4, 4, 256)    0           add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 4, 4, 256)    1024        max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_156 (ReLU)                (None, 4, 4, 256)    0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 4, 4, 128)    32896       re_lu_156[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 4, 4, 128)    512         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_157 (ReLU)                (None, 4, 4, 128)    0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 4, 4, 128)    147584      re_lu_157[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 4, 4, 128)    512         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_158 (ReLU)                (None, 4, 4, 128)    0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 4, 4, 256)    33024       re_lu_158[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_52 (Add)                    (None, 4, 4, 256)    0           max_pooling2d_12[0][0]           \n",
      "                                                                 conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 4, 4, 256)    1024        add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_159 (ReLU)                (None, 4, 4, 256)    0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 8, 8, 256)    1024        add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 4, 4, 128)    32896       re_lu_159[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_150 (ReLU)                (None, 8, 8, 256)    0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 4, 4, 128)    512         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_150[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_160 (ReLU)                (None, 4, 4, 128)    0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 8, 8, 128)    512         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 4, 4, 128)    147584      re_lu_160[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_151 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 4, 4, 128)    512         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_151[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_161 (ReLU)                (None, 4, 4, 128)    0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 8, 8, 128)    512         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 4, 4, 256)    33024       re_lu_161[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_152 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_53 (Add)                    (None, 4, 4, 256)    0           add_52[0][0]                     \n",
      "                                                                 conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_152[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 4, 4, 256)    1024        add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_50 (Add)                    (None, 8, 8, 256)    0           add_49[0][0]                     \n",
      "                                                                 conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_162 (ReLU)                (None, 4, 4, 256)    0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 8, 8, 256)    1024        add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 4, 4, 128)    32896       re_lu_162[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_153 (ReLU)                (None, 8, 8, 256)    0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 4, 4, 128)    512         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_153[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 16, 16, 256)  1024        add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_163 (ReLU)                (None, 4, 4, 128)    0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 8, 8, 128)    512         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_141 (ReLU)                (None, 16, 16, 256)  0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 4, 4, 128)    147584      re_lu_163[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_154 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 16, 16, 128)  32896       re_lu_141[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 4, 4, 128)    512         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_154[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 16, 16, 128)  512         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_164 (ReLU)                (None, 4, 4, 128)    0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 8, 8, 128)    512         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_142 (ReLU)                (None, 16, 16, 128)  0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 4, 4, 256)    33024       re_lu_164[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_155 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 16, 16, 128)  147584      re_lu_142[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_54 (Add)                    (None, 4, 4, 256)    0           add_53[0][0]                     \n",
      "                                                                 conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_155[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 16, 16, 128)  512         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, 8, 8, 256)    0           add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 8, 8, 256)    0           add_50[0][0]                     \n",
      "                                                                 conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_143 (ReLU)                (None, 16, 16, 128)  0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_8 (TFOpLam (None, 8, 8, 256)    0           up_sampling2d_8[0][0]            \n",
      "                                                                 add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 16, 16, 256)  33024       re_lu_143[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 8, 8, 256)    1024        tf.__operators__.add_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 16, 16, 256)  0           add_46[0][0]                     \n",
      "                                                                 conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_165 (ReLU)                (None, 8, 8, 256)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 16, 16, 256)  1024        add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_165[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_144 (ReLU)                (None, 16, 16, 256)  0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 8, 8, 128)    512         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 16, 16, 128)  32896       re_lu_144[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 32, 32, 256)  1024        add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_166 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 16, 16, 128)  512         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_132 (ReLU)                (None, 32, 32, 256)  0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_166[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_145 (ReLU)                (None, 16, 16, 128)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 32, 32, 128)  32896       re_lu_132[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 8, 8, 128)    512         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 16, 16, 128)  147584      re_lu_145[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 32, 32, 128)  512         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_167 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 16, 16, 128)  512         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_133 (ReLU)                (None, 32, 32, 128)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_167[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_146 (ReLU)                (None, 16, 16, 128)  0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 32, 32, 128)  147584      re_lu_133[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_55 (Add)                    (None, 8, 8, 256)    0           tf.__operators__.add_8[0][0]     \n",
      "                                                                 conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 16, 16, 256)  33024       re_lu_146[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 32, 32, 128)  512         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2D)  (None, 16, 16, 256)  0           add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, 16, 16, 256)  0           add_47[0][0]                     \n",
      "                                                                 conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_134 (ReLU)                (None, 32, 32, 128)  0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_9 (TFOpLam (None, 16, 16, 256)  0           up_sampling2d_9[0][0]            \n",
      "                                                                 add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 32, 32, 256)  33024       re_lu_134[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 16, 16, 256)  1024        tf.__operators__.add_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 32, 32, 256)  0           add_43[0][0]                     \n",
      "                                                                 conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_168 (ReLU)                (None, 16, 16, 256)  0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 32, 32, 256)  1024        add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 16, 16, 128)  32896       re_lu_168[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_135 (ReLU)                (None, 32, 32, 256)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 16, 16, 128)  512         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 32, 32, 128)  32896       re_lu_135[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 64, 64, 256)  1024        add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_169 (ReLU)                (None, 16, 16, 128)  0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 32, 32, 128)  512         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_123 (ReLU)                (None, 64, 64, 256)  0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 16, 16, 128)  147584      re_lu_169[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_136 (ReLU)                (None, 32, 32, 128)  0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 64, 64, 128)  32896       re_lu_123[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 16, 16, 128)  512         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 32, 32, 128)  147584      re_lu_136[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 64, 64, 128)  512         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_170 (ReLU)                (None, 16, 16, 128)  0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 32, 32, 128)  512         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_124 (ReLU)                (None, 64, 64, 128)  0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 16, 16, 256)  33024       re_lu_170[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_137 (ReLU)                (None, 32, 32, 128)  0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 64, 64, 128)  147584      re_lu_124[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_56 (Add)                    (None, 16, 16, 256)  0           tf.__operators__.add_9[0][0]     \n",
      "                                                                 conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 32, 32, 256)  33024       re_lu_137[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 64, 64, 128)  512         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling2D) (None, 32, 32, 256)  0           add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 32, 32, 256)  0           add_44[0][0]                     \n",
      "                                                                 conv2d_143[0][0]                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "re_lu_125 (ReLU)                (None, 64, 64, 128)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_10 (TFOpLa (None, 32, 32, 256)  0           up_sampling2d_10[0][0]           \n",
      "                                                                 add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 64, 64, 256)  33024       re_lu_125[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 32, 32, 256)  1024        tf.__operators__.add_10[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 64, 64, 256)  0           add_40[0][0]                     \n",
      "                                                                 conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_171 (ReLU)                (None, 32, 32, 256)  0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 64, 64, 256)  1024        add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 32, 32, 128)  32896       re_lu_171[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_126 (ReLU)                (None, 64, 64, 256)  0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 32, 32, 128)  512         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 64, 64, 128)  32896       re_lu_126[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_172 (ReLU)                (None, 32, 32, 128)  0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 64, 64, 128)  512         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 32, 32, 128)  147584      re_lu_172[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_127 (ReLU)                (None, 64, 64, 128)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 32, 32, 128)  512         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 64, 64, 128)  147584      re_lu_127[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_173 (ReLU)                (None, 32, 32, 128)  0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 64, 64, 128)  512         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 32, 32, 256)  33024       re_lu_173[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_128 (ReLU)                (None, 64, 64, 128)  0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_57 (Add)                    (None, 32, 32, 256)  0           tf.__operators__.add_10[0][0]    \n",
      "                                                                 conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 64, 64, 256)  33024       re_lu_128[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling2D) (None, 64, 64, 256)  0           add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 64, 64, 256)  0           add_41[0][0]                     \n",
      "                                                                 conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_11 (TFOpLa (None, 64, 64, 256)  0           up_sampling2d_11[0][0]           \n",
      "                                                                 add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 64, 64, 256)  1024        tf.__operators__.add_11[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_174 (ReLU)                (None, 64, 64, 256)  0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 64, 64, 128)  32896       re_lu_174[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 64, 64, 128)  512         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_175 (ReLU)                (None, 64, 64, 128)  0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 64, 64, 128)  147584      re_lu_175[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 64, 64, 128)  512         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_176 (ReLU)                (None, 64, 64, 128)  0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 64, 64, 256)  33024       re_lu_176[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_58 (Add)                    (None, 64, 64, 256)  0           tf.__operators__.add_11[0][0]    \n",
      "                                                                 conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 64, 64, 256)  65792       add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 64, 64, 256)  1024        conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_177 (ReLU)                (None, 64, 64, 256)  0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 64, 64, 16)   4112        re_lu_177[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 64, 64, 256)  65792       re_lu_177[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 64, 64, 256)  4352        conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_59 (Add)                    (None, 64, 64, 256)  0           conv2d_185[0][0]                 \n",
      "                                                                 conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 32, 32, 256)  0           add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 32, 32, 256)  1024        max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_184 (ReLU)                (None, 32, 32, 256)  0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 32, 32, 128)  32896       re_lu_184[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 32, 32, 128)  512         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_185 (ReLU)                (None, 32, 32, 128)  0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 32, 32, 128)  147584      re_lu_185[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 32, 32, 128)  512         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_186 (ReLU)                (None, 32, 32, 128)  0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 32, 32, 256)  33024       re_lu_186[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_62 (Add)                    (None, 32, 32, 256)  0           max_pooling2d_13[0][0]           \n",
      "                                                                 conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 16, 16, 256)  0           add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 16, 16, 256)  1024        max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_193 (ReLU)                (None, 16, 16, 256)  0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 16, 16, 128)  32896       re_lu_193[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 16, 16, 128)  512         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_194 (ReLU)                (None, 16, 16, 128)  0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 16, 16, 128)  147584      re_lu_194[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 16, 16, 128)  512         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_195 (ReLU)                (None, 16, 16, 128)  0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 16, 16, 256)  33024       re_lu_195[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_65 (Add)                    (None, 16, 16, 256)  0           max_pooling2d_14[0][0]           \n",
      "                                                                 conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 8, 8, 256)    0           add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 8, 8, 256)    1024        max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_202 (ReLU)                (None, 8, 8, 256)    0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_202[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 8, 8, 128)    512         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_203 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_203[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 8, 8, 128)    512         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_204 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_204[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_68 (Add)                    (None, 8, 8, 256)    0           max_pooling2d_15[0][0]           \n",
      "                                                                 conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 4, 4, 256)    0           add_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 4, 4, 256)    1024        max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_211 (ReLU)                (None, 4, 4, 256)    0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 4, 4, 128)    32896       re_lu_211[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 4, 4, 128)    512         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_212 (ReLU)                (None, 4, 4, 128)    0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 4, 4, 128)    147584      re_lu_212[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 4, 4, 128)    512         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_213 (ReLU)                (None, 4, 4, 128)    0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 4, 4, 256)    33024       re_lu_213[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_71 (Add)                    (None, 4, 4, 256)    0           max_pooling2d_16[0][0]           \n",
      "                                                                 conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 4, 4, 256)    1024        add_71[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_214 (ReLU)                (None, 4, 4, 256)    0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 8, 8, 256)    1024        add_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 4, 4, 128)    32896       re_lu_214[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_205 (ReLU)                (None, 8, 8, 256)    0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 4, 4, 128)    512         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_205[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_215 (ReLU)                (None, 4, 4, 128)    0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 8, 8, 128)    512         conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 4, 4, 128)    147584      re_lu_215[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_206 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 4, 4, 128)    512         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_206[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_216 (ReLU)                (None, 4, 4, 128)    0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 8, 8, 128)    512         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 4, 4, 256)    33024       re_lu_216[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_207 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_72 (Add)                    (None, 4, 4, 256)    0           add_71[0][0]                     \n",
      "                                                                 conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_207[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 4, 4, 256)    1024        add_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_69 (Add)                    (None, 8, 8, 256)    0           add_68[0][0]                     \n",
      "                                                                 conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_217 (ReLU)                (None, 4, 4, 256)    0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 8, 8, 256)    1024        add_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 4, 4, 128)    32896       re_lu_217[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_208 (ReLU)                (None, 8, 8, 256)    0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 4, 4, 128)    512         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_208[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 16, 16, 256)  1024        add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_218 (ReLU)                (None, 4, 4, 128)    0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 8, 8, 128)    512         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_196 (ReLU)                (None, 16, 16, 256)  0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 4, 4, 128)    147584      re_lu_218[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_209 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 16, 16, 128)  32896       re_lu_196[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 4, 4, 128)    512         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_209[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 16, 16, 128)  512         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_219 (ReLU)                (None, 4, 4, 128)    0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 8, 8, 128)    512         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_197 (ReLU)                (None, 16, 16, 128)  0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 4, 4, 256)    33024       re_lu_219[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_210 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 16, 16, 128)  147584      re_lu_197[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_73 (Add)                    (None, 4, 4, 256)    0           add_72[0][0]                     \n",
      "                                                                 conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_210[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 16, 16, 128)  512         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_12 (UpSampling2D) (None, 8, 8, 256)    0           add_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_70 (Add)                    (None, 8, 8, 256)    0           add_69[0][0]                     \n",
      "                                                                 conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_198 (ReLU)                (None, 16, 16, 128)  0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_12 (TFOpLa (None, 8, 8, 256)    0           up_sampling2d_12[0][0]           \n",
      "                                                                 add_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 16, 16, 256)  33024       re_lu_198[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 8, 8, 256)    1024        tf.__operators__.add_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_66 (Add)                    (None, 16, 16, 256)  0           add_65[0][0]                     \n",
      "                                                                 conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_220 (ReLU)                (None, 8, 8, 256)    0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 16, 16, 256)  1024        add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_220[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_199 (ReLU)                (None, 16, 16, 256)  0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 8, 8, 128)    512         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 16, 16, 128)  32896       re_lu_199[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 32, 32, 256)  1024        add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_221 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 16, 16, 128)  512         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_187 (ReLU)                (None, 32, 32, 256)  0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_221[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_200 (ReLU)                (None, 16, 16, 128)  0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 32, 32, 128)  32896       re_lu_187[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 8, 8, 128)    512         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 16, 16, 128)  147584      re_lu_200[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 32, 32, 128)  512         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_222 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 16, 16, 128)  512         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_188 (ReLU)                (None, 32, 32, 128)  0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_222[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_201 (ReLU)                (None, 16, 16, 128)  0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 32, 32, 128)  147584      re_lu_188[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_74 (Add)                    (None, 8, 8, 256)    0           tf.__operators__.add_12[0][0]    \n",
      "                                                                 conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 16, 16, 256)  33024       re_lu_201[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 32, 32, 128)  512         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_13 (UpSampling2D) (None, 16, 16, 256)  0           add_74[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_67 (Add)                    (None, 16, 16, 256)  0           add_66[0][0]                     \n",
      "                                                                 conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_189 (ReLU)                (None, 32, 32, 128)  0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_13 (TFOpLa (None, 16, 16, 256)  0           up_sampling2d_13[0][0]           \n",
      "                                                                 add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 32, 32, 256)  33024       re_lu_189[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 16, 16, 256)  1024        tf.__operators__.add_13[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_63 (Add)                    (None, 32, 32, 256)  0           add_62[0][0]                     \n",
      "                                                                 conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_223 (ReLU)                (None, 16, 16, 256)  0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 32, 32, 256)  1024        add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 16, 16, 128)  32896       re_lu_223[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_190 (ReLU)                (None, 32, 32, 256)  0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 16, 16, 128)  512         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 32, 32, 128)  32896       re_lu_190[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 64, 64, 256)  1024        add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_224 (ReLU)                (None, 16, 16, 128)  0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 32, 32, 128)  512         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_178 (ReLU)                (None, 64, 64, 256)  0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 16, 16, 128)  147584      re_lu_224[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_191 (ReLU)                (None, 32, 32, 128)  0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 64, 64, 128)  32896       re_lu_178[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 16, 16, 128)  512         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 32, 32, 128)  147584      re_lu_191[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 64, 64, 128)  512         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_225 (ReLU)                (None, 16, 16, 128)  0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 32, 32, 128)  512         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_179 (ReLU)                (None, 64, 64, 128)  0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 16, 16, 256)  33024       re_lu_225[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_192 (ReLU)                (None, 32, 32, 128)  0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 64, 64, 128)  147584      re_lu_179[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_75 (Add)                    (None, 16, 16, 256)  0           tf.__operators__.add_13[0][0]    \n",
      "                                                                 conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 32, 32, 256)  33024       re_lu_192[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 64, 64, 128)  512         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_14 (UpSampling2D) (None, 32, 32, 256)  0           add_75[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_64 (Add)                    (None, 32, 32, 256)  0           add_63[0][0]                     \n",
      "                                                                 conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_180 (ReLU)                (None, 64, 64, 128)  0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_14 (TFOpLa (None, 32, 32, 256)  0           up_sampling2d_14[0][0]           \n",
      "                                                                 add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 64, 64, 256)  33024       re_lu_180[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 32, 32, 256)  1024        tf.__operators__.add_14[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_60 (Add)                    (None, 64, 64, 256)  0           add_59[0][0]                     \n",
      "                                                                 conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_226 (ReLU)                (None, 32, 32, 256)  0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 64, 64, 256)  1024        add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 32, 32, 128)  32896       re_lu_226[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_181 (ReLU)                (None, 64, 64, 256)  0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 32, 32, 128)  512         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 64, 64, 128)  32896       re_lu_181[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_227 (ReLU)                (None, 32, 32, 128)  0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 64, 64, 128)  512         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 32, 32, 128)  147584      re_lu_227[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_182 (ReLU)                (None, 64, 64, 128)  0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 32, 32, 128)  512         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 64, 64, 128)  147584      re_lu_182[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_228 (ReLU)                (None, 32, 32, 128)  0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 64, 64, 128)  512         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 32, 32, 256)  33024       re_lu_228[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_183 (ReLU)                (None, 64, 64, 128)  0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_76 (Add)                    (None, 32, 32, 256)  0           tf.__operators__.add_14[0][0]    \n",
      "                                                                 conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 64, 64, 256)  33024       re_lu_183[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_15 (UpSampling2D) (None, 64, 64, 256)  0           add_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_61 (Add)                    (None, 64, 64, 256)  0           add_60[0][0]                     \n",
      "                                                                 conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_15 (TFOpLa (None, 64, 64, 256)  0           up_sampling2d_15[0][0]           \n",
      "                                                                 add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 64, 64, 256)  1024        tf.__operators__.add_15[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_229 (ReLU)                (None, 64, 64, 256)  0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 64, 64, 128)  32896       re_lu_229[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 64, 64, 128)  512         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_230 (ReLU)                (None, 64, 64, 128)  0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 64, 64, 128)  147584      re_lu_230[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 64, 64, 128)  512         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_231 (ReLU)                (None, 64, 64, 128)  0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 64, 64, 256)  33024       re_lu_231[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_77 (Add)                    (None, 64, 64, 256)  0           tf.__operators__.add_15[0][0]    \n",
      "                                                                 conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 64, 64, 256)  65792       add_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 64, 64, 256)  1024        conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_232 (ReLU)                (None, 64, 64, 256)  0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 64, 64, 16)   4112        re_lu_232[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 16,368,320\n",
      "Trainable params: 16,290,752\n",
      "Non-trainable params: 77,568\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# StackedHourglassNetwork\n",
    "model_1 = StackedHourglassNetwork(IMAGE_SHAPE, 4, 1, num_heatmap)\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8ee72dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stacked_hourglass'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60fda9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"simple_baseline\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, None, None, 2048)  23587712  \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 64, 64, 256)       10489600  \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 64, 64, 17)        4369      \n",
      "=================================================================\n",
      "Total params: 34,081,681\n",
      "Trainable params: 34,027,025\n",
      "Non-trainable params: 54,656\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Simplebaseline\n",
    "model_2 = Simplebaseline(IMAGE_SHAPE)\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24c6a44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'simple_baseline'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c72c1a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Start training...\n",
      "Start epoch 1 with learning rate 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:374: UserWarning: To make it possible to preserve tf.data options across serialization boundaries, their implementation has moved to be part of the TensorFlow graph. As a consequence, the options value is in general no longer known at graph construction time. Invoking this method in graph mode retains the legacy behavior of the original implementation, but note that the returned value might not reflect the actual value of the options.\n",
      "  warnings.warn(\"To make it possible to preserve tf.data options across \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: in user code:\n",
      "\n",
      "    /tmp/ipykernel_790/3116605721.py:70 train_step  *\n",
      "        self.optimizer.apply_gradients(\n",
      "    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:628 apply_gradients  **\n",
      "        self._create_all_weights(var_list)\n",
      "    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:815 _create_all_weights\n",
      "        self._create_slots(var_list)\n",
      "    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:117 _create_slots\n",
      "        self.add_slot(var, 'm')\n",
      "    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:892 add_slot\n",
      "        raise ValueError(\n",
      "\n",
      "    ValueError: Trying to create optimizer slot variable under the scope for tf.distribute.Strategy (<tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7fe3bde54070>), which is different from the scope used for the original variable (<tf.Variable 'conv2d_1/kernel:0' shape=(7, 7, 3, 64) dtype=float32, numpy=\n",
      "    array([[[[ 6.13027476e-02,  1.50614455e-01,  1.35345340e-01, ...,\n",
      "              -8.16099793e-02,  7.15045482e-02, -8.85434896e-02],\n",
      "             [-6.29635602e-02, -6.45009577e-02,  6.59904853e-02, ...,\n",
      "               4.35089208e-02,  2.15629488e-02,  2.57276475e-01],\n",
      "             [ 1.00521408e-01, -1.51722565e-01,  9.92045775e-02, ...,\n",
      "              -9.40072984e-02, -1.46815609e-02, -1.15684219e-01]],\n",
      "    \n",
      "            [[-9.80345309e-02,  1.89435855e-01, -2.37035602e-01, ...,\n",
      "               3.63893621e-02, -9.04790536e-02,  1.92969024e-01],\n",
      "             [ 2.16621935e-01, -1.02797031e-01, -1.64573925e-04, ...,\n",
      "              -1.09765165e-01, -4.60456088e-02, -2.80861929e-02],\n",
      "             [ 5.09737693e-02, -6.60286322e-02, -1.33431092e-01, ...,\n",
      "              -1.24041647e-01, -8.81058127e-02,  1.50977215e-02]],\n",
      "    \n",
      "            [[-3.01897596e-03,  5.22158742e-02,  1.65612474e-02, ...,\n",
      "              -2.43651614e-01,  6.62046224e-02, -1.80847988e-01],\n",
      "             [-9.65840742e-02, -1.45419076e-01,  2.03709617e-01, ...,\n",
      "              -7.71873444e-02,  2.29114853e-02, -1.21069320e-01],\n",
      "             [-8.00769702e-02, -1.01478718e-01,  1.00891180e-01, ...,\n",
      "               4.88331616e-02, -1.18581466e-01, -2.26025164e-01]],\n",
      "    \n",
      "            ...,\n",
      "    \n",
      "            [[ 1.35203265e-02,  2.76322067e-02, -1.44717664e-01, ...,\n",
      "               1.67539835e-01,  2.53902730e-02,  6.53840229e-02],\n",
      "             [ 8.61227289e-02,  5.12347668e-02, -1.39597639e-01, ...,\n",
      "               1.86924770e-01,  1.58347726e-01,  5.85889928e-02],\n",
      "             [-8.15377235e-02, -3.60459127e-02,  1.24675594e-02, ...,\n",
      "               3.86517122e-03, -8.50900263e-03, -7.69343972e-02]],\n",
      "    \n",
      "            [[ 1.66026592e-01,  1.49623260e-01, -2.31387913e-02, ...,\n",
      "              -6.54041320e-02, -1.24785528e-01,  1.31704941e-01],\n",
      "             [-6.64192736e-02, -1.13489442e-01,  1.60216063e-01, ...,\n",
      "              -3.09046414e-02,  5.88068701e-02, -4.45075817e-02],\n",
      "             [ 5.02059385e-02,  1.50478587e-01, -1.24967478e-01, ...,\n",
      "              -2.35792808e-02, -1.87081173e-01, -1.82202458e-03]],\n",
      "    \n",
      "            [[ 9.77816880e-02, -1.43437177e-01, -2.41182633e-02, ...,\n",
      "              -1.09410852e-01,  1.40387043e-01,  5.70664816e-02],\n",
      "             [ 2.14798331e-01, -1.96973637e-01,  2.03399867e-01, ...,\n",
      "               1.52573794e-01,  7.31504485e-02, -1.98803246e-02],\n",
      "             [ 5.21983206e-03,  9.81542990e-02, -7.46836141e-02, ...,\n",
      "               5.88658266e-02, -1.54774925e-02, -1.11802541e-01]]],\n",
      "    \n",
      "    \n",
      "           [[[ 7.43995011e-02, -3.11786756e-02,  3.34962271e-02, ...,\n",
      "               1.63646415e-01, -1.68314334e-02, -8.54853541e-02],\n",
      "             [ 1.04430266e-01, -1.40769137e-02, -1.32401913e-01, ...,\n",
      "              -1.31703451e-01,  1.18291833e-01, -1.89344719e-01],\n",
      "             [ 1.49974078e-01, -5.15702255e-02, -4.86299507e-02, ...,\n",
      "              -1.29736990e-01, -8.76289606e-02, -3.76371704e-02]],\n",
      "    \n",
      "            [[-8.01044796e-03, -2.40040213e-01, -4.81870994e-02, ...,\n",
      "               9.27171577e-03, -1.13444172e-01, -8.72101337e-02],\n",
      "             [-5.35292737e-02,  8.68863985e-02, -1.58409998e-01, ...,\n",
      "               1.55851930e-01,  9.55974590e-03,  6.06897473e-02],\n",
      "             [ 7.65984431e-02,  4.81488109e-02, -2.23900869e-01, ...,\n",
      "              -2.12638348e-01, -3.57730053e-02,  1.10168077e-01]],\n",
      "    \n",
      "            [[-3.13774236e-02, -9.63343382e-02,  1.56977430e-01, ...,\n",
      "              -4.51943576e-02, -2.04060555e-01,  9.81798321e-02],\n",
      "             [-1.87521636e-01, -2.46430308e-01,  1.55240605e-02, ...,\n",
      "              -1.04741462e-01,  1.54669628e-01,  1.00513427e-02],\n",
      "             [-8.26077834e-02,  6.01827316e-02, -1.45832434e-01, ...,\n",
      "              -2.47084014e-02, -1.86228052e-01, -7.59718008e-03]],\n",
      "    \n",
      "            ...,\n",
      "    \n",
      "            [[-1.98650762e-01,  1.63403571e-01, -2.17505336e-01, ...,\n",
      "              -1.25022501e-01,  1.50700205e-03,  6.11829832e-02],\n",
      "             [ 1.57758147e-01,  1.10434867e-01,  1.03581257e-01, ...,\n",
      "              -6.36967656e-04,  4.37583774e-02, -7.52287507e-02],\n",
      "             [-1.15172891e-03, -2.32697934e-01,  3.84797826e-02, ...,\n",
      "              -1.27419859e-01, -4.13282439e-02,  2.72780024e-02]],\n",
      "    \n",
      "            [[-1.87169820e-01,  9.76692960e-02, -4.22885753e-02, ...,\n",
      "               1.64859876e-01, -1.90731382e-03,  3.88390273e-02],\n",
      "             [ 6.44878298e-02, -4.29949947e-02,  4.66062538e-02, ...,\n",
      "              -1.00921109e-01,  9.50264186e-02, -1.41044557e-01],\n",
      "             [-1.18268281e-01,  6.36323616e-02, -4.75717883e-04, ...,\n",
      "              -7.70919770e-02,  6.90176114e-02, -9.26017538e-02]],\n",
      "    \n",
      "            [[-1.77174926e-01, -1.09059796e-01,  2.57321477e-01, ...,\n",
      "               2.14279905e-01,  3.51525508e-02, -4.04059067e-02],\n",
      "             [ 1.24453166e-02, -2.31172085e-01,  1.59734562e-01, ...,\n",
      "              -9.72141325e-02, -4.11993489e-02,  6.70645759e-02],\n",
      "             [ 1.80671969e-03, -2.23725867e-02, -1.82955608e-01, ...,\n",
      "               5.20451441e-02, -3.42951156e-02, -1.68170840e-01]]],\n",
      "    \n",
      "    \n",
      "           [[[ 4.26355489e-02,  7.08516911e-02,  2.27851477e-02, ...,\n",
      "              -1.65555432e-01, -2.32125863e-01, -4.53629717e-02],\n",
      "             [ 1.11784525e-01, -1.33745179e-01,  2.93720867e-02, ...,\n",
      "               1.87195957e-01, -5.33411540e-02, -3.95275019e-02],\n",
      "             [ 6.24825135e-02,  1.15999490e-01, -1.92222238e-01, ...,\n",
      "               8.75054970e-02,  1.74466074e-01,  5.45380078e-02]],\n",
      "    \n",
      "            [[-1.21881589e-01,  4.38498296e-02, -7.23414049e-02, ...,\n",
      "               9.86528918e-02, -1.50920851e-02,  6.44939169e-02],\n",
      "             [ 1.88989453e-02, -1.88362241e-01, -6.54458180e-02, ...,\n",
      "               1.97988749e-01,  1.69605762e-01, -1.03346892e-01],\n",
      "             [-5.94289042e-02, -9.17370170e-02,  1.96886927e-01, ...,\n",
      "               1.30331054e-01, -2.43689463e-01, -1.35739595e-01]],\n",
      "    \n",
      "            [[ 2.38891795e-01, -1.43961757e-01, -9.46223140e-02, ...,\n",
      "               6.54063299e-02, -1.12381577e-02,  3.47842425e-02],\n",
      "             [-1.24086522e-01,  9.33054239e-02, -1.71027740e-03, ...,\n",
      "              -1.03802510e-01, -1.44332871e-01,  5.87318987e-02],\n",
      "             [ 2.63413131e-01, -7.97889370e-04, -8.63094404e-02, ...,\n",
      "              -4.97243134e-03,  2.32819375e-03,  6.36920407e-02]],\n",
      "    \n",
      "            ...,\n",
      "    \n",
      "            [[ 4.39061895e-02, -3.06197144e-02,  8.19719583e-02, ...,\n",
      "               5.70775308e-02,  2.36131266e-01, -2.16464344e-02],\n",
      "             [ 1.58768788e-01, -1.44167338e-02,  1.66579440e-01, ...,\n",
      "               2.32374817e-02,  3.99878994e-02,  2.65069008e-01],\n",
      "             [-9.17340443e-03,  9.61398333e-02,  1.42653644e-01, ...,\n",
      "               8.60497877e-02, -1.56885013e-01, -2.45002419e-01]],\n",
      "    \n",
      "            [[ 3.78528871e-02, -4.50962633e-02,  2.17729837e-01, ...,\n",
      "              -7.20090494e-02, -1.03469238e-01, -2.47531980e-01],\n",
      "             [-9.78876948e-02, -2.15603426e-01,  2.57111993e-02, ...,\n",
      "               9.55697894e-02,  8.25565867e-03, -1.76898494e-01],\n",
      "             [-1.48313567e-01, -1.53920949e-01,  1.48660854e-01, ...,\n",
      "              -3.63829024e-02,  1.68311447e-01,  2.36072749e-01]],\n",
      "    \n",
      "            [[-7.60350004e-02,  2.57441364e-02,  1.55617103e-01, ...,\n",
      "              -1.51833028e-01, -2.96167843e-02, -1.05702221e-01],\n",
      "             [ 6.35700487e-03,  1.19157456e-01, -1.14801116e-02, ...,\n",
      "               1.77513450e-01, -5.99536579e-03, -7.12867975e-02],\n",
      "             [ 3.88280638e-02, -4.55495762e-03,  1.19555937e-02, ...,\n",
      "              -4.38393056e-02, -1.00527555e-01, -2.49935798e-02]]],\n",
      "    \n",
      "    \n",
      "           ...,\n",
      "    \n",
      "    \n",
      "           [[[ 1.22513577e-01,  5.09266648e-03, -8.53807628e-02, ...,\n",
      "              -4.58052615e-03, -1.68446988e-01, -2.58252531e-01],\n",
      "             [-2.14745346e-02,  1.63010120e-01, -9.59499255e-02, ...,\n",
      "              -6.83643371e-02, -1.53660802e-02, -2.36012965e-01],\n",
      "             [-1.70981824e-01, -1.40343681e-01,  2.26165846e-01, ...,\n",
      "              -3.32186744e-02,  1.70948461e-01, -8.36032704e-02]],\n",
      "    \n",
      "            [[-2.35205576e-01,  5.70198856e-02,  1.68733433e-01, ...,\n",
      "              -1.08057626e-01, -9.40405112e-03,  1.75195873e-01],\n",
      "             [ 2.64507532e-01, -1.91123098e-01, -1.61637619e-01, ...,\n",
      "               6.51448518e-02, -2.10690424e-02,  1.45839348e-01],\n",
      "             [ 1.39066324e-01, -5.14815859e-02,  2.19909810e-02, ...,\n",
      "               5.60113881e-03, -1.17751718e-01, -1.44344121e-01]],\n",
      "    \n",
      "            [[ 4.54274043e-02,  1.57887377e-02,  1.67322367e-01, ...,\n",
      "               9.58062708e-02,  1.19645859e-03, -1.23345762e-01],\n",
      "             [-3.60198915e-02, -2.64056563e-01, -9.42556038e-02, ...,\n",
      "              -1.68050960e-01, -2.11052999e-01, -4.06056568e-02],\n",
      "             [-1.45537816e-02,  1.73526824e-01,  6.66935593e-02, ...,\n",
      "               1.35415448e-02, -5.84160127e-02, -5.43588661e-02]],\n",
      "    \n",
      "            ...,\n",
      "    \n",
      "            [[-7.06954151e-02, -1.57525837e-02, -6.17827736e-02, ...,\n",
      "               4.98971902e-02, -1.35388508e-01,  1.19418912e-01],\n",
      "             [-7.34979659e-02, -9.36273858e-02,  4.66608108e-05, ...,\n",
      "              -2.12430488e-02,  1.30864397e-01,  2.23309956e-02],\n",
      "             [ 1.05640348e-02,  1.14529040e-02, -1.98482163e-02, ...,\n",
      "              -3.01012192e-02,  3.05300076e-02,  1.01408176e-02]],\n",
      "    \n",
      "            [[ 6.65159523e-02, -6.20860606e-02,  1.73784435e-01, ...,\n",
      "              -1.11620888e-01, -1.10321261e-01, -9.86246988e-02],\n",
      "             [ 1.92608505e-01,  1.04694196e-03,  6.53823167e-02, ...,\n",
      "              -2.04312056e-01, -1.18431769e-01,  1.71276495e-01],\n",
      "             [ 6.37844801e-02, -1.83133736e-01, -5.33691421e-03, ...,\n",
      "               1.10962778e-01,  1.49894720e-02, -2.65677460e-02]],\n",
      "    \n",
      "            [[ 1.54260352e-01, -1.84997752e-01,  2.22448170e-01, ...,\n",
      "               1.06664814e-01,  2.46161804e-01, -1.50213555e-01],\n",
      "             [ 1.95108657e-03,  1.25695586e-01,  1.11226246e-01, ...,\n",
      "               1.00337654e-01, -4.07159738e-02,  5.33722788e-02],\n",
      "             [-4.67980653e-02,  1.68124102e-02, -5.42787984e-02, ...,\n",
      "               7.21492171e-02, -1.94428295e-01, -8.44115540e-02]]],\n",
      "    \n",
      "    \n",
      "           [[[ 1.82942763e-01, -8.18129033e-02, -6.50480986e-02, ...,\n",
      "              -3.28951329e-02,  1.11755855e-01, -1.93311468e-01],\n",
      "             [ 6.88859448e-02,  1.05793223e-01, -3.78636196e-02, ...,\n",
      "              -1.24510430e-01, -1.39778003e-01,  5.25865369e-02],\n",
      "             [ 6.43820912e-02, -4.60356027e-02, -1.58389047e-01, ...,\n",
      "              -1.41978385e-02,  2.69474909e-02,  1.35781392e-01]],\n",
      "    \n",
      "            [[ 1.08313477e-02,  8.51419717e-02,  9.51005705e-03, ...,\n",
      "               1.34007007e-01,  8.09658617e-02, -3.71751608e-03],\n",
      "             [-1.57593071e-01,  7.20410347e-02, -3.25790830e-02, ...,\n",
      "              -7.64965490e-02,  5.53848557e-02, -7.33073801e-03],\n",
      "             [ 4.44678366e-02, -1.98039442e-01,  4.25111242e-02, ...,\n",
      "              -6.98965567e-04, -6.23266958e-02, -1.28207669e-01]],\n",
      "    \n",
      "            [[ 1.73923433e-01, -1.82014033e-01,  1.99949592e-01, ...,\n",
      "               1.08951762e-01,  1.37633190e-01, -7.67332837e-02],\n",
      "             [ 1.78947002e-01, -1.05287030e-01, -1.78546026e-01, ...,\n",
      "               4.18139920e-02,  1.19867198e-01, -5.30888252e-02],\n",
      "             [ 1.23708047e-01,  8.57422501e-02, -8.08505341e-02, ...,\n",
      "               6.55694902e-02,  1.19448610e-01, -2.02073436e-02]],\n",
      "    \n",
      "            ...,\n",
      "    \n",
      "            [[-5.52293323e-02, -1.73223298e-02, -5.15250005e-02, ...,\n",
      "              -2.60589927e-01, -2.89728567e-02,  8.53877664e-02],\n",
      "             [ 2.05206409e-01, -2.08407059e-01,  1.54277846e-01, ...,\n",
      "              -9.81937908e-03, -7.25610703e-02, -3.35084088e-02],\n",
      "             [ 7.93058239e-03, -4.96752821e-02,  4.48598005e-02, ...,\n",
      "              -1.96584761e-01,  1.00772962e-01, -3.94208394e-02]],\n",
      "    \n",
      "            [[ 6.71999678e-02,  1.73313782e-01,  2.93664597e-02, ...,\n",
      "               5.67325018e-02, -5.00684567e-02,  1.11726359e-01],\n",
      "             [ 1.38092965e-01, -1.90900519e-01,  2.08595954e-02, ...,\n",
      "               4.12898026e-02,  2.09918916e-01,  1.04889885e-01],\n",
      "             [ 5.27262837e-02,  1.54369742e-01,  1.67765431e-02, ...,\n",
      "              -6.49158955e-02, -1.98975384e-01,  9.15587470e-02]],\n",
      "    \n",
      "            [[ 1.21292941e-01,  2.61825696e-02,  7.50790834e-02, ...,\n",
      "               7.48665407e-02, -1.71162244e-02,  2.04452112e-01],\n",
      "             [ 7.71558732e-02,  8.79929215e-02,  2.91220881e-02, ...,\n",
      "              -2.75771040e-02, -1.71310008e-01, -2.05015957e-01],\n",
      "             [ 2.61003301e-02,  7.40160421e-02, -1.57126129e-01, ...,\n",
      "               4.59693894e-02, -1.56030869e-02,  4.71492670e-02]]],\n",
      "    \n",
      "    \n",
      "           [[[ 5.18705361e-02,  9.25799385e-02, -4.54633161e-02, ...,\n",
      "              -1.85025752e-01,  1.03554344e-02,  3.04602180e-02],\n",
      "             [-9.15733650e-02,  8.38815495e-02,  9.64396750e-04, ...,\n",
      "              -4.18407880e-02,  9.77511778e-02,  1.88279059e-02],\n",
      "             [-6.69050589e-02,  2.22615927e-01, -2.02202648e-01, ...,\n",
      "               2.68423986e-02, -2.29618717e-02,  1.95339024e-01]],\n",
      "    \n",
      "            [[-2.98027899e-02, -1.23825036e-02, -4.72679548e-03, ...,\n",
      "              -2.23784283e-01, -2.03028638e-02, -1.13757990e-01],\n",
      "             [-6.01671971e-02,  6.52498528e-02, -1.52463406e-01, ...,\n",
      "               1.61664765e-02,  1.56070486e-01,  1.99765205e-01],\n",
      "             [-1.08138425e-03,  1.74854442e-01, -3.07951812e-02, ...,\n",
      "               2.00511247e-01,  2.56577320e-02, -1.06467262e-01]],\n",
      "    \n",
      "            [[ 2.44527441e-02, -4.42111716e-02, -9.53390971e-02, ...,\n",
      "              -1.34497965e-02,  7.15488195e-03,  9.86931026e-02],\n",
      "             [ 1.20191805e-01,  6.38831779e-02, -4.98587154e-02, ...,\n",
      "               6.52875677e-02,  9.09444019e-02,  2.06941679e-01],\n",
      "             [-1.89792797e-01, -2.77121440e-02, -9.00824070e-02, ...,\n",
      "               1.40164331e-01,  1.09205008e-01, -1.37078285e-01]],\n",
      "    \n",
      "            ...,\n",
      "    \n",
      "            [[-1.48054764e-01,  2.90305130e-02, -1.91400170e-01, ...,\n",
      "               5.24067134e-02,  3.07518840e-02,  4.91254106e-02],\n",
      "             [-1.00802153e-01, -2.14555293e-01, -1.29172012e-01, ...,\n",
      "               1.55810356e-01, -1.18614532e-01,  1.55882500e-02],\n",
      "             [ 6.24768576e-03, -1.86250567e-01, -2.27873698e-01, ...,\n",
      "               3.64947878e-02, -6.01969212e-02,  6.99269958e-03]],\n",
      "    \n",
      "            [[ 1.28245413e-01, -8.93764272e-02, -2.15834565e-02, ...,\n",
      "              -1.63186938e-01,  1.36647627e-01, -1.75899312e-01],\n",
      "             [-1.03763625e-01, -2.95581091e-02,  5.59201743e-03, ...,\n",
      "               7.47436378e-03,  1.10236563e-01,  3.99365053e-02],\n",
      "             [ 9.58012193e-02, -1.53220743e-01, -2.66150720e-02, ...,\n",
      "              -2.00559318e-01, -4.89554890e-02,  3.05318180e-02]],\n",
      "    \n",
      "            [[ 3.92769910e-02,  1.67552739e-01, -3.91807668e-02, ...,\n",
      "              -1.11705367e-03, -2.08108023e-01,  2.52939388e-03],\n",
      "             [-7.16665834e-02,  1.22348018e-01,  6.68843240e-02, ...,\n",
      "              -2.32481323e-02, -8.43867958e-02,  8.99919495e-02],\n",
      "             [-1.21405385e-01,  7.25267828e-02,  2.32462194e-02, ...,\n",
      "              -1.94767132e-01, -1.20492391e-01,  2.04466000e-01]]]],\n",
      "          dtype=float32)>). Make sure the slot variables are created under the same strategy scope. This may happen if you're restoring from a checkpoint outside the scope\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n",
      "    yield\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_run.py\", line 346, in run\n",
      "    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 695, in wrapper\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "ValueError: in user code:\n",
      "\n",
      "    /tmp/ipykernel_790/3116605721.py:70 train_step  *\n",
      "        self.optimizer.apply_gradients(\n",
      "    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:628 apply_gradients  **\n",
      "        self._create_all_weights(var_list)\n",
      "    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:815 _create_all_weights\n",
      "        self._create_slots(var_list)\n",
      "    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:117 _create_slots\n",
      "        self.add_slot(var, 'm')\n",
      "    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:892 add_slot\n",
      "        raise ValueError(\n",
      "\n",
      "    ValueError: Trying to create optimizer slot variable under the scope for tf.distribute.Strategy (<tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7fe3bde54070>), which is different from the scope used for the original variable (<tf.Variable 'conv2d_1/kernel:0' shape=(7, 7, 3, 64) dtype=float32, numpy=\n",
      "    array([[[[ 6.13027476e-02,  1.50614455e-01,  1.35345340e-01, ...,\n",
      "              -8.16099793e-02,  7.15045482e-02, -8.85434896e-02],\n",
      "             [-6.29635602e-02, -6.45009577e-02,  6.59904853e-02, ...,\n",
      "               4.35089208e-02,  2.15629488e-02,  2.57276475e-01],\n",
      "             [ 1.00521408e-01, -1.51722565e-01,  9.92045775e-02, ...,\n",
      "              -9.40072984e-02, -1.46815609e-02, -1.15684219e-01]],\n",
      "    \n",
      "            [[-9.80345309e-02,  1.89435855e-01, -2.37035602e-01, ...,\n",
      "               3.63893621e-02, -9.04790536e-02,  1.92969024e-01],\n",
      "             [ 2.16621935e-01, -1.02797031e-01, -1.64573925e-04, ...,\n",
      "              -1.09765165e-01, -4.60456088e-02, -2.80861929e-02],\n",
      "             [ 5.09737693e-02, -6.60286322e-02, -1.33431092e-01, ...,\n",
      "              -1.24041647e-01, -8.81058127e-02,  1.50977215e-02]],\n",
      "    \n",
      "            [[-3.01897596e-03,  5.22158742e-02,  1.65612474e-02, ...,\n",
      "              -2.43651614e-01,  6.62046224e-02, -1.80847988e-01],\n",
      "             [-9.65840742e-02, -1.45419076e-01,  2.03709617e-01, ...,\n",
      "              -7.71873444e-02,  2.29114853e-02, -1.21069320e-01],\n",
      "             [-8.00769702e-02, -1.01478718e-01,  1.00891180e-01, ...,\n",
      "               4.88331616e-02, -1.18581466e-01, -2.26025164e-01]],\n",
      "    \n",
      "            ...,\n",
      "    \n",
      "            [[ 1.35203265e-02,  2.76322067e-02, -1.44717664e-01, ...,\n",
      "               1.67539835e-01,  2.53902730e-02,  6.53840229e-02],\n",
      "             [ 8.61227289e-02,  5.12347668e-02, -1.39597639e-01, ...,\n",
      "               1.86924770e-01,  1.58347726e-01,  5.85889928e-02],\n",
      "             [-8.15377235e-02, -3.60459127e-02,  1.24675594e-02, ...,\n",
      "               3.86517122e-03, -8.50900263e-03, -7.69343972e-02]],\n",
      "    \n",
      "            [[ 1.66026592e-01,  1.49623260e-01, -2.31387913e-02, ...,\n",
      "              -6.54041320e-02, -1.24785528e-01,  1.31704941e-01],\n",
      "             [-6.64192736e-02, -1.13489442e-01,  1.60216063e-01, ...,\n",
      "              -3.09046414e-02,  5.88068701e-02, -4.45075817e-02],\n",
      "             [ 5.02059385e-02,  1.50478587e-01, -1.24967478e-01, ...,\n",
      "              -2.35792808e-02, -1.87081173e-01, -1.82202458e-03]],\n",
      "    \n",
      "            [[ 9.77816880e-02, -1.43437177e-01, -2.41182633e-02, ...,\n",
      "              -1.09410852e-01,  1.40387043e-01,  5.70664816e-02],\n",
      "             [ 2.14798331e-01, -1.96973637e-01,  2.03399867e-01, ...,\n",
      "               1.52573794e-01,  7.31504485e-02, -1.98803246e-02],\n",
      "             [ 5.21983206e-03,  9.81542990e-02, -7.46836141e-02, ...,\n",
      "               5.88658266e-02, -1.54774925e-02, -1.11802541e-01]]],\n",
      "    \n",
      "    \n",
      "           [[[ 7.43995011e-02, -3.11786756e-02,  3.34962271e-02, ...,\n",
      "               1.63646415e-01, -1.68314334e-02, -8.54853541e-02],\n",
      "             [ 1.04430266e-01, -1.40769137e-02, -1.32401913e-01, ...,\n",
      "              -1.31703451e-01,  1.18291833e-01, -1.89344719e-01],\n",
      "             [ 1.49974078e-01, -5.15702255e-02, -4.86299507e-02, ...,\n",
      "              -1.29736990e-01, -8.76289606e-02, -3.76371704e-02]],\n",
      "    \n",
      "            [[-8.01044796e-03, -2.40040213e-01, -4.81870994e-02, ...,\n",
      "               9.27171577e-03, -1.13444172e-01, -8.72101337e-02],\n",
      "             [-5.35292737e-02,  8.68863985e-02, -1.58409998e-01, ...,\n",
      "               1.55851930e-01,  9.55974590e-03,  6.06897473e-02],\n",
      "             [ 7.65984431e-02,  4.81488109e-02, -2.23900869e-01, ...,\n",
      "              -2.12638348e-01, -3.57730053e-02,  1.10168077e-01]],\n",
      "    \n",
      "            [[-3.13774236e-02, -9.63343382e-02,  1.56977430e-01, ...,\n",
      "              -4.51943576e-02, -2.04060555e-01,  9.81798321e-02],\n",
      "             [-1.87521636e-01, -2.46430308e-01,  1.55240605e-02, ...,\n",
      "              -1.04741462e-01,  1.54669628e-01,  1.00513427e-02],\n",
      "             [-8.26077834e-02,  6.01827316e-02, -1.45832434e-01, ...,\n",
      "              -2.47084014e-02, -1.86228052e-01, -7.59718008e-03]],\n",
      "    \n",
      "            ...,\n",
      "    \n",
      "            [[-1.98650762e-01,  1.63403571e-01, -2.17505336e-01, ...,\n",
      "              -1.25022501e-01,  1.50700205e-03,  6.11829832e-02],\n",
      "             [ 1.57758147e-01,  1.10434867e-01,  1.03581257e-01, ...,\n",
      "              -6.36967656e-04,  4.37583774e-02, -7.52287507e-02],\n",
      "             [-1.15172891e-03, -2.32697934e-01,  3.84797826e-02, ...,\n",
      "              -1.27419859e-01, -4.13282439e-02,  2.72780024e-02]],\n",
      "    \n",
      "            [[-1.87169820e-01,  9.76692960e-02, -4.22885753e-02, ...,\n",
      "               1.64859876e-01, -1.90731382e-03,  3.88390273e-02],\n",
      "             [ 6.44878298e-02, -4.29949947e-02,  4.66062538e-02, ...,\n",
      "              -1.00921109e-01,  9.50264186e-02, -1.41044557e-01],\n",
      "             [-1.18268281e-01,  6.36323616e-02, -4.75717883e-04, ...,\n",
      "              -7.70919770e-02,  6.90176114e-02, -9.26017538e-02]],\n",
      "    \n",
      "            [[-1.77174926e-01, -1.09059796e-01,  2.57321477e-01, ...,\n",
      "               2.14279905e-01,  3.51525508e-02, -4.04059067e-02],\n",
      "             [ 1.24453166e-02, -2.31172085e-01,  1.59734562e-01, ...,\n",
      "              -9.72141325e-02, -4.11993489e-02,  6.70645759e-02],\n",
      "             [ 1.80671969e-03, -2.23725867e-02, -1.82955608e-01, ...,\n",
      "               5.20451441e-02, -3.42951156e-02, -1.68170840e-01]]],\n",
      "    \n",
      "    \n",
      "           [[[ 4.26355489e-02,  7.08516911e-02,  2.27851477e-02, ...,\n",
      "              -1.65555432e-01, -2.32125863e-01, -4.53629717e-02],\n",
      "             [ 1.11784525e-01, -1.33745179e-01,  2.93720867e-02, ...,\n",
      "               1.87195957e-01, -5.33411540e-02, -3.95275019e-02],\n",
      "             [ 6.24825135e-02,  1.15999490e-01, -1.92222238e-01, ...,\n",
      "               8.75054970e-02,  1.74466074e-01,  5.45380078e-02]],\n",
      "    \n",
      "            [[-1.21881589e-01,  4.38498296e-02, -7.23414049e-02, ...,\n",
      "               9.86528918e-02, -1.50920851e-02,  6.44939169e-02],\n",
      "             [ 1.88989453e-02, -1.88362241e-01, -6.54458180e-02, ...,\n",
      "               1.97988749e-01,  1.69605762e-01, -1.03346892e-01],\n",
      "             [-5.94289042e-02, -9.17370170e-02,  1.96886927e-01, ...,\n",
      "               1.30331054e-01, -2.43689463e-01, -1.35739595e-01]],\n",
      "    \n",
      "            [[ 2.38891795e-01, -1.43961757e-01, -9.46223140e-02, ...,\n",
      "               6.54063299e-02, -1.12381577e-02,  3.47842425e-02],\n",
      "             [-1.24086522e-01,  9.33054239e-02, -1.71027740e-03, ...,\n",
      "              -1.03802510e-01, -1.44332871e-01,  5.87318987e-02],\n",
      "             [ 2.63413131e-01, -7.97889370e-04, -8.63094404e-02, ...,\n",
      "              -4.97243134e-03,  2.32819375e-03,  6.36920407e-02]],\n",
      "    \n",
      "            ...,\n",
      "    \n",
      "            [[ 4.39061895e-02, -3.06197144e-02,  8.19719583e-02, ...,\n",
      "               5.70775308e-02,  2.36131266e-01, -2.16464344e-02],\n",
      "             [ 1.58768788e-01, -1.44167338e-02,  1.66579440e-01, ...,\n",
      "               2.32374817e-02,  3.99878994e-02,  2.65069008e-01],\n",
      "             [-9.17340443e-03,  9.61398333e-02,  1.42653644e-01, ...,\n",
      "               8.60497877e-02, -1.56885013e-01, -2.45002419e-01]],\n",
      "    \n",
      "            [[ 3.78528871e-02, -4.50962633e-02,  2.17729837e-01, ...,\n",
      "              -7.20090494e-02, -1.03469238e-01, -2.47531980e-01],\n",
      "             [-9.78876948e-02, -2.15603426e-01,  2.57111993e-02, ...,\n",
      "               9.55697894e-02,  8.25565867e-03, -1.76898494e-01],\n",
      "             [-1.48313567e-01, -1.53920949e-01,  1.48660854e-01, ...,\n",
      "              -3.63829024e-02,  1.68311447e-01,  2.36072749e-01]],\n",
      "    \n",
      "            [[-7.60350004e-02,  2.57441364e-02,  1.55617103e-01, ...,\n",
      "              -1.51833028e-01, -2.96167843e-02, -1.05702221e-01],\n",
      "             [ 6.35700487e-03,  1.19157456e-01, -1.14801116e-02, ...,\n",
      "               1.77513450e-01, -5.99536579e-03, -7.12867975e-02],\n",
      "             [ 3.88280638e-02, -4.55495762e-03,  1.19555937e-02, ...,\n",
      "              -4.38393056e-02, -1.00527555e-01, -2.49935798e-02]]],\n",
      "    \n",
      "    \n",
      "           ...,\n",
      "    \n",
      "    \n",
      "           [[[ 1.22513577e-01,  5.09266648e-03, -8.53807628e-02, ...,\n",
      "              -4.58052615e-03, -1.68446988e-01, -2.58252531e-01],\n",
      "             [-2.14745346e-02,  1.63010120e-01, -9.59499255e-02, ...,\n",
      "              -6.83643371e-02, -1.53660802e-02, -2.36012965e-01],\n",
      "             [-1.70981824e-01, -1.40343681e-01,  2.26165846e-01, ...,\n",
      "              -3.32186744e-02,  1.70948461e-01, -8.36032704e-02]],\n",
      "    \n",
      "            [[-2.35205576e-01,  5.70198856e-02,  1.68733433e-01, ...,\n",
      "              -1.08057626e-01, -9.40405112e-03,  1.75195873e-01],\n",
      "             [ 2.64507532e-01, -1.91123098e-01, -1.61637619e-01, ...,\n",
      "               6.51448518e-02, -2.10690424e-02,  1.45839348e-01],\n",
      "             [ 1.39066324e-01, -5.14815859e-02,  2.19909810e-02, ...,\n",
      "               5.60113881e-03, -1.17751718e-01, -1.44344121e-01]],\n",
      "    \n",
      "            [[ 4.54274043e-02,  1.57887377e-02,  1.67322367e-01, ...,\n",
      "               9.58062708e-02,  1.19645859e-03, -1.23345762e-01],\n",
      "             [-3.60198915e-02, -2.64056563e-01, -9.42556038e-02, ...,\n",
      "              -1.68050960e-01, -2.11052999e-01, -4.06056568e-02],\n",
      "             [-1.45537816e-02,  1.73526824e-01,  6.66935593e-02, ...,\n",
      "               1.35415448e-02, -5.84160127e-02, -5.43588661e-02]],\n",
      "    \n",
      "            ...,\n",
      "    \n",
      "            [[-7.06954151e-02, -1.57525837e-02, -6.17827736e-02, ...,\n",
      "               4.98971902e-02, -1.35388508e-01,  1.19418912e-01],\n",
      "             [-7.34979659e-02, -9.36273858e-02,  4.66608108e-05, ...,\n",
      "              -2.12430488e-02,  1.30864397e-01,  2.23309956e-02],\n",
      "             [ 1.05640348e-02,  1.14529040e-02, -1.98482163e-02, ...,\n",
      "              -3.01012192e-02,  3.05300076e-02,  1.01408176e-02]],\n",
      "    \n",
      "            [[ 6.65159523e-02, -6.20860606e-02,  1.73784435e-01, ...,\n",
      "              -1.11620888e-01, -1.10321261e-01, -9.86246988e-02],\n",
      "             [ 1.92608505e-01,  1.04694196e-03,  6.53823167e-02, ...,\n",
      "              -2.04312056e-01, -1.18431769e-01,  1.71276495e-01],\n",
      "             [ 6.37844801e-02, -1.83133736e-01, -5.33691421e-03, ...,\n",
      "               1.10962778e-01,  1.49894720e-02, -2.65677460e-02]],\n",
      "    \n",
      "            [[ 1.54260352e-01, -1.84997752e-01,  2.22448170e-01, ...,\n",
      "               1.06664814e-01,  2.46161804e-01, -1.50213555e-01],\n",
      "             [ 1.95108657e-03,  1.25695586e-01,  1.11226246e-01, ...,\n",
      "               1.00337654e-01, -4.07159738e-02,  5.33722788e-02],\n",
      "             [-4.67980653e-02,  1.68124102e-02, -5.42787984e-02, ...,\n",
      "               7.21492171e-02, -1.94428295e-01, -8.44115540e-02]]],\n",
      "    \n",
      "    \n",
      "           [[[ 1.82942763e-01, -8.18129033e-02, -6.50480986e-02, ...,\n",
      "              -3.28951329e-02,  1.11755855e-01, -1.93311468e-01],\n",
      "             [ 6.88859448e-02,  1.05793223e-01, -3.78636196e-02, ...,\n",
      "              -1.24510430e-01, -1.39778003e-01,  5.25865369e-02],\n",
      "             [ 6.43820912e-02, -4.60356027e-02, -1.58389047e-01, ...,\n",
      "              -1.41978385e-02,  2.69474909e-02,  1.35781392e-01]],\n",
      "    \n",
      "            [[ 1.08313477e-02,  8.51419717e-02,  9.51005705e-03, ...,\n",
      "               1.34007007e-01,  8.09658617e-02, -3.71751608e-03],\n",
      "             [-1.57593071e-01,  7.20410347e-02, -3.25790830e-02, ...,\n",
      "              -7.64965490e-02,  5.53848557e-02, -7.33073801e-03],\n",
      "             [ 4.44678366e-02, -1.98039442e-01,  4.25111242e-02, ...,\n",
      "              -6.98965567e-04, -6.23266958e-02, -1.28207669e-01]],\n",
      "    \n",
      "            [[ 1.73923433e-01, -1.82014033e-01,  1.99949592e-01, ...,\n",
      "               1.08951762e-01,  1.37633190e-01, -7.67332837e-02],\n",
      "             [ 1.78947002e-01, -1.05287030e-01, -1.78546026e-01, ...,\n",
      "               4.18139920e-02,  1.19867198e-01, -5.30888252e-02],\n",
      "             [ 1.23708047e-01,  8.57422501e-02, -8.08505341e-02, ...,\n",
      "               6.55694902e-02,  1.19448610e-01, -2.02073436e-02]],\n",
      "    \n",
      "            ...,\n",
      "    \n",
      "            [[-5.52293323e-02, -1.73223298e-02, -5.15250005e-02, ...,\n",
      "              -2.60589927e-01, -2.89728567e-02,  8.53877664e-02],\n",
      "             [ 2.05206409e-01, -2.08407059e-01,  1.54277846e-01, ...,\n",
      "              -9.81937908e-03, -7.25610703e-02, -3.35084088e-02],\n",
      "             [ 7.93058239e-03, -4.96752821e-02,  4.48598005e-02, ...,\n",
      "              -1.96584761e-01,  1.00772962e-01, -3.94208394e-02]],\n",
      "    \n",
      "            [[ 6.71999678e-02,  1.73313782e-01,  2.93664597e-02, ...,\n",
      "               5.67325018e-02, -5.00684567e-02,  1.11726359e-01],\n",
      "             [ 1.38092965e-01, -1.90900519e-01,  2.08595954e-02, ...,\n",
      "               4.12898026e-02,  2.09918916e-01,  1.04889885e-01],\n",
      "             [ 5.27262837e-02,  1.54369742e-01,  1.67765431e-02, ...,\n",
      "              -6.49158955e-02, -1.98975384e-01,  9.15587470e-02]],\n",
      "    \n",
      "            [[ 1.21292941e-01,  2.61825696e-02,  7.50790834e-02, ...,\n",
      "               7.48665407e-02, -1.71162244e-02,  2.04452112e-01],\n",
      "             [ 7.71558732e-02,  8.79929215e-02,  2.91220881e-02, ...,\n",
      "              -2.75771040e-02, -1.71310008e-01, -2.05015957e-01],\n",
      "             [ 2.61003301e-02,  7.40160421e-02, -1.57126129e-01, ...,\n",
      "               4.59693894e-02, -1.56030869e-02,  4.71492670e-02]]],\n",
      "    \n",
      "    \n",
      "           [[[ 5.18705361e-02,  9.25799385e-02, -4.54633161e-02, ...,\n",
      "              -1.85025752e-01,  1.03554344e-02,  3.04602180e-02],\n",
      "             [-9.15733650e-02,  8.38815495e-02,  9.64396750e-04, ...,\n",
      "              -4.18407880e-02,  9.77511778e-02,  1.88279059e-02],\n",
      "             [-6.69050589e-02,  2.22615927e-01, -2.02202648e-01, ...,\n",
      "               2.68423986e-02, -2.29618717e-02,  1.95339024e-01]],\n",
      "    \n",
      "            [[-2.98027899e-02, -1.23825036e-02, -4.72679548e-03, ...,\n",
      "              -2.23784283e-01, -2.03028638e-02, -1.13757990e-01],\n",
      "             [-6.01671971e-02,  6.52498528e-02, -1.52463406e-01, ...,\n",
      "               1.61664765e-02,  1.56070486e-01,  1.99765205e-01],\n",
      "             [-1.08138425e-03,  1.74854442e-01, -3.07951812e-02, ...,\n",
      "               2.00511247e-01,  2.56577320e-02, -1.06467262e-01]],\n",
      "    \n",
      "            [[ 2.44527441e-02, -4.42111716e-02, -9.53390971e-02, ...,\n",
      "              -1.34497965e-02,  7.15488195e-03,  9.86931026e-02],\n",
      "             [ 1.20191805e-01,  6.38831779e-02, -4.98587154e-02, ...,\n",
      "               6.52875677e-02,  9.09444019e-02,  2.06941679e-01],\n",
      "             [-1.89792797e-01, -2.77121440e-02, -9.00824070e-02, ...,\n",
      "               1.40164331e-01,  1.09205008e-01, -1.37078285e-01]],\n",
      "    \n",
      "            ...,\n",
      "    \n",
      "            [[-1.48054764e-01,  2.90305130e-02, -1.91400170e-01, ...,\n",
      "               5.24067134e-02,  3.07518840e-02,  4.91254106e-02],\n",
      "             [-1.00802153e-01, -2.14555293e-01, -1.29172012e-01, ...,\n",
      "               1.55810356e-01, -1.18614532e-01,  1.55882500e-02],\n",
      "             [ 6.24768576e-03, -1.86250567e-01, -2.27873698e-01, ...,\n",
      "               3.64947878e-02, -6.01969212e-02,  6.99269958e-03]],\n",
      "    \n",
      "            [[ 1.28245413e-01, -8.93764272e-02, -2.15834565e-02, ...,\n",
      "              -1.63186938e-01,  1.36647627e-01, -1.75899312e-01],\n",
      "             [-1.03763625e-01, -2.95581091e-02,  5.59201743e-03, ...,\n",
      "               7.47436378e-03,  1.10236563e-01,  3.99365053e-02],\n",
      "             [ 9.58012193e-02, -1.53220743e-01, -2.66150720e-02, ...,\n",
      "              -2.00559318e-01, -4.89554890e-02,  3.05318180e-02]],\n",
      "    \n",
      "            [[ 3.92769910e-02,  1.67552739e-01, -3.91807668e-02, ...,\n",
      "              -1.11705367e-03, -2.08108023e-01,  2.52939388e-03],\n",
      "             [-7.16665834e-02,  1.22348018e-01,  6.68843240e-02, ...,\n",
      "              -2.32481323e-02, -8.43867958e-02,  8.99919495e-02],\n",
      "             [-1.21405385e-01,  7.25267828e-02,  2.32462194e-02, ...,\n",
      "              -1.94767132e-01, -1.20492391e-01,  2.04466000e-01]]]],\n",
      "          dtype=float32)>). Make sure the slot variables are created under the same strategy scope. This may happen if you're restoring from a checkpoint outside the scope\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /tmp/ipykernel_790/3116605721.py:93 distributed_train_epoch  *\n        per_replica_loss = self.strategy.run(\n    /tmp/ipykernel_790/3116605721.py:70 train_step  *\n        self.optimizer.apply_gradients(\n    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:628 apply_gradients  **\n        self._create_all_weights(var_list)\n    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:815 _create_all_weights\n        self._create_slots(var_list)\n    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:117 _create_slots\n        self.add_slot(var, 'm')\n    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:892 add_slot\n        raise ValueError(\n\n    ValueError: Trying to create optimizer slot variable under the scope for tf.distribute.Strategy (<tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7fe3bde54070>), which is different from the scope used for the original variable (<tf.Variable 'conv2d_1/kernel:0' shape=(7, 7, 3, 64) dtype=float32, numpy=\n    array([[[[ 6.13027476e-02,  1.50614455e-01,  1.35345340e-01, ...,\n              -8.16099793e-02,  7.15045482e-02, -8.85434896e-02],\n             [-6.29635602e-02, -6.45009577e-02,  6.59904853e-02, ...,\n               4.35089208e-02,  2.15629488e-02,  2.57276475e-01],\n             [ 1.00521408e-01, -1.51722565e-01,  9.92045775e-02, ...,\n              -9.40072984e-02, -1.46815609e-02, -1.15684219e-01]],\n    \n            [[-9.80345309e-02,  1.89435855e-01, -2.37035602e-01, ...,\n               3.63893621e-02, -9.04790536e-02,  1.92969024e-01],\n             [ 2.16621935e-01, -1.02797031e-01, -1.64573925e-04, ...,\n              -1.09765165e-01, -4.60456088e-02, -2.80861929e-02],\n             [ 5.09737693e-02, -6.60286322e-02, -1.33431092e-01, ...,\n              -1.24041647e-01, -8.81058127e-02,  1.50977215e-02]],\n    \n            [[-3.01897596e-03,  5.22158742e-02,  1.65612474e-02, ...,\n              -2.43651614e-01,  6.62046224e-02, -1.80847988e-01],\n             [-9.65840742e-02, -1.45419076e-01,  2.03709617e-01, ...,\n              -7.71873444e-02,  2.29114853e-02, -1.21069320e-01],\n             [-8.00769702e-02, -1.01478718e-01,  1.00891180e-01, ...,\n               4.88331616e-02, -1.18581466e-01, -2.26025164e-01]],\n    \n            ...,\n    \n            [[ 1.35203265e-02,  2.76322067e-02, -1.44717664e-01, ...,\n               1.67539835e-01,  2.53902730e-02,  6.53840229e-02],\n             [ 8.61227289e-02,  5.12347668e-02, -1.39597639e-01, ...,\n               1.86924770e-01,  1.58347726e-01,  5.85889928e-02],\n             [-8.15377235e-02, -3.60459127e-02,  1.24675594e-02, ...,\n               3.86517122e-03, -8.50900263e-03, -7.69343972e-02]],\n    \n            [[ 1.66026592e-01,  1.49623260e-01, -2.31387913e-02, ...,\n              -6.54041320e-02, -1.24785528e-01,  1.31704941e-01],\n             [-6.64192736e-02, -1.13489442e-01,  1.60216063e-01, ...,\n              -3.09046414e-02,  5.88068701e-02, -4.45075817e-02],\n             [ 5.02059385e-02,  1.50478587e-01, -1.24967478e-01, ...,\n              -2.35792808e-02, -1.87081173e-01, -1.82202458e-03]],\n    \n            [[ 9.77816880e-02, -1.43437177e-01, -2.41182633e-02, ...,\n              -1.09410852e-01,  1.40387043e-01,  5.70664816e-02],\n             [ 2.14798331e-01, -1.96973637e-01,  2.03399867e-01, ...,\n               1.52573794e-01,  7.31504485e-02, -1.98803246e-02],\n             [ 5.21983206e-03,  9.81542990e-02, -7.46836141e-02, ...,\n               5.88658266e-02, -1.54774925e-02, -1.11802541e-01]]],\n    \n    \n           [[[ 7.43995011e-02, -3.11786756e-02,  3.34962271e-02, ...,\n               1.63646415e-01, -1.68314334e-02, -8.54853541e-02],\n             [ 1.04430266e-01, -1.40769137e-02, -1.32401913e-01, ...,\n              -1.31703451e-01,  1.18291833e-01, -1.89344719e-01],\n             [ 1.49974078e-01, -5.15702255e-02, -4.86299507e-02, ...,\n              -1.29736990e-01, -8.76289606e-02, -3.76371704e-02]],\n    \n            [[-8.01044796e-03, -2.40040213e-01, -4.81870994e-02, ...,\n               9.27171577e-03, -1.13444172e-01, -8.72101337e-02],\n             [-5.35292737e-02,  8.68863985e-02, -1.58409998e-01, ...,\n               1.55851930e-01,  9.55974590e-03,  6.06897473e-02],\n             [ 7.65984431e-02,  4.81488109e-02, -2.23900869e-01, ...,\n              -2.12638348e-01, -3.57730053e-02,  1.10168077e-01]],\n    \n            [[-3.13774236e-02, -9.63343382e-02,  1.56977430e-01, ...,\n              -4.51943576e-02, -2.04060555e-01,  9.81798321e-02],\n             [-1.87521636e-01, -2.46430308e-01,  1.55240605e-02, ...,\n              -1.04741462e-01,  1.54669628e-01,  1.00513427e-02],\n             [-8.26077834e-02,  6.01827316e-02, -1.45832434e-01, ...,\n              -2.47084014e-02, -1.86228052e-01, -7.59718008e-03]],\n    \n            ...,\n    \n            [[-1.98650762e-01,  1.63403571e-01, -2.17505336e-01, ...,\n              -1.25022501e-01,  1.50700205e-03,  6.11829832e-02],\n             [ 1.57758147e-01,  1.10434867e-01,  1.03581257e-01, ...,\n              -6.36967656e-04,  4.37583774e-02, -7.52287507e-02],\n             [-1.15172891e-03, -2.32697934e-01,  3.84797826e-02, ...,\n              -1.27419859e-01, -4.13282439e-02,  2.72780024e-02]],\n    \n            [[-1.87169820e-01,  9.76692960e-02, -4.22885753e-02, ...,\n               1.64859876e-01, -1.90731382e-03,  3.88390273e-02],\n             [ 6.44878298e-02, -4.29949947e-02,  4.66062538e-02, ...,\n              -1.00921109e-01,  9.50264186e-02, -1.41044557e-01],\n             [-1.18268281e-01,  6.36323616e-02, -4.75717883e-04, ...,\n              -7.70919770e-02,  6.90176114e-02, -9.26017538e-02]],\n    \n            [[-1.77174926e-01, -1.09059796e-01,  2.57321477e-01, ...,\n               2.14279905e-01,  3.51525508e-02, -4.04059067e-02],\n             [ 1.24453166e-02, -2.31172085e-01,  1.59734562e-01, ...,\n              -9.72141325e-02, -4.11993489e-02,  6.70645759e-02],\n             [ 1.80671969e-03, -2.23725867e-02, -1.82955608e-01, ...,\n               5.20451441e-02, -3.42951156e-02, -1.68170840e-01]]],\n    \n    \n           [[[ 4.26355489e-02,  7.08516911e-02,  2.27851477e-02, ...,\n              -1.65555432e-01, -2.32125863e-01, -4.53629717e-02],\n             [ 1.11784525e-01, -1.33745179e-01,  2.93720867e-02, ...,\n               1.87195957e-01, -5.33411540e-02, -3.95275019e-02],\n             [ 6.24825135e-02,  1.15999490e-01, -1.92222238e-01, ...,\n               8.75054970e-02,  1.74466074e-01,  5.45380078e-02]],\n    \n            [[-1.21881589e-01,  4.38498296e-02, -7.23414049e-02, ...,\n               9.86528918e-02, -1.50920851e-02,  6.44939169e-02],\n             [ 1.88989453e-02, -1.88362241e-01, -6.54458180e-02, ...,\n               1.97988749e-01,  1.69605762e-01, -1.03346892e-01],\n             [-5.94289042e-02, -9.17370170e-02,  1.96886927e-01, ...,\n               1.30331054e-01, -2.43689463e-01, -1.35739595e-01]],\n    \n            [[ 2.38891795e-01, -1.43961757e-01, -9.46223140e-02, ...,\n               6.54063299e-02, -1.12381577e-02,  3.47842425e-02],\n             [-1.24086522e-01,  9.33054239e-02, -1.71027740e-03, ...,\n              -1.03802510e-01, -1.44332871e-01,  5.87318987e-02],\n             [ 2.63413131e-01, -7.97889370e-04, -8.63094404e-02, ...,\n              -4.97243134e-03,  2.32819375e-03,  6.36920407e-02]],\n    \n            ...,\n    \n            [[ 4.39061895e-02, -3.06197144e-02,  8.19719583e-02, ...,\n               5.70775308e-02,  2.36131266e-01, -2.16464344e-02],\n             [ 1.58768788e-01, -1.44167338e-02,  1.66579440e-01, ...,\n               2.32374817e-02,  3.99878994e-02,  2.65069008e-01],\n             [-9.17340443e-03,  9.61398333e-02,  1.42653644e-01, ...,\n               8.60497877e-02, -1.56885013e-01, -2.45002419e-01]],\n    \n            [[ 3.78528871e-02, -4.50962633e-02,  2.17729837e-01, ...,\n              -7.20090494e-02, -1.03469238e-01, -2.47531980e-01],\n             [-9.78876948e-02, -2.15603426e-01,  2.57111993e-02, ...,\n               9.55697894e-02,  8.25565867e-03, -1.76898494e-01],\n             [-1.48313567e-01, -1.53920949e-01,  1.48660854e-01, ...,\n              -3.63829024e-02,  1.68311447e-01,  2.36072749e-01]],\n    \n            [[-7.60350004e-02,  2.57441364e-02,  1.55617103e-01, ...,\n              -1.51833028e-01, -2.96167843e-02, -1.05702221e-01],\n             [ 6.35700487e-03,  1.19157456e-01, -1.14801116e-02, ...,\n               1.77513450e-01, -5.99536579e-03, -7.12867975e-02],\n             [ 3.88280638e-02, -4.55495762e-03,  1.19555937e-02, ...,\n              -4.38393056e-02, -1.00527555e-01, -2.49935798e-02]]],\n    \n    \n           ...,\n    \n    \n           [[[ 1.22513577e-01,  5.09266648e-03, -8.53807628e-02, ...,\n              -4.58052615e-03, -1.68446988e-01, -2.58252531e-01],\n             [-2.14745346e-02,  1.63010120e-01, -9.59499255e-02, ...,\n              -6.83643371e-02, -1.53660802e-02, -2.36012965e-01],\n             [-1.70981824e-01, -1.40343681e-01,  2.26165846e-01, ...,\n              -3.32186744e-02,  1.70948461e-01, -8.36032704e-02]],\n    \n            [[-2.35205576e-01,  5.70198856e-02,  1.68733433e-01, ...,\n              -1.08057626e-01, -9.40405112e-03,  1.75195873e-01],\n             [ 2.64507532e-01, -1.91123098e-01, -1.61637619e-01, ...,\n               6.51448518e-02, -2.10690424e-02,  1.45839348e-01],\n             [ 1.39066324e-01, -5.14815859e-02,  2.19909810e-02, ...,\n               5.60113881e-03, -1.17751718e-01, -1.44344121e-01]],\n    \n            [[ 4.54274043e-02,  1.57887377e-02,  1.67322367e-01, ...,\n               9.58062708e-02,  1.19645859e-03, -1.23345762e-01],\n             [-3.60198915e-02, -2.64056563e-01, -9.42556038e-02, ...,\n              -1.68050960e-01, -2.11052999e-01, -4.06056568e-02],\n             [-1.45537816e-02,  1.73526824e-01,  6.66935593e-02, ...,\n               1.35415448e-02, -5.84160127e-02, -5.43588661e-02]],\n    \n            ...,\n    \n            [[-7.06954151e-02, -1.57525837e-02, -6.17827736e-02, ...,\n               4.98971902e-02, -1.35388508e-01,  1.19418912e-01],\n             [-7.34979659e-02, -9.36273858e-02,  4.66608108e-05, ...,\n              -2.12430488e-02,  1.30864397e-01,  2.23309956e-02],\n             [ 1.05640348e-02,  1.14529040e-02, -1.98482163e-02, ...,\n              -3.01012192e-02,  3.05300076e-02,  1.01408176e-02]],\n    \n            [[ 6.65159523e-02, -6.20860606e-02,  1.73784435e-01, ...,\n              -1.11620888e-01, -1.10321261e-01, -9.86246988e-02],\n             [ 1.92608505e-01,  1.04694196e-03,  6.53823167e-02, ...,\n              -2.04312056e-01, -1.18431769e-01,  1.71276495e-01],\n             [ 6.37844801e-02, -1.83133736e-01, -5.33691421e-03, ...,\n               1.10962778e-01,  1.49894720e-02, -2.65677460e-02]],\n    \n            [[ 1.54260352e-01, -1.84997752e-01,  2.22448170e-01, ...,\n               1.06664814e-01,  2.46161804e-01, -1.50213555e-01],\n             [ 1.95108657e-03,  1.25695586e-01,  1.11226246e-01, ...,\n               1.00337654e-01, -4.07159738e-02,  5.33722788e-02],\n             [-4.67980653e-02,  1.68124102e-02, -5.42787984e-02, ...,\n               7.21492171e-02, -1.94428295e-01, -8.44115540e-02]]],\n    \n    \n           [[[ 1.82942763e-01, -8.18129033e-02, -6.50480986e-02, ...,\n              -3.28951329e-02,  1.11755855e-01, -1.93311468e-01],\n             [ 6.88859448e-02,  1.05793223e-01, -3.78636196e-02, ...,\n              -1.24510430e-01, -1.39778003e-01,  5.25865369e-02],\n             [ 6.43820912e-02, -4.60356027e-02, -1.58389047e-01, ...,\n              -1.41978385e-02,  2.69474909e-02,  1.35781392e-01]],\n    \n            [[ 1.08313477e-02,  8.51419717e-02,  9.51005705e-03, ...,\n               1.34007007e-01,  8.09658617e-02, -3.71751608e-03],\n             [-1.57593071e-01,  7.20410347e-02, -3.25790830e-02, ...,\n              -7.64965490e-02,  5.53848557e-02, -7.33073801e-03],\n             [ 4.44678366e-02, -1.98039442e-01,  4.25111242e-02, ...,\n              -6.98965567e-04, -6.23266958e-02, -1.28207669e-01]],\n    \n            [[ 1.73923433e-01, -1.82014033e-01,  1.99949592e-01, ...,\n               1.08951762e-01,  1.37633190e-01, -7.67332837e-02],\n             [ 1.78947002e-01, -1.05287030e-01, -1.78546026e-01, ...,\n               4.18139920e-02,  1.19867198e-01, -5.30888252e-02],\n             [ 1.23708047e-01,  8.57422501e-02, -8.08505341e-02, ...,\n               6.55694902e-02,  1.19448610e-01, -2.02073436e-02]],\n    \n            ...,\n    \n            [[-5.52293323e-02, -1.73223298e-02, -5.15250005e-02, ...,\n              -2.60589927e-01, -2.89728567e-02,  8.53877664e-02],\n             [ 2.05206409e-01, -2.08407059e-01,  1.54277846e-01, ...,\n              -9.81937908e-03, -7.25610703e-02, -3.35084088e-02],\n             [ 7.93058239e-03, -4.96752821e-02,  4.48598005e-02, ...,\n              -1.96584761e-01,  1.00772962e-01, -3.94208394e-02]],\n    \n            [[ 6.71999678e-02,  1.73313782e-01,  2.93664597e-02, ...,\n               5.67325018e-02, -5.00684567e-02,  1.11726359e-01],\n             [ 1.38092965e-01, -1.90900519e-01,  2.08595954e-02, ...,\n               4.12898026e-02,  2.09918916e-01,  1.04889885e-01],\n             [ 5.27262837e-02,  1.54369742e-01,  1.67765431e-02, ...,\n              -6.49158955e-02, -1.98975384e-01,  9.15587470e-02]],\n    \n            [[ 1.21292941e-01,  2.61825696e-02,  7.50790834e-02, ...,\n               7.48665407e-02, -1.71162244e-02,  2.04452112e-01],\n             [ 7.71558732e-02,  8.79929215e-02,  2.91220881e-02, ...,\n              -2.75771040e-02, -1.71310008e-01, -2.05015957e-01],\n             [ 2.61003301e-02,  7.40160421e-02, -1.57126129e-01, ...,\n               4.59693894e-02, -1.56030869e-02,  4.71492670e-02]]],\n    \n    \n           [[[ 5.18705361e-02,  9.25799385e-02, -4.54633161e-02, ...,\n              -1.85025752e-01,  1.03554344e-02,  3.04602180e-02],\n             [-9.15733650e-02,  8.38815495e-02,  9.64396750e-04, ...,\n              -4.18407880e-02,  9.77511778e-02,  1.88279059e-02],\n             [-6.69050589e-02,  2.22615927e-01, -2.02202648e-01, ...,\n               2.68423986e-02, -2.29618717e-02,  1.95339024e-01]],\n    \n            [[-2.98027899e-02, -1.23825036e-02, -4.72679548e-03, ...,\n              -2.23784283e-01, -2.03028638e-02, -1.13757990e-01],\n             [-6.01671971e-02,  6.52498528e-02, -1.52463406e-01, ...,\n               1.61664765e-02,  1.56070486e-01,  1.99765205e-01],\n             [-1.08138425e-03,  1.74854442e-01, -3.07951812e-02, ...,\n               2.00511247e-01,  2.56577320e-02, -1.06467262e-01]],\n    \n            [[ 2.44527441e-02, -4.42111716e-02, -9.53390971e-02, ...,\n              -1.34497965e-02,  7.15488195e-03,  9.86931026e-02],\n             [ 1.20191805e-01,  6.38831779e-02, -4.98587154e-02, ...,\n               6.52875677e-02,  9.09444019e-02,  2.06941679e-01],\n             [-1.89792797e-01, -2.77121440e-02, -9.00824070e-02, ...,\n               1.40164331e-01,  1.09205008e-01, -1.37078285e-01]],\n    \n            ...,\n    \n            [[-1.48054764e-01,  2.90305130e-02, -1.91400170e-01, ...,\n               5.24067134e-02,  3.07518840e-02,  4.91254106e-02],\n             [-1.00802153e-01, -2.14555293e-01, -1.29172012e-01, ...,\n               1.55810356e-01, -1.18614532e-01,  1.55882500e-02],\n             [ 6.24768576e-03, -1.86250567e-01, -2.27873698e-01, ...,\n               3.64947878e-02, -6.01969212e-02,  6.99269958e-03]],\n    \n            [[ 1.28245413e-01, -8.93764272e-02, -2.15834565e-02, ...,\n              -1.63186938e-01,  1.36647627e-01, -1.75899312e-01],\n             [-1.03763625e-01, -2.95581091e-02,  5.59201743e-03, ...,\n               7.47436378e-03,  1.10236563e-01,  3.99365053e-02],\n             [ 9.58012193e-02, -1.53220743e-01, -2.66150720e-02, ...,\n              -2.00559318e-01, -4.89554890e-02,  3.05318180e-02]],\n    \n            [[ 3.92769910e-02,  1.67552739e-01, -3.91807668e-02, ...,\n              -1.11705367e-03, -2.08108023e-01,  2.52939388e-03],\n             [-7.16665834e-02,  1.22348018e-01,  6.68843240e-02, ...,\n              -2.32481323e-02, -8.43867958e-02,  8.99919495e-02],\n             [-1.21405385e-01,  7.25267828e-02,  2.32462194e-02, ...,\n              -1.94767132e-01, -1.20492391e-01,  2.04466000e-01]]]],\n          dtype=float32)>). Make sure the slot variables are created under the same strategy scope. This may happen if you're restoring from a checkpoint outside the scope\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_790/974597712.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model_file_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heatmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tfrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_tfrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_790/15491495.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epochs, learning_rate, num_heatmap, batch_size, train_tfrecords, val_tfrecords)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Start training...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dist_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dist_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_790/3116605721.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, train_dist_dataset, val_dist_dataset)\u001b[0m\n\u001b[1;32m    126\u001b[0m                 epoch, self.current_learning_rate))\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             train_total_loss, num_train_batches = distributed_train_epoch(\n\u001b[0m\u001b[1;32m    129\u001b[0m                 train_dist_dataset)\n\u001b[1;32m    130\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_total_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_train_batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 759\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    760\u001b[0m             *args, **kwds))\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3298\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /tmp/ipykernel_790/3116605721.py:93 distributed_train_epoch  *\n        per_replica_loss = self.strategy.run(\n    /tmp/ipykernel_790/3116605721.py:70 train_step  *\n        self.optimizer.apply_gradients(\n    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:628 apply_gradients  **\n        self._create_all_weights(var_list)\n    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:815 _create_all_weights\n        self._create_slots(var_list)\n    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:117 _create_slots\n        self.add_slot(var, 'm')\n    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:892 add_slot\n        raise ValueError(\n\n    ValueError: Trying to create optimizer slot variable under the scope for tf.distribute.Strategy (<tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7fe3bde54070>), which is different from the scope used for the original variable (<tf.Variable 'conv2d_1/kernel:0' shape=(7, 7, 3, 64) dtype=float32, numpy=\n    array([[[[ 6.13027476e-02,  1.50614455e-01,  1.35345340e-01, ...,\n              -8.16099793e-02,  7.15045482e-02, -8.85434896e-02],\n             [-6.29635602e-02, -6.45009577e-02,  6.59904853e-02, ...,\n               4.35089208e-02,  2.15629488e-02,  2.57276475e-01],\n             [ 1.00521408e-01, -1.51722565e-01,  9.92045775e-02, ...,\n              -9.40072984e-02, -1.46815609e-02, -1.15684219e-01]],\n    \n            [[-9.80345309e-02,  1.89435855e-01, -2.37035602e-01, ...,\n               3.63893621e-02, -9.04790536e-02,  1.92969024e-01],\n             [ 2.16621935e-01, -1.02797031e-01, -1.64573925e-04, ...,\n              -1.09765165e-01, -4.60456088e-02, -2.80861929e-02],\n             [ 5.09737693e-02, -6.60286322e-02, -1.33431092e-01, ...,\n              -1.24041647e-01, -8.81058127e-02,  1.50977215e-02]],\n    \n            [[-3.01897596e-03,  5.22158742e-02,  1.65612474e-02, ...,\n              -2.43651614e-01,  6.62046224e-02, -1.80847988e-01],\n             [-9.65840742e-02, -1.45419076e-01,  2.03709617e-01, ...,\n              -7.71873444e-02,  2.29114853e-02, -1.21069320e-01],\n             [-8.00769702e-02, -1.01478718e-01,  1.00891180e-01, ...,\n               4.88331616e-02, -1.18581466e-01, -2.26025164e-01]],\n    \n            ...,\n    \n            [[ 1.35203265e-02,  2.76322067e-02, -1.44717664e-01, ...,\n               1.67539835e-01,  2.53902730e-02,  6.53840229e-02],\n             [ 8.61227289e-02,  5.12347668e-02, -1.39597639e-01, ...,\n               1.86924770e-01,  1.58347726e-01,  5.85889928e-02],\n             [-8.15377235e-02, -3.60459127e-02,  1.24675594e-02, ...,\n               3.86517122e-03, -8.50900263e-03, -7.69343972e-02]],\n    \n            [[ 1.66026592e-01,  1.49623260e-01, -2.31387913e-02, ...,\n              -6.54041320e-02, -1.24785528e-01,  1.31704941e-01],\n             [-6.64192736e-02, -1.13489442e-01,  1.60216063e-01, ...,\n              -3.09046414e-02,  5.88068701e-02, -4.45075817e-02],\n             [ 5.02059385e-02,  1.50478587e-01, -1.24967478e-01, ...,\n              -2.35792808e-02, -1.87081173e-01, -1.82202458e-03]],\n    \n            [[ 9.77816880e-02, -1.43437177e-01, -2.41182633e-02, ...,\n              -1.09410852e-01,  1.40387043e-01,  5.70664816e-02],\n             [ 2.14798331e-01, -1.96973637e-01,  2.03399867e-01, ...,\n               1.52573794e-01,  7.31504485e-02, -1.98803246e-02],\n             [ 5.21983206e-03,  9.81542990e-02, -7.46836141e-02, ...,\n               5.88658266e-02, -1.54774925e-02, -1.11802541e-01]]],\n    \n    \n           [[[ 7.43995011e-02, -3.11786756e-02,  3.34962271e-02, ...,\n               1.63646415e-01, -1.68314334e-02, -8.54853541e-02],\n             [ 1.04430266e-01, -1.40769137e-02, -1.32401913e-01, ...,\n              -1.31703451e-01,  1.18291833e-01, -1.89344719e-01],\n             [ 1.49974078e-01, -5.15702255e-02, -4.86299507e-02, ...,\n              -1.29736990e-01, -8.76289606e-02, -3.76371704e-02]],\n    \n            [[-8.01044796e-03, -2.40040213e-01, -4.81870994e-02, ...,\n               9.27171577e-03, -1.13444172e-01, -8.72101337e-02],\n             [-5.35292737e-02,  8.68863985e-02, -1.58409998e-01, ...,\n               1.55851930e-01,  9.55974590e-03,  6.06897473e-02],\n             [ 7.65984431e-02,  4.81488109e-02, -2.23900869e-01, ...,\n              -2.12638348e-01, -3.57730053e-02,  1.10168077e-01]],\n    \n            [[-3.13774236e-02, -9.63343382e-02,  1.56977430e-01, ...,\n              -4.51943576e-02, -2.04060555e-01,  9.81798321e-02],\n             [-1.87521636e-01, -2.46430308e-01,  1.55240605e-02, ...,\n              -1.04741462e-01,  1.54669628e-01,  1.00513427e-02],\n             [-8.26077834e-02,  6.01827316e-02, -1.45832434e-01, ...,\n              -2.47084014e-02, -1.86228052e-01, -7.59718008e-03]],\n    \n            ...,\n    \n            [[-1.98650762e-01,  1.63403571e-01, -2.17505336e-01, ...,\n              -1.25022501e-01,  1.50700205e-03,  6.11829832e-02],\n             [ 1.57758147e-01,  1.10434867e-01,  1.03581257e-01, ...,\n              -6.36967656e-04,  4.37583774e-02, -7.52287507e-02],\n             [-1.15172891e-03, -2.32697934e-01,  3.84797826e-02, ...,\n              -1.27419859e-01, -4.13282439e-02,  2.72780024e-02]],\n    \n            [[-1.87169820e-01,  9.76692960e-02, -4.22885753e-02, ...,\n               1.64859876e-01, -1.90731382e-03,  3.88390273e-02],\n             [ 6.44878298e-02, -4.29949947e-02,  4.66062538e-02, ...,\n              -1.00921109e-01,  9.50264186e-02, -1.41044557e-01],\n             [-1.18268281e-01,  6.36323616e-02, -4.75717883e-04, ...,\n              -7.70919770e-02,  6.90176114e-02, -9.26017538e-02]],\n    \n            [[-1.77174926e-01, -1.09059796e-01,  2.57321477e-01, ...,\n               2.14279905e-01,  3.51525508e-02, -4.04059067e-02],\n             [ 1.24453166e-02, -2.31172085e-01,  1.59734562e-01, ...,\n              -9.72141325e-02, -4.11993489e-02,  6.70645759e-02],\n             [ 1.80671969e-03, -2.23725867e-02, -1.82955608e-01, ...,\n               5.20451441e-02, -3.42951156e-02, -1.68170840e-01]]],\n    \n    \n           [[[ 4.26355489e-02,  7.08516911e-02,  2.27851477e-02, ...,\n              -1.65555432e-01, -2.32125863e-01, -4.53629717e-02],\n             [ 1.11784525e-01, -1.33745179e-01,  2.93720867e-02, ...,\n               1.87195957e-01, -5.33411540e-02, -3.95275019e-02],\n             [ 6.24825135e-02,  1.15999490e-01, -1.92222238e-01, ...,\n               8.75054970e-02,  1.74466074e-01,  5.45380078e-02]],\n    \n            [[-1.21881589e-01,  4.38498296e-02, -7.23414049e-02, ...,\n               9.86528918e-02, -1.50920851e-02,  6.44939169e-02],\n             [ 1.88989453e-02, -1.88362241e-01, -6.54458180e-02, ...,\n               1.97988749e-01,  1.69605762e-01, -1.03346892e-01],\n             [-5.94289042e-02, -9.17370170e-02,  1.96886927e-01, ...,\n               1.30331054e-01, -2.43689463e-01, -1.35739595e-01]],\n    \n            [[ 2.38891795e-01, -1.43961757e-01, -9.46223140e-02, ...,\n               6.54063299e-02, -1.12381577e-02,  3.47842425e-02],\n             [-1.24086522e-01,  9.33054239e-02, -1.71027740e-03, ...,\n              -1.03802510e-01, -1.44332871e-01,  5.87318987e-02],\n             [ 2.63413131e-01, -7.97889370e-04, -8.63094404e-02, ...,\n              -4.97243134e-03,  2.32819375e-03,  6.36920407e-02]],\n    \n            ...,\n    \n            [[ 4.39061895e-02, -3.06197144e-02,  8.19719583e-02, ...,\n               5.70775308e-02,  2.36131266e-01, -2.16464344e-02],\n             [ 1.58768788e-01, -1.44167338e-02,  1.66579440e-01, ...,\n               2.32374817e-02,  3.99878994e-02,  2.65069008e-01],\n             [-9.17340443e-03,  9.61398333e-02,  1.42653644e-01, ...,\n               8.60497877e-02, -1.56885013e-01, -2.45002419e-01]],\n    \n            [[ 3.78528871e-02, -4.50962633e-02,  2.17729837e-01, ...,\n              -7.20090494e-02, -1.03469238e-01, -2.47531980e-01],\n             [-9.78876948e-02, -2.15603426e-01,  2.57111993e-02, ...,\n               9.55697894e-02,  8.25565867e-03, -1.76898494e-01],\n             [-1.48313567e-01, -1.53920949e-01,  1.48660854e-01, ...,\n              -3.63829024e-02,  1.68311447e-01,  2.36072749e-01]],\n    \n            [[-7.60350004e-02,  2.57441364e-02,  1.55617103e-01, ...,\n              -1.51833028e-01, -2.96167843e-02, -1.05702221e-01],\n             [ 6.35700487e-03,  1.19157456e-01, -1.14801116e-02, ...,\n               1.77513450e-01, -5.99536579e-03, -7.12867975e-02],\n             [ 3.88280638e-02, -4.55495762e-03,  1.19555937e-02, ...,\n              -4.38393056e-02, -1.00527555e-01, -2.49935798e-02]]],\n    \n    \n           ...,\n    \n    \n           [[[ 1.22513577e-01,  5.09266648e-03, -8.53807628e-02, ...,\n              -4.58052615e-03, -1.68446988e-01, -2.58252531e-01],\n             [-2.14745346e-02,  1.63010120e-01, -9.59499255e-02, ...,\n              -6.83643371e-02, -1.53660802e-02, -2.36012965e-01],\n             [-1.70981824e-01, -1.40343681e-01,  2.26165846e-01, ...,\n              -3.32186744e-02,  1.70948461e-01, -8.36032704e-02]],\n    \n            [[-2.35205576e-01,  5.70198856e-02,  1.68733433e-01, ...,\n              -1.08057626e-01, -9.40405112e-03,  1.75195873e-01],\n             [ 2.64507532e-01, -1.91123098e-01, -1.61637619e-01, ...,\n               6.51448518e-02, -2.10690424e-02,  1.45839348e-01],\n             [ 1.39066324e-01, -5.14815859e-02,  2.19909810e-02, ...,\n               5.60113881e-03, -1.17751718e-01, -1.44344121e-01]],\n    \n            [[ 4.54274043e-02,  1.57887377e-02,  1.67322367e-01, ...,\n               9.58062708e-02,  1.19645859e-03, -1.23345762e-01],\n             [-3.60198915e-02, -2.64056563e-01, -9.42556038e-02, ...,\n              -1.68050960e-01, -2.11052999e-01, -4.06056568e-02],\n             [-1.45537816e-02,  1.73526824e-01,  6.66935593e-02, ...,\n               1.35415448e-02, -5.84160127e-02, -5.43588661e-02]],\n    \n            ...,\n    \n            [[-7.06954151e-02, -1.57525837e-02, -6.17827736e-02, ...,\n               4.98971902e-02, -1.35388508e-01,  1.19418912e-01],\n             [-7.34979659e-02, -9.36273858e-02,  4.66608108e-05, ...,\n              -2.12430488e-02,  1.30864397e-01,  2.23309956e-02],\n             [ 1.05640348e-02,  1.14529040e-02, -1.98482163e-02, ...,\n              -3.01012192e-02,  3.05300076e-02,  1.01408176e-02]],\n    \n            [[ 6.65159523e-02, -6.20860606e-02,  1.73784435e-01, ...,\n              -1.11620888e-01, -1.10321261e-01, -9.86246988e-02],\n             [ 1.92608505e-01,  1.04694196e-03,  6.53823167e-02, ...,\n              -2.04312056e-01, -1.18431769e-01,  1.71276495e-01],\n             [ 6.37844801e-02, -1.83133736e-01, -5.33691421e-03, ...,\n               1.10962778e-01,  1.49894720e-02, -2.65677460e-02]],\n    \n            [[ 1.54260352e-01, -1.84997752e-01,  2.22448170e-01, ...,\n               1.06664814e-01,  2.46161804e-01, -1.50213555e-01],\n             [ 1.95108657e-03,  1.25695586e-01,  1.11226246e-01, ...,\n               1.00337654e-01, -4.07159738e-02,  5.33722788e-02],\n             [-4.67980653e-02,  1.68124102e-02, -5.42787984e-02, ...,\n               7.21492171e-02, -1.94428295e-01, -8.44115540e-02]]],\n    \n    \n           [[[ 1.82942763e-01, -8.18129033e-02, -6.50480986e-02, ...,\n              -3.28951329e-02,  1.11755855e-01, -1.93311468e-01],\n             [ 6.88859448e-02,  1.05793223e-01, -3.78636196e-02, ...,\n              -1.24510430e-01, -1.39778003e-01,  5.25865369e-02],\n             [ 6.43820912e-02, -4.60356027e-02, -1.58389047e-01, ...,\n              -1.41978385e-02,  2.69474909e-02,  1.35781392e-01]],\n    \n            [[ 1.08313477e-02,  8.51419717e-02,  9.51005705e-03, ...,\n               1.34007007e-01,  8.09658617e-02, -3.71751608e-03],\n             [-1.57593071e-01,  7.20410347e-02, -3.25790830e-02, ...,\n              -7.64965490e-02,  5.53848557e-02, -7.33073801e-03],\n             [ 4.44678366e-02, -1.98039442e-01,  4.25111242e-02, ...,\n              -6.98965567e-04, -6.23266958e-02, -1.28207669e-01]],\n    \n            [[ 1.73923433e-01, -1.82014033e-01,  1.99949592e-01, ...,\n               1.08951762e-01,  1.37633190e-01, -7.67332837e-02],\n             [ 1.78947002e-01, -1.05287030e-01, -1.78546026e-01, ...,\n               4.18139920e-02,  1.19867198e-01, -5.30888252e-02],\n             [ 1.23708047e-01,  8.57422501e-02, -8.08505341e-02, ...,\n               6.55694902e-02,  1.19448610e-01, -2.02073436e-02]],\n    \n            ...,\n    \n            [[-5.52293323e-02, -1.73223298e-02, -5.15250005e-02, ...,\n              -2.60589927e-01, -2.89728567e-02,  8.53877664e-02],\n             [ 2.05206409e-01, -2.08407059e-01,  1.54277846e-01, ...,\n              -9.81937908e-03, -7.25610703e-02, -3.35084088e-02],\n             [ 7.93058239e-03, -4.96752821e-02,  4.48598005e-02, ...,\n              -1.96584761e-01,  1.00772962e-01, -3.94208394e-02]],\n    \n            [[ 6.71999678e-02,  1.73313782e-01,  2.93664597e-02, ...,\n               5.67325018e-02, -5.00684567e-02,  1.11726359e-01],\n             [ 1.38092965e-01, -1.90900519e-01,  2.08595954e-02, ...,\n               4.12898026e-02,  2.09918916e-01,  1.04889885e-01],\n             [ 5.27262837e-02,  1.54369742e-01,  1.67765431e-02, ...,\n              -6.49158955e-02, -1.98975384e-01,  9.15587470e-02]],\n    \n            [[ 1.21292941e-01,  2.61825696e-02,  7.50790834e-02, ...,\n               7.48665407e-02, -1.71162244e-02,  2.04452112e-01],\n             [ 7.71558732e-02,  8.79929215e-02,  2.91220881e-02, ...,\n              -2.75771040e-02, -1.71310008e-01, -2.05015957e-01],\n             [ 2.61003301e-02,  7.40160421e-02, -1.57126129e-01, ...,\n               4.59693894e-02, -1.56030869e-02,  4.71492670e-02]]],\n    \n    \n           [[[ 5.18705361e-02,  9.25799385e-02, -4.54633161e-02, ...,\n              -1.85025752e-01,  1.03554344e-02,  3.04602180e-02],\n             [-9.15733650e-02,  8.38815495e-02,  9.64396750e-04, ...,\n              -4.18407880e-02,  9.77511778e-02,  1.88279059e-02],\n             [-6.69050589e-02,  2.22615927e-01, -2.02202648e-01, ...,\n               2.68423986e-02, -2.29618717e-02,  1.95339024e-01]],\n    \n            [[-2.98027899e-02, -1.23825036e-02, -4.72679548e-03, ...,\n              -2.23784283e-01, -2.03028638e-02, -1.13757990e-01],\n             [-6.01671971e-02,  6.52498528e-02, -1.52463406e-01, ...,\n               1.61664765e-02,  1.56070486e-01,  1.99765205e-01],\n             [-1.08138425e-03,  1.74854442e-01, -3.07951812e-02, ...,\n               2.00511247e-01,  2.56577320e-02, -1.06467262e-01]],\n    \n            [[ 2.44527441e-02, -4.42111716e-02, -9.53390971e-02, ...,\n              -1.34497965e-02,  7.15488195e-03,  9.86931026e-02],\n             [ 1.20191805e-01,  6.38831779e-02, -4.98587154e-02, ...,\n               6.52875677e-02,  9.09444019e-02,  2.06941679e-01],\n             [-1.89792797e-01, -2.77121440e-02, -9.00824070e-02, ...,\n               1.40164331e-01,  1.09205008e-01, -1.37078285e-01]],\n    \n            ...,\n    \n            [[-1.48054764e-01,  2.90305130e-02, -1.91400170e-01, ...,\n               5.24067134e-02,  3.07518840e-02,  4.91254106e-02],\n             [-1.00802153e-01, -2.14555293e-01, -1.29172012e-01, ...,\n               1.55810356e-01, -1.18614532e-01,  1.55882500e-02],\n             [ 6.24768576e-03, -1.86250567e-01, -2.27873698e-01, ...,\n               3.64947878e-02, -6.01969212e-02,  6.99269958e-03]],\n    \n            [[ 1.28245413e-01, -8.93764272e-02, -2.15834565e-02, ...,\n              -1.63186938e-01,  1.36647627e-01, -1.75899312e-01],\n             [-1.03763625e-01, -2.95581091e-02,  5.59201743e-03, ...,\n               7.47436378e-03,  1.10236563e-01,  3.99365053e-02],\n             [ 9.58012193e-02, -1.53220743e-01, -2.66150720e-02, ...,\n              -2.00559318e-01, -4.89554890e-02,  3.05318180e-02]],\n    \n            [[ 3.92769910e-02,  1.67552739e-01, -3.91807668e-02, ...,\n              -1.11705367e-03, -2.08108023e-01,  2.52939388e-03],\n             [-7.16665834e-02,  1.22348018e-01,  6.68843240e-02, ...,\n              -2.32481323e-02, -8.43867958e-02,  8.99919495e-02],\n             [-1.21405385e-01,  7.25267828e-02,  2.32462194e-02, ...,\n              -1.94767132e-01, -1.20492391e-01,  2.04466000e-01]]]],\n          dtype=float32)>). Make sure the slot variables are created under the same strategy scope. This may happen if you're restoring from a checkpoint outside the scope\n"
     ]
    }
   ],
   "source": [
    "best_model_file_1 = train(model_1, epochs, learning_rate, num_heatmap, batch_size, train_tfrecords, val_tfrecords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf50196",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_file_2 = train(model_2, epochs, learning_rate, num_heatmap, batch_size, train_tfrecords, val_tfrecords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cc1ad5",
   "metadata": {},
   "source": [
    "## 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420c14a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 학습된 모델\n",
    "\n",
    "# WEIGHTS_PATH = os.path.join(PROJECT_PATH, 'models', 'model-v0.0.1-epoch-2-loss-1.3072.h5')\n",
    "\n",
    "# model = StackedHourglassNetwork(IMAGE_SHAPE, 4, 1)\n",
    "# model.load_weights(WEIGHTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ab5ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 직접 학습한 모델\n",
    "model_1 = StackedHourglassNetwork(IMAGE_SHAPE, 4, 1)\n",
    "model_1.load_weights(best_model_file_1)\n",
    "\n",
    "model_2 = Simplebaseline(IMAGE_SHAPE)\n",
    "model_2.load_weights(best_model_file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfabc177",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_ANKLE = 0\n",
    "R_KNEE = 1\n",
    "R_HIP = 2\n",
    "L_HIP = 3\n",
    "L_KNEE = 4\n",
    "L_ANKLE = 5\n",
    "PELVIS = 6\n",
    "THORAX = 7\n",
    "UPPER_NECK = 8\n",
    "HEAD_TOP = 9\n",
    "R_WRIST = 10\n",
    "R_ELBOW = 11\n",
    "R_SHOULDER = 12\n",
    "L_SHOULDER = 13\n",
    "L_ELBOW = 14\n",
    "L_WRIST = 15\n",
    "\n",
    "MPII_BONES = [\n",
    "    [R_ANKLE, R_KNEE],\n",
    "    [R_KNEE, R_HIP],\n",
    "    [R_HIP, PELVIS],\n",
    "    [L_HIP, PELVIS],\n",
    "    [L_HIP, L_KNEE],\n",
    "    [L_KNEE, L_ANKLE],\n",
    "    [PELVIS, THORAX],\n",
    "    [THORAX, UPPER_NECK],\n",
    "    [UPPER_NECK, HEAD_TOP],\n",
    "    [R_WRIST, R_ELBOW],\n",
    "    [R_ELBOW, R_SHOULDER],\n",
    "    [THORAX, R_SHOULDER],\n",
    "    [THORAX, L_SHOULDER],\n",
    "    [L_SHOULDER, L_ELBOW],\n",
    "    [L_ELBOW, L_WRIST]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aa1393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 학습할 때 라벨이 되는 좌표를 heatmap으로 바꿨던 것이 기억 나시나요? \n",
    "# 학습을 heatmap으로 했기 때문에 모델이 추론해 내놓은 결과도 heatmap입니다.\n",
    "# 그래서 이 heatmap으로부터 좌표를 추출해야해요. heatmap중에 최대값을 갖는 지점을 찾아내면 되겠네요.\n",
    "# heatmap에서 최대값을 찾는 함수를 만들어 줍니다.\n",
    "def find_max_coordinates(heatmaps):\n",
    "    flatten_heatmaps = tf.reshape(heatmaps, (-1, 16))\n",
    "    indices = tf.math.argmax(flatten_heatmaps, axis=0)\n",
    "    y = tf.cast(indices / 64, dtype=tf.int64)\n",
    "    x = indices - 64 * y\n",
    "    return tf.stack([x, y], axis=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce9b08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints_from_heatmap(heatmaps):\n",
    "    max_keypoints = find_max_coordinates(heatmaps)\n",
    "\n",
    "    padded_heatmap = np.pad(heatmaps, [[1,1],[1,1],[0,0]], mode='constant')\n",
    "    adjusted_keypoints = []\n",
    "    for i, keypoint in enumerate(max_keypoints):\n",
    "        max_y = keypoint[1]+1\n",
    "        max_x = keypoint[0]+1\n",
    "        \n",
    "        patch = padded_heatmap[max_y-1:max_y+2, max_x-1:max_x+2, i]\n",
    "        patch[1][1] = 0\n",
    "        \n",
    "        index = np.argmax(patch)\n",
    "        \n",
    "        next_y = index // 3\n",
    "        next_x = index - next_y * 3\n",
    "        delta_y = (next_y - 1) / 4\n",
    "        delta_x = (next_x - 1) / 4\n",
    "        \n",
    "        adjusted_keypoint_x = keypoint[0] + delta_x\n",
    "        adjusted_keypoint_y = keypoint[1] + delta_y\n",
    "        adjusted_keypoints.append((adjusted_keypoint_x, adjusted_keypoint_y))\n",
    "        \n",
    "    adjusted_keypoints = np.clip(adjusted_keypoints, 0, 64)\n",
    "    normalized_keypoints = adjusted_keypoints / 64\n",
    "    return normalized_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5a882c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bec81ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
